{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnsonYu0924/114_2_text-analysis/blob/main/L8_corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建構 Corpus（語料庫）\n"
      ],
      "metadata": {
        "id": "P7krTRlAm1aE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PlaintextCorpusReader 是不分類，整體語料庫\n",
        "- CategorizedPlaintextCorpusReader 是有分類，分類後的語料庫"
      ],
      "metadata": {
        "id": "GcivSP4_vsGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import nltk, os, json\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader, CategorizedPlaintextCorpusReader\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/combine/\"\n",
        "# print(os.listdir(path))\n",
        "\n",
        "# 利用pattern\n",
        "txtPattern = r\"[\\w\\s.]+\\.txt\"\n",
        "myCorpus1 = PlaintextCorpusReader(path, txtPattern)\n",
        "myCorpus1.fileids()\n",
        "\n",
        "Pattern = r\".*(_Han|_Soong|_Tsai).*\\.txt\"\n",
        "catePattern = r\".*(_Han|_Soong|_Tsai).*\"\n",
        "\n",
        "myCorpus2 = CategorizedPlaintextCorpusReader(path, Pattern, cat_pattern = catePattern)\n",
        "myCorpus2.fileids()\n",
        "myCorpus2.categories()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlQRt0U1DIF4",
        "outputId": "f2dee43c-fabf-4dfe-f81a-51c14ec3542a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Han', '_Soong', '_Tsai']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaFLBvK6mC0k",
        "outputId": "d3bd3cbf-ac92-4f2d-a19a-4b7fe808817b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'myCorpus2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1564715626.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyCorpus2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## sentence 是一個 list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## \"[5:7]\" 取幾個句子來看看\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'myCorpus2' is not defined"
          ]
        }
      ],
      "source": [
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YON3bcbmC0k",
        "outputId": "2a1b819a-eb3d-4232-ebce-700c1aa93f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'have', 'no', 'doubt', 'that', 'the', 'military', 'had', 'authority', 'to', 'select', 'this', 'particular', 'property', 'for', 'destruction', '.', 'But', 'whatever', 'the', 'weight', 'of', 'authority', 'may', 'be', ',', 'I', 'believe', 'that', 'the', 'Fifth', 'Amendment', 'requires', 'compensation', 'for', 'the', 'taking', '.']\n"
          ]
        }
      ],
      "source": [
        "print(myCorpus2.words()[26:64]) #經過 tokenizer 後的所有 tokens（字詞）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_lBTTdimC0k",
        "outputId": "af266b9b-f6f7-4c72-c3ca-94baa415563a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(myCorpus2.paras(\"1952 U.S. LEXIS 2631.opin.neg.txt\"))\n",
        "\n",
        "# paras() 會回傳：\n",
        "# 一個 list，其中每個元素是一個段落（paragraph）\n",
        "# 每個段落本身會是一個「由句子構成的 list」，\n",
        "# 每個句子又是一份「由 tokens 構成的 list」"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "用 loop 總結你的文本"
      ],
      "metadata": {
        "id": "Hn7N5e4syw-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqKy8yOQmC0k",
        "outputId": "d2630e1e-3b99-4adc-91ad-fe4c74e34be0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1952 U.S. LEXIS 2631.opin.neg.txt\n",
            "7 paragraphs, 11 sentences, and 190 words\n",
            "\n",
            "1959 U.S. LEXIS 1490.opin.neg.txt\n",
            "2 paragraphs, 2 sentences, and 35 words\n",
            "\n",
            "1985 U.S. LEXIS 63.opin.neg.txt\n",
            "6 paragraphs, 7 sentences, and 45 words\n",
            "\n",
            "1986 U.S. LEXIS 25.opin.pos.txt\n",
            "8 paragraphs, 38 sentences, and 1230 words\n",
            "\n",
            "1986 U.S. LEXIS 72.opin.2.pos.txt\n",
            "6 paragraphs, 6 sentences, and 44 words\n",
            "\n",
            "1989 U.S. LEXIS 579.opin.6.pos 2.txt\n",
            "5 paragraphs, 10 sentences, and 231 words\n",
            "\n",
            "1989 U.S. LEXIS 579.opin.6.pos.txt\n",
            "5 paragraphs, 10 sentences, and 231 words\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Building a loop to summarize each document in your corpus       ## for publish: use the function prevuos people have done.\n",
        "for file in myCorpus2.fileids():  ##() : empty: all the files.\n",
        "    paras = len(myCorpus2.paras(file))   ## paragragh!\n",
        "    sents = len(myCorpus2.sents(file))   ## sentences!\n",
        "    words = len(myCorpus2.words(file))   ## words!\n",
        "    print(file)\n",
        "    print(str(paras) + \" paragraphs, \" + str(sents) + \\\n",
        "          \" sentences, and \" + str(words) + \" words\" + \"\\n\")\n",
        "\n",
        "# for file in myCorpus2.fileids():\n",
        "# myCorpus2.fileids() 會回傳 corpus 裡所有的檔案名稱（list）\n",
        "# for file in ... 表示要對 corpus 中 每一個文件都做一次統計\n",
        "\n",
        "# paras = len(myCorpus2.paras(file))\n",
        "# myCorpus2.paras(file) → 回傳「段落列表」\n",
        "# len(...) → 計算這篇文件有幾段（paragraphs）\n",
        "\n",
        "# sents = len(myCorpus2.sents(file))\n",
        "# myCorpus2.sents(file) → 回傳「句子列表」\n",
        "# len(...) → 計算句子的數量\n",
        "\n",
        "# words = len(myCorpus2.words(file))\n",
        "# myCorpus2.words(file) → 回傳整篇文章 tokenize 後的「字詞 list」\n",
        "# len(...) → 計算單字數量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRKmlf3fmC0l",
        "outputId": "0bc7b15b-8842-45fd-8a21-0c4fe8e32bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1986 U.S. LEXIS 25.opin.pos.txt\n",
            "1986 U.S. LEXIS 72.opin.2.pos.txt\n",
            "1989 U.S. LEXIS 579.opin.6.pos 2.txt\n",
            "1989 U.S. LEXIS 579.opin.6.pos.txt\n"
          ]
        }
      ],
      "source": [
        "## 設定只看某個類別\n",
        "for file in myCorpus2.fileids(categories=\"pos\"):   ## the files in that category\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhWOlyMUmC0l"
      },
      "outputs": [],
      "source": [
        "# 用函數總結你的文本   ## codes from the book and reword a bit!\n",
        "import time, nltk\n",
        "from nltk import pos_tag, sent_tokenize, wordpunct_tokenize\n",
        "\n",
        "def describe(self, fileids=None, categories=None):\n",
        "    \"\"\"\n",
        "    Performs a single pass of the corpus and\n",
        "    returns a dictionary with a variety of metrics\n",
        "    concerning the state of the corpus.\n",
        "    \"\"\"\n",
        "    started = time.time()   ## how much time needed\n",
        "\n",
        "    # Structures to perform counting.\n",
        "    counts  = nltk.FreqDist()\n",
        "    tokens  = nltk.FreqDist() # 一個專門用來計數的字典（frequency dictionary）。自動處理 key-value 增加（比 defaultdict 更方便）。\n",
        "\n",
        "    # 計算段落數\n",
        "    for para in self.paras(fileids, categories): # 走訪所有選到的段落，每遇到一個句子就加一。\n",
        "        counts['paras'] += 1\n",
        "    # 計算句子數\n",
        "    for sent in self.sents(fileids, categories):\n",
        "        counts['sents'] += 1\n",
        "\n",
        "    for word in self.words(fileids, categories):\n",
        "        counts['words'] += 1\n",
        "        tokens[word] += 1\n",
        "\n",
        "    # Compute the number of files and categories in the corpus\n",
        "    n_fileids = len(self.fileids())\n",
        "    n_topics  = len(self.categories())\n",
        "\n",
        "    # Return data structure with information\n",
        "    return {\n",
        "        'files':  n_fileids,\n",
        "        'topics': n_topics,\n",
        "        'paras':  counts['paras'],\n",
        "        'sents':  counts['sents'],\n",
        "        'words':  counts['words'],\n",
        "        'vocab':  len(tokens),\n",
        "        'lexical diversity': float(counts['words']) / float(len(tokens)),\n",
        "        'paragraphs per doc':  float(counts['paras']) / float(n_fileids),\n",
        "        'sentences per paragraph':  float(counts['sents']) / float(counts['paras']),\n",
        "        'secs':   time.time() - started,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjwQY_kBmC0s",
        "outputId": "c489f080-47a7-4994-d40d-37df292ce8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'files': 7,\n",
              " 'topics': 2,\n",
              " 'paras': 39,\n",
              " 'sents': 84,\n",
              " 'words': 2006,\n",
              " 'vocab': 638,\n",
              " 'lexical diversity': 3.1442006269592477,\n",
              " 'paragraphs per doc': 5.571428571428571,\n",
              " 'sentences per paragraph': 2.1538461538461537,\n",
              " 'secs': 0.03154444694519043}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "describe(myCorpus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DGweuIEmC0t",
        "outputId": "4feb3771-aaf6-4dd5-8405-d42d6314591f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'files': 7,\n",
              " 'topics': 2,\n",
              " 'paras': 15,\n",
              " 'sents': 20,\n",
              " 'words': 270,\n",
              " 'vocab': 140,\n",
              " 'lexical diversity': 1.9285714285714286,\n",
              " 'paragraphs per doc': 2.142857142857143,\n",
              " 'sentences per paragraph': 1.3333333333333333,\n",
              " 'secs': 0.00561213493347168}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "describe(myCorpus2, categories=\"neg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlsiwtEpmC0t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 如何使用課本中的程式碼 (Slide 15)"
      ],
      "metadata": {
        "id": "W4S1LynK1e3z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnBird_5mC0t",
        "outputId": "002331d4-effe-4e7c-bd22-61f160a12055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting readability-lxml\n",
            "  Downloading readability_lxml-0.8.4.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from readability-lxml) (5.2.0)\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.12/dist-packages (from readability-lxml) (6.0.2)\n",
            "Collecting cssselect (from readability-lxml)\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting lxml_html_clean (from lxml[html_clean]->readability-lxml)\n",
            "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading readability_lxml-0.8.4.1-py3-none-any.whl (19 kB)\n",
            "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: lxml_html_clean, cssselect, readability-lxml\n",
            "Successfully installed cssselect-1.3.0 lxml_html_clean-0.4.3 readability-lxml-0.8.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install readability-lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr0z0AAVmC0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8bbb58-c285-4176-9277-585beb084c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-01 07:06:31--  https://raw.githubusercontent.com/foxbook/atap/refs/heads/master/snippets/ch03/reader.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9710 (9.5K) [text/plain]\n",
            "Saving to: ‘reader.py’\n",
            "\n",
            "reader.py           100%[===================>]   9.48K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-12-01 07:06:31 (2.86 MB/s) - ‘reader.py’ saved [9710/9710]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#from ch03 import reader\n",
        "\n",
        "!wget https://raw.githubusercontent.com/foxbook/atap/refs/heads/master/snippets/ch03/reader.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "reader = importlib.import_module(\"reader\")"
      ],
      "metadata": {
        "id": "kpWAXFej3xN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0pnSyIfmC0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "d7c5b5e5-b7a6-4b45-cc32-9509ebb85e05"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No such file or directory: '/content/mc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1876612917.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmyTags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'h1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'li'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m myCorpus3 = reader.HTMLCorpusReader(mydir + \"mc/\",\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocumentPattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 tags=myTags)\n",
            "\u001b[0;32m/content/reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, encoding, tags, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Initialize the NLTK corpus reader objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mCategorizedCorpusReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mCorpusReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Save the tags that we specifically want to extract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, encoding, tagset)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPathPointer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CorpusReader: expected a string or a PathPointer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or directory: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/content/mc'"
          ]
        }
      ],
      "source": [
        "documentPattern = r'.*\\.json'\n",
        "myTags = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'li']\n",
        "\n",
        "myCorpus3 = reader.HTMLCorpusReader(mydir + \"mc/\",\n",
        "                fileids = documentPattern, encoding='utf8', \\\n",
        "                tags=myTags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-8JYTqgmC0u",
        "outputId": "de8a2378-bc21-4653-a17b-e02d82ad21b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'myCorpus3' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3442422359.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyCorpus3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'myCorpus3' is not defined"
          ]
        }
      ],
      "source": [
        "myCorpus3.fileids()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Vectorization"
      ],
      "metadata": {
        "id": "pK6UDFlp5DMu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGAgblYvmC0v"
      },
      "outputs": [],
      "source": [
        "## Slide 17\n",
        "## Function to tokenize and create frequency vectors using NLTK\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "# okenize() 函式 — 分詞 + 清理 + 詞幹化\n",
        "def tokenize(text):\n",
        "   stem = nltk.stem.SnowballStemmer('english')  #建立一個 詞幹化器（例如：running → run）\n",
        "   text = text.lower() #把整串文字變成小寫\n",
        "   tokens = []\n",
        "\n",
        "   for token in nltk.word_tokenize(text):\n",
        "       if token in string.punctuation: continue #丟掉標點符號\n",
        "       yield stem.stem(token) #例如 running → run 或是 studies → studi\n",
        "       tokens.append(token)\n",
        "   return tokens\n",
        "\n",
        "def tokenize(text):\n",
        "    stem = nltk.stem.SnowballStemmer('english')\n",
        "    text = text.lower()\n",
        "    tokens = []\n",
        "\n",
        "    for token in nltk.word_tokenize(text):\n",
        "        if token in string.punctuation:\n",
        "            continue\n",
        "        tokens.append(stem.stem(token))   # 用 stem 過的 token\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# vectorize function\n",
        "from collections import defaultdict\n",
        "\n",
        "def vectorize(doc):\n",
        "    features = defaultdict(int) # 建立一個 frequency dictionary\n",
        "    for token in tokenize(doc): # 逐一取得分詞結果（從 tokenize 函式）\n",
        "        features[token] += 1\n",
        "    return features\n",
        "\n",
        "# vectorize\"\n",
        "# 例如輸入：\"This is great, great!\"\n",
        "# tokenize 後：['this', 'is', 'great', 'great']\n",
        "# vector 會是：{'this': 1, 'is': 1 'great': 2}\n",
        "\n",
        "## 英文文件之間的重複字很少，所以如果把兩篇文章變成 Bag-of-Words vector 來比較，你會看到很多 0。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "例如輸入：```\"This is great, great!\"```\n",
        "\n",
        "tokenize 後：```['this', 'is', 'great', 'great'] ```\n",
        "\n",
        "vector 會是：\n",
        "```{'this': 1, 'is': 1 'great': 2} ```\n"
      ],
      "metadata": {
        "id": "sRJbxs5x8FNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKQ8OgyqmC0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f16ecce-f0b9-4181-cf16-1ae40b4599cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-616724644.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  doc = re.sub(\"\\s+\", \" \", doc) # 清理：把多個空白統一成一個空白\n"
          ]
        }
      ],
      "source": [
        "# Tokenize 文本，然後儲存成字串清單\n",
        "import re\n",
        "strCorpus = []  ## 每個元素是一篇完整文件的字串。\n",
        "for file in myCorpus2.fileids(): # myCorpus2.fileids() 會列出語料庫的所有檔名\n",
        "    doc = myCorpus2.raw(file) #讀取整篇文件的原始內容 (raw)\n",
        "    doc = re.sub(\"\\s+\", \" \", doc) # 清理：把多個空白統一成一個空白\n",
        "    strCorpus.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvuGfgOamC0v"
      },
      "outputs": [],
      "source": [
        "# 示範 NLP 程式碼的測試語料庫\n",
        "toyCorpus = [ \"The elephant sneezed at the sight of potatoes.\", \"Bats can see via echolocation. See the bat sight sneeze!\", \"Wondering, she opened the door to the studio.\", ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbTe3MQKmC0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23747a72-f9e2-4e99-bf3f-57e429e05c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[defaultdict(<class 'int'>, {'the': 2, 'eleph': 1, 'sneez': 1, 'at': 1, 'sight': 1, 'of': 1, 'potato': 1}), defaultdict(<class 'int'>, {'bat': 2, 'can': 1, 'see': 2, 'via': 1, 'echoloc': 1, 'the': 1, 'sight': 1, 'sneez': 1}), defaultdict(<class 'int'>, {'wonder': 1, 'she': 1, 'open': 1, 'the': 2, 'door': 1, 'to': 1, 'studio': 1})]\n"
          ]
        }
      ],
      "source": [
        "toyFreqVectors = map(vectorize, toyCorpus) # 把 vectorize() 函數套用到 toyCorpus 的每一個元素。\n",
        "print(list(toyFreqVectors)) # map() 回傳的是 lazy object：所以可以用 list() 展開，再輸出內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTkl7Bq1mC0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca8bfe4-eeb6-444b-e6db-e16bbee4661d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[defaultdict(<class 'int'>, {'author': 3, 'wodougla': 1, 'type': 1, 'dissent': 3, 'dissentbi': 1, 'dougla': 2, 'mr.': 2, 'justic': 2, 'with': 1, 'whom': 1, 'black': 1, 'concur': 1, 'i': 2, 'have': 1, 'no': 1, 'doubt': 1, 'that': 5, 'the': 18, 'militari': 1, 'had': 1, 'to': 5, 'select': 1, 'this': 3, 'particular': 1, 'properti': 4, 'for': 4, 'destruct': 3, 'but': 2, 'whatev': 2, 'weight': 1, 'of': 4, 'may': 2, 'be': 3, 'believ': 1, 'fifth': 1, 'amend': 1, 'requir': 1, 'compens': 1, 'take': 1, 'was': 4, 'destroy': 1, 'not': 1, 'becaus': 2, 'it': 6, 'in': 1, 'natur': 1, 'a': 2, 'public': 2, 'nuisanc': 1, 'deem': 1, 'necessari': 1, 'help': 1, 'win': 1, 'war': 2, 'as': 3, 'clear': 1, 'appropri': 2, 'end': 1, 'anim': 1, 'food': 1, 'and': 2, 'suppli': 1, 'requisit': 1, 'defens': 1, 'effort': 2, 'court': 1, 'say': 1, 'depriv': 1, 'enemi': 1, 'valuabl': 1, 'logist': 1, 'weapon': 1, 'seem': 1, 'me': 1, 'guid': 1, 'principl': 1, 'should': 2, 'whenev': 1, 'govern': 1, 'determin': 1, 'one': 1, 'person': 1, \"'s\": 1, '--': 2, 'is': 1, 'essenti': 1, 'common': 1, 'good': 1, 'purs': 1, 'rather': 1, 'than': 1, 'individu': 1, 'bear': 1, 'loss': 1}), defaultdict(<class 'int'>, {'author': 1, 'wodougla': 1, 'type': 1, 'dissent': 2, 'mr.': 1, 'justic': 1, 'dougla': 1, 'be': 1, 'of': 2, 'the': 2, 'view': 1, 'that': 1, 'petition': 1, 'was': 1, 'in': 2, 'substanc': 1, 'tri': 1, 'for': 1, 'murder': 1, 'twice': 1, 'violat': 1, 'guarante': 1, 'against': 1, 'doubl': 1, 'jeopardi': 1}), defaultdict(<class 'int'>, {'author': 1, 'tmarshal': 1, 'type': 1, 'dissent': 4, 'dissentbi': 1, 'marshal': 2, 'justic': 1, 'i': 2, 'continu': 1, 'to': 4, 'object': 1, 'decid': 1, 'case': 1, 'without': 1, 'grant': 1, 'either': 2, 'parti': 1, 'an': 1, 'opportun': 1, 'argu': 1, 'the': 1, 'merit': 1, 'by': 1, 'brief': 1, 'or': 1, 'oral': 1, 'argument': 1, 'therefor': 1}), defaultdict(<class 'int'>, {'author': 2, 'ascalia': 1, 'type': 1, 'dissent': 4, 'justic': 3, 'scalia': 1, 'with': 3, 'whom': 1, 'the': 89, 'chief': 1, 'and': 15, \"o'connor\": 1, 'join': 2, 'both': 1, 'right': 3, 'of': 46, 'free': 2, 'polit': 2, 'associ': 6, 'state': 9, \"'s\": 16, 'to': 33, 'establish': 1, 'arrang': 1, 'that': 22, 'assur': 2, 'fair': 1, 'effect': 1, 'parti': 38, 'particip': 2, 'in': 13, 'elect': 4, 'process': 4, 'are': 4, 'essenti': 1, 'democrat': 11, 'govern': 1, 'our': 1, 'case': 4, 'make': 1, 'it': 24, 'clear': 1, 'accommod': 1, 'these': 1, 'two': 2, 'vital': 1, 'interest': 4, 'doe': 3, 'not': 9, 'lend': 1, 'itself': 3, 'bright-lin': 1, 'rule': 2, 'but': 4, 'requir': 4, 'care': 1, 'inquiri': 1, 'into': 1, 'extent': 1, 'which': 5, 'one': 4, 'or': 4, 'other': 3, 'is': 17, 'inordin': 1, 'impair': 2, 'under': 2, 'fact': 4, 'particular': 1, 'see': 4, 'anderson': 1, 'v.': 6, 'celebrezz': 1, '460': 1, 'u.s.': 6, '780': 1, '788-790': 1, '1983': 1, 'storer': 1, 'brown': 1, '415': 2, '724': 1, '730': 1, '1974': 2, 'even': 3, 'so': 4, 'conclus': 2, 'reach': 2, 'on': 4, 'individu': 2, 'shed': 1, 'some': 1, 'measur': 1, 'light': 1, 'upon': 2, 'will': 1, 'be': 13, 'next': 1, 'sinc': 1, 'this': 7, 'an': 6, 'area': 1, 'moreov': 1, 'predict': 1, 'decis': 4, 'import': 4, 'i': 3, 'think': 1, 'worth': 1, 'note': 1, 'for': 3, 'me': 4, 'today': 1, 'alreadi': 1, 'exceed': 1, 'permiss': 1, 'limit': 1, 'first': 2, 'amend': 1, 'restrict': 3, 'order': 1, 'my': 2, 'view': 2, 'court': 2, 'opinion': 3, 'exagger': 1, 'at': 2, 'issu': 1, 'if': 5, 'inde': 1, 'where': 1, 'none': 1, 'exist': 1, 'there': 5, 'no': 6, 'question': 3, 'here': 2, 'republican': 9, 'abil': 4, 'recruit': 1, 'enrol': 1, 'member': 12, 'by': 16, 'offer': 1, 'them': 1, 'select': 8, 'candid': 13, 'conn.': 2, 'gen.': 1, 'stat': 1, '9-56': 1, '1985': 1, 'permit': 2, 'independ': 7, 'voter': 3, 'as': 9, 'late': 1, 'day': 1, 'befor': 2, 'primari': 6, 'cf': 1, 'kusper': 1, 'pontik': 1, '414': 1, '51': 1, '1973': 1, 'nor': 2, 'ani': 4, 'whatev': 1, 'they': 1, 'desir': 3, 'appelle': 1, 'onli': 1, 'complaint': 1, 'can': 5, 'leav': 1, 'person': 2, 'who': 4, 'unwil': 1, 'becom': 1, 'seem': 2, 'fanci': 1, 'refer': 1, 'freedom': 4, 'between': 2, 'putat': 1, 'connecticut': 3, 'while': 1, 'steadfast': 1, 'refus': 1, 'regist': 2, 'a': 14, 'cast': 1, 'vote': 5, 'form': 1, 'more': 4, 'meaning': 1, 'than': 5, 'respond': 1, 'pollster': 1, 'concept': 1, 'extend': 1, 'such': 1, 'casual': 1, 'contact': 1, 'ceas': 1, 'analyt': 1, 'use': 2, 'unit': 1, 'wisconsin': 1, 'ex': 1, 'rel': 1, 'la': 1, 'follett': 1, '450': 1, '107': 1, '130-131': 1, '1981': 1, 'powel': 1, 'j.': 1, '``': 2, 'everi': 1, 'conflict': 1, 'law': 2, 'concern': 1, 'nomin': 3, 'creat': 1, 'burden': 1, \"''\": 2, 'must': 1, 'their': 1, 'own': 1, 'hand': 1, 'unquestion': 1, 'implic': 1, '--': 6, 'hard': 1, 'thought': 2, 'unconstitut': 1, 'entir': 2, 'put': 1, 'forward': 1, 'wish': 2, 'has': 3, 'highest': 1, 'degre': 1, 'support': 2, 'among': 2, 'combin': 1, 'oblig': 1, 'howev': 2, 'let': 1, 'instead': 1, 'party-fund': 1, 'poll': 1, 'mean': 1, 'identifi': 1, 'relat': 1, 'popular': 1, 'potenti': 1, 'reason': 2, 'appar': 1, 'whi': 3, 'insist': 1, 'what': 1, 'might': 1, 'call': 1, 'choic': 4, 'taken': 1, 'membership': 2, 'fashion': 1, 'rather': 2, 'through': 1, 'dilut': 1, 'perhap': 1, 'absolut': 1, 'outnumb': 1, 'outsid': 3, 'character': 2, 'disparag': 1, 'attempt': 1, 'integr': 1, 'against': 2, 'ant': 1, '224.': 1, 'problem': 1, 'less': 1, 'true': 1, 'we': 3, 'have': 3, 'way': 1, 'know': 2, 'major': 3, 'favor': 1, 'allow': 1, 'ultim': 1, 'feder': 1, 'statewid': 1, 'offic': 2, 'determin': 2, 'was': 2, 'made': 1, 'ballot': 1, 'convent': 3, 'all': 1, 'may': 4, 'been': 1, 'domin': 1, 'officehold': 1, 'seeker': 1, 'whose': 1, 'evalu': 1, 'merit': 2, 'vis-a-vi': 1, 'propos': 1, 'faith': 1, 'philosophi': 1, 'diverg': 1, 'signific': 2, 'from': 1, 'rank': 1, 'file': 1, 'had': 1, 'alway': 1, 'purpos': 1, 'state-impos': 2, 'protect': 1, 'general': 1, 'sort': 1, 'minor': 1, 'control': 1, 'nader': 1, 'schaffer': 1, '417': 1, 'f.supp': 1, '837': 1, '843': 1, 'summarili': 1, 'aff': 1, \"'d\": 1, '429': 1, '989': 1, '1976': 1, 'second': 1, 'were': 1, 'want': 2, 'bound': 2, 'honor': 2, 'would': 1, 'express': 1, 'henceforth': 1, 'execut': 2, 'committe': 2, 'smoke-fil': 1, 'room': 1, 'word': 1, 'valid': 1, 'hitherto': 1, 'consid': 1, 'american': 1, 'texa': 1, 'white': 1, '767': 1, '781': 1, 'presuppos': 1, 'element': 1, 'whether': 1, 'beyond': 1, 'understand': 1, 'deleg': 2, 'proscrib': 1, 'nonmemb': 1, 'us': 1, 'said': 1, 'just': 1, 'recommend': 1, 'long': 2, 'name': 2, 'also': 1, 'him': 1, 'plain': 1, 'constitut': 1, 'respect': 1}), defaultdict(<class 'int'>, {'author': 1, 'wjbrennan': 1, 'type': 1, 'dissent': 3, 'dissentbi': 1, 'brennan': 2, 'white': 1, 'marshal': 1, 'justic': 1, 'i': 1, 'would': 1, 'affirm': 1, 'on': 1, 'the': 4, 'ground': 1, 'that': 1, 'challeng': 1, 'classif': 1, 'violat': 1, 'equal': 1, 'protect': 1, 'claus': 1, 'becaus': 1, 'they': 1, 'fail': 1, 'rational-basi': 1, 'test': 1}), defaultdict(<class 'int'>, {'author': 1, 'hablackmun': 1, 'type': 1, 'dissent': 2, 'justic': 4, 'blackmun': 1, 'with': 2, 'whom': 1, 'brennan': 1, 'join': 2, 'i': 4, 'marshal': 2, \"'s\": 3, 'percept': 1, 'and': 3, 'incis': 1, 'opinion': 1, 'reveal': 1, 'great': 3, 'sensit': 1, 'toward': 1, 'those': 2, 'who': 2, 'have': 1, 'suffer': 1, 'the': 16, 'pain': 1, 'of': 10, 'econom': 1, 'discrimin': 3, 'in': 4, 'construct': 1, 'trade': 1, 'for': 1, 'so': 2, 'long': 1, 'never': 2, 'thought': 1, 'that': 4, 'would': 2, 'live': 1, 'to': 4, 'see': 1, 'day': 2, 'when': 1, 'citi': 1, 'richmond': 3, 'virginia': 1, 'cradl': 1, 'old': 1, 'confederaci': 1, 'sought': 1, 'on': 1, 'it': 4, 'own': 1, 'within': 1, 'a': 2, 'narrow': 1, 'confin': 1, 'lessen': 1, 'stark': 1, 'impact': 1, 'persist': 1, 'but': 1, 'credit': 1, 'act': 1, 'yet': 1, 'this': 3, 'court': 2, 'suppos': 1, 'bastion': 1, 'equal': 1, 'strike': 1, 'down': 1, 'effort': 1, 'as': 1, 'though': 3, 'had': 1, 'exist': 1, 'or': 1, 'was': 1, 'not': 1, 'demonstr': 1, 'particular': 1, 'litig': 1, 'convinc': 1, 'disclos': 1, 'fallaci': 1, 'shallow': 1, 'approach': 1, 'histori': 1, 'is': 1, 'irrefut': 1, 'even': 1, 'one': 2, 'might': 1, 'sympath': 1, '--': 3, 'possibl': 1, 'innoc': 1, 'themselv': 1, 'benefit': 1, 'from': 1, 'wrong': 1, 'past': 1, 'decad': 1, 'today': 1, 'regress': 1, 'am': 1, 'confid': 1, 'howev': 1, 'given': 1, 'time': 1, 'again': 1, 'will': 1, 'do': 1, 'best': 1, 'fulfil': 2, 'promis': 1, 'constitut': 1, 'preambl': 1, 'guarante': 1, 'embodi': 1, 'bill': 1, 'right': 1, 'make': 1, 'nation': 1, 'veri': 1, 'special': 1}), defaultdict(<class 'int'>, {'author': 1, 'hablackmun': 1, 'type': 1, 'dissent': 2, 'justic': 4, 'blackmun': 1, 'with': 2, 'whom': 1, 'brennan': 1, 'join': 2, 'i': 4, 'marshal': 2, \"'s\": 3, 'percept': 1, 'and': 3, 'incis': 1, 'opinion': 1, 'reveal': 1, 'great': 3, 'sensit': 1, 'toward': 1, 'those': 2, 'who': 2, 'have': 1, 'suffer': 1, 'the': 16, 'pain': 1, 'of': 10, 'econom': 1, 'discrimin': 3, 'in': 4, 'construct': 1, 'trade': 1, 'for': 1, 'so': 2, 'long': 1, 'never': 2, 'thought': 1, 'that': 4, 'would': 2, 'live': 1, 'to': 4, 'see': 1, 'day': 2, 'when': 1, 'citi': 1, 'richmond': 3, 'virginia': 1, 'cradl': 1, 'old': 1, 'confederaci': 1, 'sought': 1, 'on': 1, 'it': 4, 'own': 1, 'within': 1, 'a': 2, 'narrow': 1, 'confin': 1, 'lessen': 1, 'stark': 1, 'impact': 1, 'persist': 1, 'but': 1, 'credit': 1, 'act': 1, 'yet': 1, 'this': 3, 'court': 2, 'suppos': 1, 'bastion': 1, 'equal': 1, 'strike': 1, 'down': 1, 'effort': 1, 'as': 1, 'though': 3, 'had': 1, 'exist': 1, 'or': 1, 'was': 1, 'not': 1, 'demonstr': 1, 'particular': 1, 'litig': 1, 'convinc': 1, 'disclos': 1, 'fallaci': 1, 'shallow': 1, 'approach': 1, 'histori': 1, 'is': 1, 'irrefut': 1, 'even': 1, 'one': 2, 'might': 1, 'sympath': 1, '--': 3, 'possibl': 1, 'innoc': 1, 'themselv': 1, 'benefit': 1, 'from': 1, 'wrong': 1, 'past': 1, 'decad': 1, 'today': 1, 'regress': 1, 'am': 1, 'confid': 1, 'howev': 1, 'given': 1, 'time': 1, 'again': 1, 'will': 1, 'do': 1, 'best': 1, 'fulfil': 2, 'promis': 1, 'constitut': 1, 'preambl': 1, 'guarante': 1, 'embodi': 1, 'bill': 1, 'right': 1, 'make': 1, 'nation': 1, 'veri': 1, 'special': 1})]\n"
          ]
        }
      ],
      "source": [
        "freqVectors = map(vectorize, strCorpus)\n",
        "print(list(freqVectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frnemoN8mC0v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scikit-Learn\n",
        "\n",
        "CountVectorizer = 自動：\n",
        "\n",
        "- tokenize\n",
        "- lowercase\n",
        "- remove punctuation\n",
        "- build vocabulary\n",
        "- build word-count vectors\n",
        "\n",
        "不需要你自己寫 tokenize 或 vectorize function。"
      ],
      "metadata": {
        "id": "bzoES_AN_y72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2tLtAfBmC0v",
        "outputId": "ce241f18-2e36-4172-c592-fe1bead8fa0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 20)\n",
            "[[1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 2 0 0 0]\n",
            " [0 1 1 1 0 1 0 0 0 0 2 0 1 1 0 0 1 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 2 1 0 1]]\n"
          ]
        }
      ],
      "source": [
        "# Scikit-Learn: 它使用 Scikit-Learn 的 CountVectorizer 來把文字轉換成 Bag-of-Words frequency vectors\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer() # 創建了一個「轉換器物件」\n",
        "toyFreqVectors2 = vectorizer.fit_transform(toyCorpus)\n",
        "#.fit()：讀進 corpus，找到所有出現的 vocabulary\n",
        "#.transform()：把每一篇文件轉成字頻向量\n",
        "\n",
        "print(toyFreqVectors2.shape)\n",
        "print(toyFreqVectors2.toarray())\n",
        "\n",
        "# shape:\n",
        "# 3 篇文件 → 3 rows\n",
        "# 15 個 unique tokens → 15 columns\n",
        "\n",
        "# .toarray → 把稀疏矩陣（sparse matrix）展開成 一般的二維矩陣（ array: list of lists）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIVX7RQ5mC0w",
        "outputId": "a75a2302-758c-4ba7-a60e-3b6b2e97ecc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 587)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 2, 1, 1],\n",
              "       [0, 0, 0, ..., 2, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "freqVectors2 = vectorizer.fit_transform(strCorpus)\n",
        "\n",
        "print(freqVectors2.shape)\n",
        "fvec = freqVectors2.toarray()\n",
        "fvec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Genism: Yet another way to create frequency vectors"
      ],
      "metadata": {
        "id": "rX5l1i6DA19D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx2A3kfBmC0w",
        "outputId": "8f149e09-4858-47ab-c586-3aeec702299c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "! pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJZT0KtfmC0w",
        "outputId": "21a10aa0-d347-426a-f643-3ecb564607ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install scipy\n",
        "! pip install numpy\n",
        "! pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgEiUB4GmC0w"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "\n",
        "tokToyCorpus = [tokenize(doc) for doc in toyCorpus] ## tokenize : u have to use it when using gensim!\n",
        "id2word = gensim.corpora.Dictionary(tokToyCorpus)\n",
        "toyFreqVectors3 = [id2word.doc2bow(doc) for doc in tokToyCorpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLAj-1dvmC0w",
        "outputId": "42257c89-0ec6-49b7-ae82-a804b72c64fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)], [(4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 2), (11, 1)], [(6, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]]\n"
          ]
        }
      ],
      "source": [
        "print(toyFreqVectors3)\n",
        "# 會得到 [(id, freq), (id, freq), ...]\n",
        "\n",
        "#doc1 = ['the','eleph','sneez','at','sight','potato','the']\n",
        "#doc2 = ['bat','can','see','see','the','sight','sneez','bat']\n",
        "#doc3 = ['wonder','she','open','door','to','the','studio']\n",
        "\n",
        "#0: 'the'\n",
        "#1: 'eleph'\n",
        "#2: 'sneez'\n",
        "#3: 'at'\n",
        "#4: 'sight'\n",
        "#5: 'potato'\n",
        "#6: 'bat'\n",
        "# So (6, 2) means: token with ID 6 appears 2 times in that document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOVrFOcPmC0w"
      },
      "outputs": [],
      "source": [
        "tokCorpus = [tokenize(doc) for doc in strCorpus]\n",
        "id2word = gensim.corpora.Dictionary(tokCorpus)\n",
        "freqVectors3 = [id2word.doc2bow(doc) for doc in tokCorpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWpLJJeymC0w"
      },
      "outputs": [],
      "source": [
        "#freqVectors3[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EGc2f-tmC0w",
        "outputId": "417511dc-8b3d-46fe-de78-ea6473edc4a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(freqVectors3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding\n",
        "\n",
        "用一個「二元值」表示是否包含某 token，集合（set）型式的 one-hot label。\n",
        "\n",
        "有些模型（特別是 early neural nets）\n",
        "只需要知道：某個詞是否出現\n",
        "而不需要知道它出現幾次。"
      ],
      "metadata": {
        "id": "VTdrG-BAEPU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NLTK One-Hot Encoding"
      ],
      "metadata": {
        "id": "pqlU6cHbA8j4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cPdzepVmC0w"
      },
      "outputs": [],
      "source": [
        "# NLTK, One-Hot Encoding\n",
        "def vectorizeOH(doc):\n",
        "    return {token: True for token in doc}\n",
        "\n",
        "tokToyCorpus = [tokenize(doc) for doc in toyCorpus]\n",
        "toyOHvectors = map(vectorizeOH, tokToyCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5Fwd-GSmC0w",
        "outputId": "ae863271-eaa7-46df-ef96-4ecf5a524901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'the': True, 'eleph': True, 'sneez': True, 'at': True, 'sight': True, 'of': True, 'potato': True}, {'bat': True, 'can': True, 'see': True, 'via': True, 'echoloc': True, 'the': True, 'sight': True, 'sneez': True}, {'wonder': True, 'she': True, 'open': True, 'the': True, 'door': True, 'to': True, 'studio': True}]\n"
          ]
        }
      ],
      "source": [
        "print(list(toyOHvectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfal8uGWmC0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365ebd57-8928-4a3b-f875-6c3251b072f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'author': True, 'wodougla': True, 'type': True, 'dissent': True, 'dissentbi': True, 'dougla': True, 'mr.': True, 'justic': True, 'with': True, 'whom': True, 'black': True, 'concur': True, 'i': True, 'have': True, 'no': True, 'doubt': True, 'that': True, 'the': True, 'militari': True, 'had': True, 'to': True, 'select': True, 'this': True, 'particular': True, 'properti': True, 'for': True, 'destruct': True, 'but': True, 'whatev': True, 'weight': True, 'of': True, 'may': True, 'be': True, 'believ': True, 'fifth': True, 'amend': True, 'requir': True, 'compens': True, 'take': True, 'was': True, 'destroy': True, 'not': True, 'becaus': True, 'it': True, 'in': True, 'natur': True, 'a': True, 'public': True, 'nuisanc': True, 'deem': True, 'necessari': True, 'help': True, 'win': True, 'war': True, 'as': True, 'clear': True, 'appropri': True, 'end': True, 'anim': True, 'food': True, 'and': True, 'suppli': True, 'requisit': True, 'defens': True, 'effort': True, 'court': True, 'say': True, 'depriv': True, 'enemi': True, 'valuabl': True, 'logist': True, 'weapon': True, 'seem': True, 'me': True, 'guid': True, 'principl': True, 'should': True, 'whenev': True, 'govern': True, 'determin': True, 'one': True, 'person': True, \"'s\": True, '--': True, 'is': True, 'essenti': True, 'common': True, 'good': True, 'purs': True, 'rather': True, 'than': True, 'individu': True, 'bear': True, 'loss': True}, {'author': True, 'wodougla': True, 'type': True, 'dissent': True, 'mr.': True, 'justic': True, 'dougla': True, 'be': True, 'of': True, 'the': True, 'view': True, 'that': True, 'petition': True, 'was': True, 'in': True, 'substanc': True, 'tri': True, 'for': True, 'murder': True, 'twice': True, 'violat': True, 'guarante': True, 'against': True, 'doubl': True, 'jeopardi': True}, {'author': True, 'tmarshal': True, 'type': True, 'dissent': True, 'dissentbi': True, 'marshal': True, 'justic': True, 'i': True, 'continu': True, 'to': True, 'object': True, 'decid': True, 'case': True, 'without': True, 'grant': True, 'either': True, 'parti': True, 'an': True, 'opportun': True, 'argu': True, 'the': True, 'merit': True, 'by': True, 'brief': True, 'or': True, 'oral': True, 'argument': True, 'therefor': True}, {'author': True, 'ascalia': True, 'type': True, 'dissent': True, 'justic': True, 'scalia': True, 'with': True, 'whom': True, 'the': True, 'chief': True, 'and': True, \"o'connor\": True, 'join': True, 'both': True, 'right': True, 'of': True, 'free': True, 'polit': True, 'associ': True, 'state': True, \"'s\": True, 'to': True, 'establish': True, 'arrang': True, 'that': True, 'assur': True, 'fair': True, 'effect': True, 'parti': True, 'particip': True, 'in': True, 'elect': True, 'process': True, 'are': True, 'essenti': True, 'democrat': True, 'govern': True, 'our': True, 'case': True, 'make': True, 'it': True, 'clear': True, 'accommod': True, 'these': True, 'two': True, 'vital': True, 'interest': True, 'doe': True, 'not': True, 'lend': True, 'itself': True, 'bright-lin': True, 'rule': True, 'but': True, 'requir': True, 'care': True, 'inquiri': True, 'into': True, 'extent': True, 'which': True, 'one': True, 'or': True, 'other': True, 'is': True, 'inordin': True, 'impair': True, 'under': True, 'fact': True, 'particular': True, 'see': True, 'anderson': True, 'v.': True, 'celebrezz': True, '460': True, 'u.s.': True, '780': True, '788-790': True, '1983': True, 'storer': True, 'brown': True, '415': True, '724': True, '730': True, '1974': True, 'even': True, 'so': True, 'conclus': True, 'reach': True, 'on': True, 'individu': True, 'shed': True, 'some': True, 'measur': True, 'light': True, 'upon': True, 'will': True, 'be': True, 'next': True, 'sinc': True, 'this': True, 'an': True, 'area': True, 'moreov': True, 'predict': True, 'decis': True, 'import': True, 'i': True, 'think': True, 'worth': True, 'note': True, 'for': True, 'me': True, 'today': True, 'alreadi': True, 'exceed': True, 'permiss': True, 'limit': True, 'first': True, 'amend': True, 'restrict': True, 'order': True, 'my': True, 'view': True, 'court': True, 'opinion': True, 'exagger': True, 'at': True, 'issu': True, 'if': True, 'inde': True, 'where': True, 'none': True, 'exist': True, 'there': True, 'no': True, 'question': True, 'here': True, 'republican': True, 'abil': True, 'recruit': True, 'enrol': True, 'member': True, 'by': True, 'offer': True, 'them': True, 'select': True, 'candid': True, 'conn.': True, 'gen.': True, 'stat': True, '9-56': True, '1985': True, 'permit': True, 'independ': True, 'voter': True, 'as': True, 'late': True, 'day': True, 'befor': True, 'primari': True, 'cf': True, 'kusper': True, 'pontik': True, '414': True, '51': True, '1973': True, 'nor': True, 'ani': True, 'whatev': True, 'they': True, 'desir': True, 'appelle': True, 'onli': True, 'complaint': True, 'can': True, 'leav': True, 'person': True, 'who': True, 'unwil': True, 'becom': True, 'seem': True, 'fanci': True, 'refer': True, 'freedom': True, 'between': True, 'putat': True, 'connecticut': True, 'while': True, 'steadfast': True, 'refus': True, 'regist': True, 'a': True, 'cast': True, 'vote': True, 'form': True, 'more': True, 'meaning': True, 'than': True, 'respond': True, 'pollster': True, 'concept': True, 'extend': True, 'such': True, 'casual': True, 'contact': True, 'ceas': True, 'analyt': True, 'use': True, 'unit': True, 'wisconsin': True, 'ex': True, 'rel': True, 'la': True, 'follett': True, '450': True, '107': True, '130-131': True, '1981': True, 'powel': True, 'j.': True, '``': True, 'everi': True, 'conflict': True, 'law': True, 'concern': True, 'nomin': True, 'creat': True, 'burden': True, \"''\": True, 'must': True, 'their': True, 'own': True, 'hand': True, 'unquestion': True, 'implic': True, '--': True, 'hard': True, 'thought': True, 'unconstitut': True, 'entir': True, 'put': True, 'forward': True, 'wish': True, 'has': True, 'highest': True, 'degre': True, 'support': True, 'among': True, 'combin': True, 'oblig': True, 'howev': True, 'let': True, 'instead': True, 'party-fund': True, 'poll': True, 'mean': True, 'identifi': True, 'relat': True, 'popular': True, 'potenti': True, 'reason': True, 'appar': True, 'whi': True, 'insist': True, 'what': True, 'might': True, 'call': True, 'choic': True, 'taken': True, 'membership': True, 'fashion': True, 'rather': True, 'through': True, 'dilut': True, 'perhap': True, 'absolut': True, 'outnumb': True, 'outsid': True, 'character': True, 'disparag': True, 'attempt': True, 'integr': True, 'against': True, 'ant': True, '224.': True, 'problem': True, 'less': True, 'true': True, 'we': True, 'have': True, 'way': True, 'know': True, 'major': True, 'favor': True, 'allow': True, 'ultim': True, 'feder': True, 'statewid': True, 'offic': True, 'determin': True, 'was': True, 'made': True, 'ballot': True, 'convent': True, 'all': True, 'may': True, 'been': True, 'domin': True, 'officehold': True, 'seeker': True, 'whose': True, 'evalu': True, 'merit': True, 'vis-a-vi': True, 'propos': True, 'faith': True, 'philosophi': True, 'diverg': True, 'signific': True, 'from': True, 'rank': True, 'file': True, 'had': True, 'alway': True, 'purpos': True, 'state-impos': True, 'protect': True, 'general': True, 'sort': True, 'minor': True, 'control': True, 'nader': True, 'schaffer': True, '417': True, 'f.supp': True, '837': True, '843': True, 'summarili': True, 'aff': True, \"'d\": True, '429': True, '989': True, '1976': True, 'second': True, 'were': True, 'want': True, 'bound': True, 'honor': True, 'would': True, 'express': True, 'henceforth': True, 'execut': True, 'committe': True, 'smoke-fil': True, 'room': True, 'word': True, 'valid': True, 'hitherto': True, 'consid': True, 'american': True, 'texa': True, 'white': True, '767': True, '781': True, 'presuppos': True, 'element': True, 'whether': True, 'beyond': True, 'understand': True, 'deleg': True, 'proscrib': True, 'nonmemb': True, 'us': True, 'said': True, 'just': True, 'recommend': True, 'long': True, 'name': True, 'also': True, 'him': True, 'plain': True, 'constitut': True, 'respect': True}, {'author': True, 'wjbrennan': True, 'type': True, 'dissent': True, 'dissentbi': True, 'brennan': True, 'white': True, 'marshal': True, 'justic': True, 'i': True, 'would': True, 'affirm': True, 'on': True, 'the': True, 'ground': True, 'that': True, 'challeng': True, 'classif': True, 'violat': True, 'equal': True, 'protect': True, 'claus': True, 'becaus': True, 'they': True, 'fail': True, 'rational-basi': True, 'test': True}, {'author': True, 'hablackmun': True, 'type': True, 'dissent': True, 'justic': True, 'blackmun': True, 'with': True, 'whom': True, 'brennan': True, 'join': True, 'i': True, 'marshal': True, \"'s\": True, 'percept': True, 'and': True, 'incis': True, 'opinion': True, 'reveal': True, 'great': True, 'sensit': True, 'toward': True, 'those': True, 'who': True, 'have': True, 'suffer': True, 'the': True, 'pain': True, 'of': True, 'econom': True, 'discrimin': True, 'in': True, 'construct': True, 'trade': True, 'for': True, 'so': True, 'long': True, 'never': True, 'thought': True, 'that': True, 'would': True, 'live': True, 'to': True, 'see': True, 'day': True, 'when': True, 'citi': True, 'richmond': True, 'virginia': True, 'cradl': True, 'old': True, 'confederaci': True, 'sought': True, 'on': True, 'it': True, 'own': True, 'within': True, 'a': True, 'narrow': True, 'confin': True, 'lessen': True, 'stark': True, 'impact': True, 'persist': True, 'but': True, 'credit': True, 'act': True, 'yet': True, 'this': True, 'court': True, 'suppos': True, 'bastion': True, 'equal': True, 'strike': True, 'down': True, 'effort': True, 'as': True, 'though': True, 'had': True, 'exist': True, 'or': True, 'was': True, 'not': True, 'demonstr': True, 'particular': True, 'litig': True, 'convinc': True, 'disclos': True, 'fallaci': True, 'shallow': True, 'approach': True, 'histori': True, 'is': True, 'irrefut': True, 'even': True, 'one': True, 'might': True, 'sympath': True, '--': True, 'possibl': True, 'innoc': True, 'themselv': True, 'benefit': True, 'from': True, 'wrong': True, 'past': True, 'decad': True, 'today': True, 'regress': True, 'am': True, 'confid': True, 'howev': True, 'given': True, 'time': True, 'again': True, 'will': True, 'do': True, 'best': True, 'fulfil': True, 'promis': True, 'constitut': True, 'preambl': True, 'guarante': True, 'embodi': True, 'bill': True, 'right': True, 'make': True, 'nation': True, 'veri': True, 'special': True}, {'author': True, 'hablackmun': True, 'type': True, 'dissent': True, 'justic': True, 'blackmun': True, 'with': True, 'whom': True, 'brennan': True, 'join': True, 'i': True, 'marshal': True, \"'s\": True, 'percept': True, 'and': True, 'incis': True, 'opinion': True, 'reveal': True, 'great': True, 'sensit': True, 'toward': True, 'those': True, 'who': True, 'have': True, 'suffer': True, 'the': True, 'pain': True, 'of': True, 'econom': True, 'discrimin': True, 'in': True, 'construct': True, 'trade': True, 'for': True, 'so': True, 'long': True, 'never': True, 'thought': True, 'that': True, 'would': True, 'live': True, 'to': True, 'see': True, 'day': True, 'when': True, 'citi': True, 'richmond': True, 'virginia': True, 'cradl': True, 'old': True, 'confederaci': True, 'sought': True, 'on': True, 'it': True, 'own': True, 'within': True, 'a': True, 'narrow': True, 'confin': True, 'lessen': True, 'stark': True, 'impact': True, 'persist': True, 'but': True, 'credit': True, 'act': True, 'yet': True, 'this': True, 'court': True, 'suppos': True, 'bastion': True, 'equal': True, 'strike': True, 'down': True, 'effort': True, 'as': True, 'though': True, 'had': True, 'exist': True, 'or': True, 'was': True, 'not': True, 'demonstr': True, 'particular': True, 'litig': True, 'convinc': True, 'disclos': True, 'fallaci': True, 'shallow': True, 'approach': True, 'histori': True, 'is': True, 'irrefut': True, 'even': True, 'one': True, 'might': True, 'sympath': True, '--': True, 'possibl': True, 'innoc': True, 'themselv': True, 'benefit': True, 'from': True, 'wrong': True, 'past': True, 'decad': True, 'today': True, 'regress': True, 'am': True, 'confid': True, 'howev': True, 'given': True, 'time': True, 'again': True, 'will': True, 'do': True, 'best': True, 'fulfil': True, 'promis': True, 'constitut': True, 'preambl': True, 'guarante': True, 'embodi': True, 'bill': True, 'right': True, 'make': True, 'nation': True, 'veri': True, 'special': True}]\n"
          ]
        }
      ],
      "source": [
        "tokCorpus = [tokenize(doc) for doc in strCorpus]\n",
        "OHvectors = map(vectorizeOH, tokCorpus)\n",
        "print(list(OHvectors))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scikit-learn, One-Hot Encoding\n",
        "\n",
        "而是把 Bag-of-Words 的「頻率矩陣」轉成「0/1 二值矩陣」"
      ],
      "metadata": {
        "id": "2s3VtODcEI1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0bMVEk0mC0y",
        "outputId": "924ae0a9-bd5f-4467-8b50-fe91b3c6284a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Scikit-learn, One-Hot Encoding\n",
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "# 建立字頻向量（frequency vectors）\n",
        "freq = CountVectorizer()\n",
        "corpus = freq.fit_transform(toyCorpus) # 生一個 Bag-of-Words 矩陣：\n",
        "\n",
        "# 建立 Binarizer 一個函數（把數字全部變 0/1）\n",
        "onehot = Binarizer()\n",
        "# 轉換成一般矩陣\n",
        "onehot.fit_transform(corpus.toarray())\n",
        "\n",
        "## the array is different from above. !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hoonc-05mC0y",
        "outputId": "17a3efa2-7150-4f26-c472-faf5fc7e2354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 1, 1],\n",
              "       [0, 0, 0, ..., 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "freq = CountVectorizer()\n",
        "corpus = freq.fit_transform(strCorpus)\n",
        "onehot = Binarizer()\n",
        "# Leaves the sparse array)\n",
        "OHvectors2 = onehot.fit_transform(corpus)\n",
        "onehot.fit_transform(corpus.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W4DlyuwmC0z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Genism, One-Hot Encoding"
      ],
      "metadata": {
        "id": "0WcCw0DbGTMz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD1wyeiamC0z"
      },
      "outputs": [],
      "source": [
        "# Genism, One-Hot Encoding\n",
        "tokToyCorpus = [tokenize(doc) for doc in toyCorpus] # 它會把每篇文章變成 tokens list：\n",
        "id2word = gensim.corpora.Dictionary(tokToyCorpus) # 建立 gensim dictionary\n",
        "toyOHvectors3 = [\n",
        "    [(token[0], 1) for token in id2word.doc2bow(doc)] # doc2bow = frequency vector（freq encoding）\n",
        "    for doc in tokToyCorpus\n",
        "]\n",
        "\n",
        "# 把 frequency vector 轉成 One-Hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3DcP6T3mC0z"
      },
      "outputs": [],
      "source": [
        "tokCorpus = [tokenize(doc) for doc in strCorpus] # tokenize 每一篇文件\n",
        "id2word = gensim.corpora.Dictionary(tokCorpus) # 建立 gensim 字典（token → id）\n",
        "OHvectors3 = [\n",
        "    [(token[0], 1) for token in id2word.doc2bow(doc)]\n",
        "    for doc in tokCorpus\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ-5KzySmC0z",
        "outputId": "903fb3f2-3d1b-44c1-96b0-f7e286e9946f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(OHvectors3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf-idf"
      ],
      "metadata": {
        "id": "Get4inMVBDwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnS6qWz1mC0z"
      },
      "outputs": [],
      "source": [
        "# NLTK, tf-idf encoding\n",
        "from nltk.text import TextCollection\n",
        "\n",
        "def vectorizeTF(corpus):\n",
        "    corpus = [tokenize(doc) for doc in corpus] # tokenize the corpus\n",
        "    texts = TextCollection(corpus) # TextCollection 是 NLTK 提供的：一個可以計算 tf、idf、tf-idf 的工具，它會讀整個 corpus，計算每個字在整個 corpus 中的 document frequency.\n",
        "\n",
        "    for doc in corpus:\n",
        "        yield {\n",
        "            term: texts.tf_idf(term, doc)\n",
        "            for term in doc\n",
        "        }\n",
        "\n",
        "## one word used a lot across different document, or a word only show up in a few document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-NmIDLymC0z"
      },
      "outputs": [],
      "source": [
        "toyTFvectors = map(vectorizeTF, toyCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaJsj-VgmC0z",
        "outputId": "5ef41120-5e89-41b9-ab2b-90febff5dbc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0:\n",
            "{'the': 0.0, 'eleph': 0.13732653608351372, 'sneez': 0.05068313851352055, 'at': 0.13732653608351372, 'sight': 0.05068313851352055, 'of': 0.13732653608351372, 'potato': 0.13732653608351372}\n",
            "\n",
            "Document 1:\n",
            "{'bat': 0.21972245773362198, 'can': 0.10986122886681099, 'see': 0.21972245773362198, 'via': 0.10986122886681099, 'echoloc': 0.10986122886681099, 'the': 0.0, 'sight': 0.04054651081081644, 'sneez': 0.04054651081081644}\n",
            "\n",
            "Document 2:\n",
            "{'wonder': 0.13732653608351372, 'she': 0.13732653608351372, 'open': 0.13732653608351372, 'the': 0.0, 'door': 0.13732653608351372, 'to': 0.13732653608351372, 'studio': 0.13732653608351372}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "toyTFvectors = list(vectorizeTF(toyCorpus))\n",
        "\n",
        "for i, vec in enumerate(toyTFvectors):\n",
        "    print(f\"Document {i}:\")\n",
        "    print(vec)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KjjpybRmC0z"
      },
      "outputs": [],
      "source": [
        "TFvectors = map(vectorizeTF, strCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-_FHJEFmC0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35eabe4f-3143-4bb7-de8e-67800012c95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0:\n",
            "{'author': 0.0, 'wodougla': 0.007638798588386391, 'type': 0.0, 'dissent': 0.0, 'dissentbi': 0.005166450368214657, 'dougla': 0.015277597176772783, 'mr.': 0.015277597176772783, 'justic': 0.0, 'with': 0.0034122913898501383, 'whom': 0.0034122913898501383, 'black': 0.011865305786922641, 'concur': 0.011865305786922641, 'i': 0.0018798863393568092, 'have': 0.0034122913898501383, 'no': 0.007638798588386391, 'doubt': 0.011865305786922641, 'that': 0.004699715848392023, 'the': 0.0, 'militari': 0.011865305786922641, 'had': 0.0034122913898501383, 'to': 0.010258299896988197, 'select': 0.007638798588386391, 'this': 0.010236874169550414, 'particular': 0.0034122913898501383, 'properti': 0.047461223147690565, 'for': 0.008206639917590559, 'destruct': 0.03559591736076792, 'but': 0.006824582779700277, 'whatev': 0.015277597176772783, 'weight': 0.011865305786922641, 'of': 0.008206639917590559, 'may': 0.015277597176772783, 'be': 0.015499351104643969, 'believ': 0.011865305786922641, 'fifth': 0.011865305786922641, 'amend': 0.007638798588386391, 'requir': 0.007638798588386391, 'compens': 0.011865305786922641, 'take': 0.011865305786922641, 'was': 0.008206639917590559, 'destroy': 0.011865305786922641, 'not': 0.0034122913898501383, 'becaus': 0.015277597176772783, 'it': 0.020473748339100827, 'in': 0.0020516599793976398, 'natur': 0.011865305786922641, 'a': 0.006824582779700277, 'public': 0.023730611573845282, 'nuisanc': 0.011865305786922641, 'deem': 0.011865305786922641, 'necessari': 0.011865305786922641, 'help': 0.011865305786922641, 'win': 0.011865305786922641, 'war': 0.023730611573845282, 'as': 0.010236874169550414, 'clear': 0.007638798588386391, 'appropri': 0.023730611573845282, 'end': 0.011865305786922641, 'anim': 0.011865305786922641, 'food': 0.011865305786922641, 'and': 0.006824582779700277, 'suppli': 0.011865305786922641, 'requisit': 0.011865305786922641, 'defens': 0.011865305786922641, 'effort': 0.010332900736429314, 'court': 0.0034122913898501383, 'say': 0.011865305786922641, 'depriv': 0.011865305786922641, 'enemi': 0.011865305786922641, 'valuabl': 0.011865305786922641, 'logist': 0.011865305786922641, 'weapon': 0.011865305786922641, 'seem': 0.007638798588386391, 'me': 0.007638798588386391, 'guid': 0.011865305786922641, 'principl': 0.011865305786922641, 'should': 0.023730611573845282, 'whenev': 0.011865305786922641, 'govern': 0.007638798588386391, 'determin': 0.007638798588386391, 'one': 0.0034122913898501383, 'person': 0.007638798588386391, \"'s\": 0.0034122913898501383, '--': 0.006824582779700277, 'is': 0.0034122913898501383, 'essenti': 0.007638798588386391, 'common': 0.011865305786922641, 'good': 0.011865305786922641, 'purs': 0.011865305786922641, 'rather': 0.007638798588386391, 'than': 0.007638798588386391, 'individu': 0.007638798588386391, 'bear': 0.011865305786922641, 'loss': 0.011865305786922641}\n",
            "\n",
            "Document 1:\n",
            "{'author': 0.0, 'wodougla': 0.043198723051564414, 'type': 0.0, 'dissent': 0.0, 'mr.': 0.043198723051564414, 'justic': 0.0, 'dougla': 0.043198723051564414, 'be': 0.02921716759955875, 'of': 0.023204981835945715, 'the': 0.0, 'view': 0.043198723051564414, 'that': 0.005315540683698564, 'petition': 0.06710034996742459, 'was': 0.011602490917972857, 'in': 0.023204981835945715, 'substanc': 0.06710034996742459, 'tri': 0.06710034996742459, 'for': 0.011602490917972857, 'murder': 0.06710034996742459, 'twice': 0.06710034996742459, 'violat': 0.043198723051564414, 'guarante': 0.02921716759955875, 'against': 0.043198723051564414, 'doubl': 0.06710034996742459, 'jeopardi': 0.06710034996742459}\n",
            "\n",
            "Document 2:\n",
            "{'author': 0.0, 'tmarshal': 0.052592166190684145, 'type': 0.0, 'dissent': 0.0, 'dissentbi': 0.022899942172627127, 'marshal': 0.030249502050563388, 'justic': 0.0, 'i': 0.008332469179851804, 'continu': 0.052592166190684145, 'to': 0.036375376932023015, 'object': 0.052592166190684145, 'decid': 0.052592166190684145, 'case': 0.03385845860798292, 'without': 0.052592166190684145, 'grant': 0.052592166190684145, 'either': 0.10518433238136829, 'parti': 0.03385845860798292, 'an': 0.03385845860798292, 'opportun': 0.052592166190684145, 'argu': 0.052592166190684145, 'the': 0.0, 'merit': 0.03385845860798292, 'by': 0.03385845860798292, 'brief': 0.052592166190684145, 'or': 0.015124751025281694, 'oral': 0.052592166190684145, 'argument': 0.052592166190684145, 'therefor': 0.052592166190684145}\n",
            "\n",
            "Document 3:\n",
            "{'author': 0.0, 'ascalia': 0.0018585579265093727, 'type': 0.0, 'dissent': 0.0, 'justic': 0.0, 'scalia': 0.0018585579265093727, 'with': 0.001603483633052787, 'whom': 0.000534494544350929, 'the': 0.0, 'chief': 0.0018585579265093727, 'and': 0.008017418165263935, \"o'connor\": 0.0018585579265093727, 'join': 0.0016185250437195868, 'both': 0.0018585579265093727, 'right': 0.00242778756557938, 'of': 0.01478292539118987, 'free': 0.0037171158530187455, 'polit': 0.0037171158530187455, 'associ': 0.011151347559056236, 'state': 0.016727021338584353, \"'s\": 0.008551912709614863, 'to': 0.010605142128462298, 'establish': 0.0018585579265093727, 'arrang': 0.0018585579265093727, 'that': 0.003239078277172573, 'assur': 0.0037171158530187455, 'fair': 0.0018585579265093727, 'effect': 0.0018585579265093727, 'parti': 0.04546799694634574, 'particip': 0.0037171158530187455, 'in': 0.0041777832627275715, 'elect': 0.007434231706037491, 'process': 0.007434231706037491, 'are': 0.007434231706037491, 'essenti': 0.001196526235430151, 'democrat': 0.0204441371916031, 'govern': 0.001196526235430151, 'our': 0.0018585579265093727, 'case': 0.004786104941720604, 'make': 0.0008092625218597934, 'it': 0.012827869064422296, 'clear': 0.001196526235430151, 'accommod': 0.0018585579265093727, 'these': 0.0018585579265093727, 'two': 0.0037171158530187455, 'vital': 0.0018585579265093727, 'interest': 0.007434231706037491, 'doe': 0.005575673779528118, 'not': 0.0048104508991583615, 'lend': 0.0018585579265093727, 'itself': 0.005575673779528118, 'bright-lin': 0.0018585579265093727, 'rule': 0.0037171158530187455, 'but': 0.002137978177403716, 'requir': 0.004786104941720604, 'care': 0.0018585579265093727, 'inquiri': 0.0018585579265093727, 'into': 0.0018585579265093727, 'extent': 0.0018585579265093727, 'which': 0.009292789632546865, 'one': 0.002137978177403716, 'or': 0.002137978177403716, 'other': 0.005575673779528118, 'is': 0.009086407253965792, 'inordin': 0.0018585579265093727, 'impair': 0.0037171158530187455, 'under': 0.0037171158530187455, 'fact': 0.007434231706037491, 'particular': 0.000534494544350929, 'see': 0.0032370500874391735, 'anderson': 0.0018585579265093727, 'v.': 0.011151347559056236, 'celebrezz': 0.0018585579265093727, '460': 0.0018585579265093727, 'u.s.': 0.011151347559056236, '780': 0.0018585579265093727, '788-790': 0.0018585579265093727, '1983': 0.0018585579265093727, 'storer': 0.0018585579265093727, 'brown': 0.0018585579265093727, '415': 0.0037171158530187455, '724': 0.0018585579265093727, '730': 0.0018585579265093727, '1974': 0.0037171158530187455, 'even': 0.00242778756557938, 'so': 0.0032370500874391735, 'conclus': 0.0037171158530187455, 'reach': 0.0037171158530187455, 'on': 0.002137978177403716, 'individu': 0.002393052470860302, 'shed': 0.0018585579265093727, 'some': 0.0018585579265093727, 'measur': 0.0018585579265093727, 'light': 0.0018585579265093727, 'upon': 0.0037171158530187455, 'will': 0.0008092625218597934, 'be': 0.010520412784177313, 'next': 0.0018585579265093727, 'sinc': 0.0018585579265093727, 'this': 0.0037414618104565033, 'an': 0.0071791574125809055, 'area': 0.0018585579265093727, 'moreov': 0.0018585579265093727, 'predict': 0.0018585579265093727, 'decis': 0.007434231706037491, 'import': 0.007434231706037491, 'i': 0.0004416924923417145, 'think': 0.0018585579265093727, 'worth': 0.0018585579265093727, 'note': 0.0018585579265093727, 'for': 0.0009641038298602089, 'me': 0.004786104941720604, 'today': 0.0008092625218597934, 'alreadi': 0.0018585579265093727, 'exceed': 0.0018585579265093727, 'permiss': 0.0018585579265093727, 'limit': 0.0018585579265093727, 'first': 0.0037171158530187455, 'amend': 0.001196526235430151, 'restrict': 0.005575673779528118, 'order': 0.0018585579265093727, 'my': 0.0037171158530187455, 'view': 0.002393052470860302, 'court': 0.001068989088701858, 'opinion': 0.00242778756557938, 'exagger': 0.0018585579265093727, 'at': 0.0037171158530187455, 'issu': 0.0018585579265093727, 'if': 0.009292789632546865, 'inde': 0.0018585579265093727, 'where': 0.0018585579265093727, 'none': 0.0018585579265093727, 'exist': 0.0008092625218597934, 'there': 0.009292789632546865, 'no': 0.0071791574125809055, 'question': 0.005575673779528118, 'here': 0.0037171158530187455, 'republican': 0.016727021338584353, 'abil': 0.007434231706037491, 'recruit': 0.0018585579265093727, 'enrol': 0.0018585579265093727, 'member': 0.022302695118112472, 'by': 0.019144419766882415, 'offer': 0.0018585579265093727, 'them': 0.0018585579265093727, 'select': 0.009572209883441207, 'candid': 0.024161253044621845, 'conn.': 0.0037171158530187455, 'gen.': 0.0018585579265093727, 'stat': 0.0018585579265093727, '9-56': 0.0018585579265093727, '1985': 0.0018585579265093727, 'permit': 0.0037171158530187455, 'independ': 0.013009905485565609, 'voter': 0.005575673779528118, 'as': 0.0048104508991583615, 'late': 0.0018585579265093727, 'day': 0.0008092625218597934, 'befor': 0.0037171158530187455, 'primari': 0.011151347559056236, 'cf': 0.0018585579265093727, 'kusper': 0.0018585579265093727, 'pontik': 0.0018585579265093727, '414': 0.0018585579265093727, '51': 0.0018585579265093727, '1973': 0.0018585579265093727, 'nor': 0.0037171158530187455, 'ani': 0.007434231706037491, 'whatev': 0.001196526235430151, 'they': 0.001196526235430151, 'desir': 0.005575673779528118, 'appelle': 0.0018585579265093727, 'onli': 0.0018585579265093727, 'complaint': 0.0018585579265093727, 'can': 0.009292789632546865, 'leav': 0.0018585579265093727, 'person': 0.002393052470860302, 'who': 0.0032370500874391735, 'unwil': 0.0018585579265093727, 'becom': 0.0018585579265093727, 'seem': 0.002393052470860302, 'fanci': 0.0018585579265093727, 'refer': 0.0018585579265093727, 'freedom': 0.007434231706037491, 'between': 0.0037171158530187455, 'putat': 0.0018585579265093727, 'connecticut': 0.005575673779528118, 'while': 0.0018585579265093727, 'steadfast': 0.0018585579265093727, 'refus': 0.0018585579265093727, 'regist': 0.0037171158530187455, 'a': 0.007482923620913007, 'cast': 0.0018585579265093727, 'vote': 0.009292789632546865, 'form': 0.0018585579265093727, 'more': 0.007434231706037491, 'meaning': 0.0018585579265093727, 'than': 0.005982631177150755, 'respond': 0.0018585579265093727, 'pollster': 0.0018585579265093727, 'concept': 0.0018585579265093727, 'extend': 0.0018585579265093727, 'such': 0.0018585579265093727, 'casual': 0.0018585579265093727, 'contact': 0.0018585579265093727, 'ceas': 0.0018585579265093727, 'analyt': 0.0018585579265093727, 'use': 0.0037171158530187455, 'unit': 0.0018585579265093727, 'wisconsin': 0.0018585579265093727, 'ex': 0.0018585579265093727, 'rel': 0.0018585579265093727, 'la': 0.0018585579265093727, 'follett': 0.0018585579265093727, '450': 0.0018585579265093727, '107': 0.0018585579265093727, '130-131': 0.0018585579265093727, '1981': 0.0018585579265093727, 'powel': 0.0018585579265093727, 'j.': 0.0018585579265093727, '``': 0.0037171158530187455, 'everi': 0.0018585579265093727, 'conflict': 0.0018585579265093727, 'law': 0.0037171158530187455, 'concern': 0.0018585579265093727, 'nomin': 0.005575673779528118, 'creat': 0.0018585579265093727, 'burden': 0.0018585579265093727, \"''\": 0.0037171158530187455, 'must': 0.0018585579265093727, 'their': 0.0018585579265093727, 'own': 0.0008092625218597934, 'hand': 0.0018585579265093727, 'unquestion': 0.0018585579265093727, 'implic': 0.0018585579265093727, '--': 0.003206967266105574, 'hard': 0.0018585579265093727, 'thought': 0.0016185250437195868, 'unconstitut': 0.0018585579265093727, 'entir': 0.0037171158530187455, 'put': 0.0018585579265093727, 'forward': 0.0018585579265093727, 'wish': 0.0037171158530187455, 'has': 0.005575673779528118, 'highest': 0.0018585579265093727, 'degre': 0.0018585579265093727, 'support': 0.0037171158530187455, 'among': 0.0037171158530187455, 'combin': 0.0018585579265093727, 'oblig': 0.0018585579265093727, 'howev': 0.0016185250437195868, 'let': 0.0018585579265093727, 'instead': 0.0018585579265093727, 'party-fund': 0.0018585579265093727, 'poll': 0.0018585579265093727, 'mean': 0.0018585579265093727, 'identifi': 0.0018585579265093727, 'relat': 0.0018585579265093727, 'popular': 0.0018585579265093727, 'potenti': 0.0018585579265093727, 'reason': 0.0037171158530187455, 'appar': 0.0018585579265093727, 'whi': 0.005575673779528118, 'insist': 0.0018585579265093727, 'what': 0.0018585579265093727, 'might': 0.0008092625218597934, 'call': 0.0018585579265093727, 'choic': 0.007434231706037491, 'taken': 0.0018585579265093727, 'membership': 0.0037171158530187455, 'fashion': 0.0018585579265093727, 'rather': 0.002393052470860302, 'through': 0.0018585579265093727, 'dilut': 0.0018585579265093727, 'perhap': 0.0018585579265093727, 'absolut': 0.0018585579265093727, 'outnumb': 0.0018585579265093727, 'outsid': 0.005575673779528118, 'character': 0.0037171158530187455, 'disparag': 0.0018585579265093727, 'attempt': 0.0018585579265093727, 'integr': 0.0018585579265093727, 'against': 0.002393052470860302, 'ant': 0.0018585579265093727, '224.': 0.0018585579265093727, 'problem': 0.0018585579265093727, 'less': 0.0018585579265093727, 'true': 0.0018585579265093727, 'we': 0.005575673779528118, 'have': 0.001603483633052787, 'way': 0.0018585579265093727, 'know': 0.0037171158530187455, 'major': 0.005575673779528118, 'favor': 0.0018585579265093727, 'allow': 0.0018585579265093727, 'ultim': 0.0018585579265093727, 'feder': 0.0018585579265093727, 'statewid': 0.0018585579265093727, 'offic': 0.0037171158530187455, 'determin': 0.002393052470860302, 'was': 0.0006427358865734726, 'made': 0.0018585579265093727, 'ballot': 0.0018585579265093727, 'convent': 0.005575673779528118, 'all': 0.0018585579265093727, 'may': 0.004786104941720604, 'been': 0.0018585579265093727, 'domin': 0.0018585579265093727, 'officehold': 0.0018585579265093727, 'seeker': 0.0018585579265093727, 'whose': 0.0018585579265093727, 'evalu': 0.0018585579265093727, 'merit': 0.002393052470860302, 'vis-a-vi': 0.0018585579265093727, 'propos': 0.0018585579265093727, 'faith': 0.0018585579265093727, 'philosophi': 0.0018585579265093727, 'diverg': 0.0018585579265093727, 'signific': 0.0037171158530187455, 'from': 0.0008092625218597934, 'rank': 0.0018585579265093727, 'file': 0.0018585579265093727, 'had': 0.000534494544350929, 'alway': 0.0018585579265093727, 'purpos': 0.0018585579265093727, 'state-impos': 0.0037171158530187455, 'protect': 0.001196526235430151, 'general': 0.0018585579265093727, 'sort': 0.0018585579265093727, 'minor': 0.0018585579265093727, 'control': 0.0018585579265093727, 'nader': 0.0018585579265093727, 'schaffer': 0.0018585579265093727, '417': 0.0018585579265093727, 'f.supp': 0.0018585579265093727, '837': 0.0018585579265093727, '843': 0.0018585579265093727, 'summarili': 0.0018585579265093727, 'aff': 0.0018585579265093727, \"'d\": 0.0018585579265093727, '429': 0.0018585579265093727, '989': 0.0018585579265093727, '1976': 0.0018585579265093727, 'second': 0.0018585579265093727, 'were': 0.0018585579265093727, 'want': 0.0037171158530187455, 'bound': 0.0037171158530187455, 'honor': 0.0037171158530187455, 'would': 0.000534494544350929, 'express': 0.0018585579265093727, 'henceforth': 0.0018585579265093727, 'execut': 0.0037171158530187455, 'committe': 0.0037171158530187455, 'smoke-fil': 0.0018585579265093727, 'room': 0.0018585579265093727, 'word': 0.0018585579265093727, 'valid': 0.0018585579265093727, 'hitherto': 0.0018585579265093727, 'consid': 0.0018585579265093727, 'american': 0.0018585579265093727, 'texa': 0.0018585579265093727, 'white': 0.001196526235430151, '767': 0.0018585579265093727, '781': 0.0018585579265093727, 'presuppos': 0.0018585579265093727, 'element': 0.0018585579265093727, 'whether': 0.0018585579265093727, 'beyond': 0.0018585579265093727, 'understand': 0.0018585579265093727, 'deleg': 0.0037171158530187455, 'proscrib': 0.0018585579265093727, 'nonmemb': 0.0018585579265093727, 'us': 0.0018585579265093727, 'said': 0.0018585579265093727, 'just': 0.0018585579265093727, 'recommend': 0.0018585579265093727, 'long': 0.0016185250437195868, 'name': 0.0037171158530187455, 'also': 0.0018585579265093727, 'him': 0.0018585579265093727, 'plain': 0.0018585579265093727, 'constitut': 0.0008092625218597934, 'respect': 0.0018585579265093727}\n",
            "\n",
            "Document 4:\n",
            "{'author': 0.0, 'wjbrennan': 0.058966974213797374, 'type': 0.0, 'dissent': 0.0, 'dissentbi': 0.025675692739006172, 'brennan': 0.051351385478012344, 'white': 0.03796251419682933, 'marshal': 0.016958054179861293, 'justic': 0.0, 'i': 0.004671232722038132, 'would': 0.016958054179861293, 'affirm': 0.058966974213797374, 'on': 0.016958054179861293, 'the': 0.0, 'ground': 0.058966974213797374, 'that': 0.004671232722038132, 'challeng': 0.058966974213797374, 'classif': 0.058966974213797374, 'violat': 0.03796251419682933, 'equal': 0.025675692739006172, 'protect': 0.03796251419682933, 'claus': 0.058966974213797374, 'becaus': 0.03796251419682933, 'they': 0.03796251419682933, 'fail': 0.058966974213797374, 'rational-basi': 0.058966974213797374, 'test': 0.058966974213797374}\n",
            "\n",
            "Document 5:\n",
            "{'author': 0.0, 'hablackmun': 0.00623265158455407, 'type': 0.0, 'dissent': 0.0, 'justic': 0.0, 'blackmun': 0.00623265158455407, 'with': 0.005568316297864902, 'whom': 0.002784158148932451, 'brennan': 0.004215412240732357, 'join': 0.008430824481464714, 'i': 0.0030676752204429523, 'marshal': 0.005568316297864902, \"'s\": 0.008352474446797353, 'percept': 0.00623265158455407, 'and': 0.008352474446797353, 'incis': 0.00623265158455407, 'opinion': 0.004215412240732357, 'reveal': 0.00623265158455407, 'great': 0.01869795475366221, 'sensit': 0.00623265158455407, 'toward': 0.00623265158455407, 'those': 0.01246530316910814, 'who': 0.008430824481464714, 'have': 0.002784158148932451, 'suffer': 0.00623265158455407, 'the': 0.0, 'pain': 0.00623265158455407, 'of': 0.016739912269712085, 'econom': 0.00623265158455407, 'discrimin': 0.01869795475366221, 'in': 0.006695964907884834, 'construct': 0.00623265158455407, 'trade': 0.00623265158455407, 'for': 0.0016739912269712084, 'so': 0.008430824481464714, 'long': 0.004215412240732357, 'never': 0.01246530316910814, 'thought': 0.004215412240732357, 'that': 0.0030676752204429523, 'would': 0.005568316297864902, 'live': 0.00623265158455407, 'to': 0.006695964907884834, 'see': 0.004215412240732357, 'day': 0.008430824481464714, 'when': 0.00623265158455407, 'citi': 0.00623265158455407, 'richmond': 0.01869795475366221, 'virginia': 0.00623265158455407, 'cradl': 0.00623265158455407, 'old': 0.00623265158455407, 'confederaci': 0.00623265158455407, 'sought': 0.00623265158455407, 'on': 0.002784158148932451, 'it': 0.011136632595729805, 'own': 0.004215412240732357, 'within': 0.00623265158455407, 'a': 0.005568316297864902, 'narrow': 0.00623265158455407, 'confin': 0.00623265158455407, 'lessen': 0.00623265158455407, 'stark': 0.00623265158455407, 'impact': 0.00623265158455407, 'persist': 0.00623265158455407, 'but': 0.002784158148932451, 'credit': 0.00623265158455407, 'act': 0.00623265158455407, 'yet': 0.00623265158455407, 'this': 0.008352474446797353, 'court': 0.005568316297864902, 'suppos': 0.00623265158455407, 'bastion': 0.00623265158455407, 'equal': 0.004215412240732357, 'strike': 0.00623265158455407, 'down': 0.00623265158455407, 'effort': 0.004215412240732357, 'as': 0.002784158148932451, 'though': 0.01869795475366221, 'had': 0.002784158148932451, 'exist': 0.004215412240732357, 'or': 0.002784158148932451, 'was': 0.0016739912269712084, 'not': 0.002784158148932451, 'demonstr': 0.00623265158455407, 'particular': 0.002784158148932451, 'litig': 0.00623265158455407, 'convinc': 0.00623265158455407, 'disclos': 0.00623265158455407, 'fallaci': 0.00623265158455407, 'shallow': 0.00623265158455407, 'approach': 0.00623265158455407, 'histori': 0.00623265158455407, 'is': 0.002784158148932451, 'irrefut': 0.00623265158455407, 'even': 0.004215412240732357, 'one': 0.005568316297864902, 'might': 0.004215412240732357, 'sympath': 0.00623265158455407, '--': 0.008352474446797353, 'possibl': 0.00623265158455407, 'innoc': 0.00623265158455407, 'themselv': 0.00623265158455407, 'benefit': 0.00623265158455407, 'from': 0.004215412240732357, 'wrong': 0.00623265158455407, 'past': 0.00623265158455407, 'decad': 0.00623265158455407, 'today': 0.004215412240732357, 'regress': 0.00623265158455407, 'am': 0.00623265158455407, 'confid': 0.00623265158455407, 'howev': 0.004215412240732357, 'given': 0.00623265158455407, 'time': 0.00623265158455407, 'again': 0.00623265158455407, 'will': 0.004215412240732357, 'do': 0.00623265158455407, 'best': 0.00623265158455407, 'fulfil': 0.01246530316910814, 'promis': 0.00623265158455407, 'constitut': 0.004215412240732357, 'preambl': 0.00623265158455407, 'guarante': 0.004215412240732357, 'embodi': 0.00623265158455407, 'bill': 0.00623265158455407, 'right': 0.004215412240732357, 'make': 0.004215412240732357, 'nation': 0.00623265158455407, 'veri': 0.00623265158455407, 'special': 0.00623265158455407}\n",
            "\n",
            "Document 6:\n",
            "{'author': 0.0, 'hablackmun': 0.00623265158455407, 'type': 0.0, 'dissent': 0.0, 'justic': 0.0, 'blackmun': 0.00623265158455407, 'with': 0.005568316297864902, 'whom': 0.002784158148932451, 'brennan': 0.004215412240732357, 'join': 0.008430824481464714, 'i': 0.0030676752204429523, 'marshal': 0.005568316297864902, \"'s\": 0.008352474446797353, 'percept': 0.00623265158455407, 'and': 0.008352474446797353, 'incis': 0.00623265158455407, 'opinion': 0.004215412240732357, 'reveal': 0.00623265158455407, 'great': 0.01869795475366221, 'sensit': 0.00623265158455407, 'toward': 0.00623265158455407, 'those': 0.01246530316910814, 'who': 0.008430824481464714, 'have': 0.002784158148932451, 'suffer': 0.00623265158455407, 'the': 0.0, 'pain': 0.00623265158455407, 'of': 0.016739912269712085, 'econom': 0.00623265158455407, 'discrimin': 0.01869795475366221, 'in': 0.006695964907884834, 'construct': 0.00623265158455407, 'trade': 0.00623265158455407, 'for': 0.0016739912269712084, 'so': 0.008430824481464714, 'long': 0.004215412240732357, 'never': 0.01246530316910814, 'thought': 0.004215412240732357, 'that': 0.0030676752204429523, 'would': 0.005568316297864902, 'live': 0.00623265158455407, 'to': 0.006695964907884834, 'see': 0.004215412240732357, 'day': 0.008430824481464714, 'when': 0.00623265158455407, 'citi': 0.00623265158455407, 'richmond': 0.01869795475366221, 'virginia': 0.00623265158455407, 'cradl': 0.00623265158455407, 'old': 0.00623265158455407, 'confederaci': 0.00623265158455407, 'sought': 0.00623265158455407, 'on': 0.002784158148932451, 'it': 0.011136632595729805, 'own': 0.004215412240732357, 'within': 0.00623265158455407, 'a': 0.005568316297864902, 'narrow': 0.00623265158455407, 'confin': 0.00623265158455407, 'lessen': 0.00623265158455407, 'stark': 0.00623265158455407, 'impact': 0.00623265158455407, 'persist': 0.00623265158455407, 'but': 0.002784158148932451, 'credit': 0.00623265158455407, 'act': 0.00623265158455407, 'yet': 0.00623265158455407, 'this': 0.008352474446797353, 'court': 0.005568316297864902, 'suppos': 0.00623265158455407, 'bastion': 0.00623265158455407, 'equal': 0.004215412240732357, 'strike': 0.00623265158455407, 'down': 0.00623265158455407, 'effort': 0.004215412240732357, 'as': 0.002784158148932451, 'though': 0.01869795475366221, 'had': 0.002784158148932451, 'exist': 0.004215412240732357, 'or': 0.002784158148932451, 'was': 0.0016739912269712084, 'not': 0.002784158148932451, 'demonstr': 0.00623265158455407, 'particular': 0.002784158148932451, 'litig': 0.00623265158455407, 'convinc': 0.00623265158455407, 'disclos': 0.00623265158455407, 'fallaci': 0.00623265158455407, 'shallow': 0.00623265158455407, 'approach': 0.00623265158455407, 'histori': 0.00623265158455407, 'is': 0.002784158148932451, 'irrefut': 0.00623265158455407, 'even': 0.004215412240732357, 'one': 0.005568316297864902, 'might': 0.004215412240732357, 'sympath': 0.00623265158455407, '--': 0.008352474446797353, 'possibl': 0.00623265158455407, 'innoc': 0.00623265158455407, 'themselv': 0.00623265158455407, 'benefit': 0.00623265158455407, 'from': 0.004215412240732357, 'wrong': 0.00623265158455407, 'past': 0.00623265158455407, 'decad': 0.00623265158455407, 'today': 0.004215412240732357, 'regress': 0.00623265158455407, 'am': 0.00623265158455407, 'confid': 0.00623265158455407, 'howev': 0.004215412240732357, 'given': 0.00623265158455407, 'time': 0.00623265158455407, 'again': 0.00623265158455407, 'will': 0.004215412240732357, 'do': 0.00623265158455407, 'best': 0.00623265158455407, 'fulfil': 0.01246530316910814, 'promis': 0.00623265158455407, 'constitut': 0.004215412240732357, 'preambl': 0.00623265158455407, 'guarante': 0.004215412240732357, 'embodi': 0.00623265158455407, 'bill': 0.00623265158455407, 'right': 0.004215412240732357, 'make': 0.004215412240732357, 'nation': 0.00623265158455407, 'veri': 0.00623265158455407, 'special': 0.00623265158455407}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "TFvectors = list(vectorizeTF(strCorpus))\n",
        "\n",
        "for i, vec in enumerate(TFvectors):\n",
        "    print(f\"Document {i}:\")\n",
        "    print(vec)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scikit-Learn, tf-idf encoding"
      ],
      "metadata": {
        "id": "05JQU58XbCuh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XZ07-rhmC0z"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn, tf-idf encoding\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "toyTFvectors2 = tfidf.fit_transform(toyCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFLuKbuYmC00",
        "outputId": "2cc7710a-1038-4b96-b585-0d793dcd40e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 23 stored elements and shape (3, 20)>\n",
            "  Coords\tValues\n",
            "  (0, 16)\t0.44730460893892116\n",
            "  (0, 6)\t0.37867626873820165\n",
            "  (0, 14)\t0.37867626873820165\n",
            "  (0, 0)\t0.37867626873820165\n",
            "  (0, 12)\t0.28799306292785165\n",
            "  (0, 7)\t0.37867626873820165\n",
            "  (0, 9)\t0.37867626873820165\n",
            "  (1, 16)\t0.1786694534059618\n",
            "  (1, 12)\t0.23006945204561577\n",
            "  (1, 2)\t0.30251368128649075\n",
            "  (1, 3)\t0.30251368128649075\n",
            "  (1, 10)\t0.6050273625729815\n",
            "  (1, 18)\t0.30251368128649075\n",
            "  (1, 5)\t0.30251368128649075\n",
            "  (1, 1)\t0.30251368128649075\n",
            "  (1, 13)\t0.30251368128649075\n",
            "  (2, 16)\t0.4343672818844283\n",
            "  (2, 19)\t0.3677238693250534\n",
            "  (2, 11)\t0.3677238693250534\n",
            "  (2, 8)\t0.3677238693250534\n",
            "  (2, 4)\t0.3677238693250534\n",
            "  (2, 17)\t0.3677238693250534\n",
            "  (2, 15)\t0.3677238693250534\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "print(toyTFvectors2)\n",
        "toyTFvectors2.shape\n",
        "\n",
        "# 結果是該字在 Document 0 的 TF-IDF 分數。\n",
        "# 位置\t意義\n",
        "# 0\t第 0 份文件（Document 0）\n",
        "# 16\t字典中 index = 16 的那個 token\n",
        "# 0.4473\t該文件的該 token 的 TF-IDF 分數\n",
        "\n",
        "# 該字在所有文件中是否常見？越罕見，分數越高。\n",
        "# TF × IDF = TF-IDF_final score\n",
        "# 像是\"the\" 在 三份文件都出現，所以它的 IDF 很接近 0。（越多人用的字 → 越不重要 → IDF 越低）\n",
        "# 算式 IDF(the) = log(N / df(the)) = log(3/3) = log(1) = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1NzlHuCmC00"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "TFvectors2 = tfidf.fit_transform(strCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orqDdViUmC00",
        "outputId": "36bfd571-0f94-4cbb-e9ea-4e7ec08e8607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 587)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "TFvectors2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbJvzaWjmC00"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### genism, tf-idf encoding"
      ],
      "metadata": {
        "id": "WyeTvVzkeHyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVViqQ8mmC00"
      },
      "outputs": [],
      "source": [
        "# genism, tf-idf encoding\n",
        "tokToyCorpus = [tokenize(doc) for doc in toyCorpus]\n",
        "lexicon = gensim.corpora.Dictionary(tokToyCorpus)\n",
        "tfidf = gensim.models.TfidfModel(dictionary=lexicon, normalize=True)\n",
        "toyTFvectors3 = [tfidf[lexicon.doc2bow(doc)] for doc in tokToyCorpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8YZIgPamC00",
        "outputId": "8418037d-2aab-410a-ff28-71ee36b4b783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, np.float64(0.4837965208957426)), (1, np.float64(0.4837965208957426)), (2, np.float64(0.4837965208957426)), (3, np.float64(0.4837965208957426)), (4, np.float64(0.17855490118826325)), (5, np.float64(0.17855490118826325))], [(4, np.float64(0.10992597952954358)), (5, np.float64(0.10992597952954358)), (7, np.float64(0.5956913654963344)), (8, np.float64(0.2978456827481672)), (9, np.float64(0.2978456827481672)), (10, np.float64(0.5956913654963344)), (11, np.float64(0.2978456827481672))], [(12, np.float64(0.408248290463863)), (13, np.float64(0.408248290463863)), (14, np.float64(0.408248290463863)), (15, np.float64(0.408248290463863)), (16, np.float64(0.408248290463863)), (17, np.float64(0.408248290463863))]]\n"
          ]
        }
      ],
      "source": [
        "print(toyTFvectors3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI8u8Jx_mC00"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distributed Representation\n",
        "\n",
        "\n",
        "TF, TF-IDF, BOW\tSparse（稀疏）、超大維度、90% 是 0\n",
        "- TF-IDF 是：[(3, 0.44), (26, 0.21), (88, 0.87), ...] （稀疏）\n",
        "\n",
        "Doc2Vec\tDense（密集）、低維度、沒有 0\n",
        "- Doc2Vec 得到的向量看起來像：[-0.13, 0.87, 0.05, -0.42, ...] （例如 100 維）\n",
        "- Doc2Vec 可理解語意（semantic representation）\n",
        "\n",
        "\n",
        "\n",
        "TF-IDF / BOW 只能比較哪些字出現一樣。如果字不重複就完全無法比較\n",
        "\n",
        "Doc2Vec 即使字完全不一樣，只要語意接近，向量相似度（cosine similarity）會靠近。這是分散式語意的強大之處。"
      ],
      "metadata": {
        "id": "FkoDIxe0BJ1Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58RIWZwTmC00",
        "outputId": "468e5a38-4a50-4921-f38f-c3bbca102b61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-5.2559674e-03 -5.9936498e-03 -9.9146254e-03  8.5665295e-03\n",
            "  3.5847796e-03  2.6267971e-04 -9.8911952e-03 -5.1613934e-03\n",
            " -9.7270506e-03  2.0224657e-03  2.8346470e-03  4.6406458e-03\n",
            " -4.3243794e-03 -3.1749432e-03 -3.0726346e-03 -8.7502059e-03\n",
            "  2.1682635e-03  9.2512239e-03 -9.5137712e-03 -3.4688634e-03\n",
            " -3.7633737e-03  2.6175780e-03 -5.7026939e-03  2.6463985e-03\n",
            "  5.7865707e-03 -8.1161438e-03 -8.3585950e-03 -9.9731311e-03\n",
            "  4.9417545e-03 -9.1574620e-03  5.8580614e-03  6.8114670e-03\n",
            " -6.5167653e-03 -4.5419913e-03 -1.2705415e-03  1.6345874e-03\n",
            " -1.4837370e-03 -8.5483706e-03 -3.6299569e-03  1.7294660e-03\n",
            " -2.0310427e-03 -7.2464654e-03  4.2032171e-03 -8.5925050e-03\n",
            "  2.7253102e-03 -4.6202657e-03  6.4654934e-04 -2.0457348e-03\n",
            "  5.4251067e-03 -8.0400398e-03 -2.1325520e-03 -7.6262681e-05\n",
            " -6.6337567e-03 -6.5803230e-03 -1.9557416e-03  8.8215312e-03\n",
            " -1.2637944e-03  3.5586639e-03 -5.7755318e-03  8.8291727e-03\n",
            "  2.9386890e-03  9.3009342e-03  4.3924297e-03 -4.2032376e-03\n",
            "  2.2444502e-03 -4.4188551e-03  5.7925293e-03  1.8414595e-03\n",
            " -2.3049368e-03 -5.8892933e-03 -8.0570737e-03 -8.5308874e-04\n",
            " -8.9493245e-03 -9.2283171e-03 -7.9420656e-03  2.1805645e-03\n",
            " -6.4925817e-03 -7.8082508e-03  2.1300097e-03  2.0451855e-03\n",
            "  8.3590578e-03  4.6819523e-03 -9.4456514e-03 -3.5458032e-04\n",
            "  7.8527071e-03  2.6930550e-03  2.7000178e-03 -4.8926664e-03\n",
            "  6.4851679e-03  1.6467690e-03 -7.6299459e-03  6.8895887e-03\n",
            " -9.7765019e-03 -8.1599606e-03 -4.8777321e-03  9.9633913e-03\n",
            "  3.1389296e-03 -2.0122137e-03  8.9285588e-03  2.3700253e-03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-687081128.py:13: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  print(toyModel.docvecs[0])\n"
          ]
        }
      ],
      "source": [
        "## Slide 20, Distributed Representation\n",
        "# Genism (the only option)\n",
        "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
        "\n",
        "corpus = [list(tokenize(doc)) for doc in toyCorpus] #先 tokenize corpus\n",
        "corpus = [\n",
        "    TaggedDocument(words, ['d{}'.format(idx)]) #  TaggedDocument 標記文件（Doc2Vec 必要步驟）\n",
        "    for idx, words in enumerate(corpus)\n",
        "]\n",
        "toyModel = Doc2Vec(corpus, min_count=0)  # size=5, 建立 Doc2Vec 模型\n",
        "\n",
        "print(toyModel.docvecs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhiIGnCemC00",
        "outputId": "25a3f554-5917-4874-f91c-701fd8b9d78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-4.2198738e-01  5.6964403e-01 -1.2523958e-01  6.6518670e-01\n",
            "  1.6320406e-01 -9.4609839e-01  1.2806635e-01  1.7377440e+00\n",
            " -4.7184888e-01 -7.8881389e-01 -5.0169196e-02 -1.4315276e+00\n",
            "  5.9740704e-01  1.1773859e+00  5.9406996e-01 -4.0982604e-01\n",
            "  9.1145575e-01  3.1282258e-01 -1.4885694e-01 -5.6883878e-01\n",
            " -5.4572470e-02  4.3965080e-01  2.0627999e-01  7.4375468e-01\n",
            "  2.4681708e-01  5.1529241e-01 -4.4300494e-01 -5.5855680e-01\n",
            "  3.0511139e-02 -9.0532142e-01  6.3319165e-01  3.3364210e-02\n",
            "  2.5430176e-01 -1.4377232e-01 -4.0192521e-01  6.2891191e-01\n",
            " -1.6899855e-01 -9.8733127e-01 -2.4156374e-01 -7.3019344e-01\n",
            " -1.0147717e-01  1.3203858e-01 -4.3308035e-01  2.8660846e-01\n",
            "  3.5042610e-02 -8.8911134e-01 -9.8572457e-01  1.8258080e-01\n",
            " -1.4504999e-01  7.7341920e-01 -5.7639575e-01  3.4444530e-02\n",
            " -3.4880501e-01  2.0311555e-01 -2.3843253e-01 -1.9748969e-01\n",
            " -7.8260446e-01  7.5431979e-01 -1.1491742e+00 -2.9330088e-02\n",
            "  7.9523295e-01  1.1019710e+00  2.9741484e-01  1.8451114e-01\n",
            " -5.4168254e-02  1.1440616e+00  5.8641464e-01  3.7020472e-01\n",
            " -1.0418884e+00  1.3135980e+00 -6.4476103e-01 -1.7541756e-01\n",
            " -3.7404534e-01 -2.9904526e-01  1.1658013e+00  1.0939380e-01\n",
            "  8.6304295e-01 -7.5127500e-01 -1.7386730e-01  1.0465569e+00\n",
            " -8.8592869e-01  8.3620459e-02 -1.3692178e+00  1.1117727e+00\n",
            " -6.2473375e-01  6.6295010e-01  1.0671260e-01  1.6684383e-01\n",
            " -1.1330262e-03 -7.6355290e-01 -1.2903753e-01  5.9498954e-01\n",
            " -8.7463945e-01 -2.8107101e-01  2.4628165e-01  9.0626216e-01\n",
            "  7.4821129e-02  5.5197090e-01  3.4065664e-01  3.2997090e-02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1479814973.py:9: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  print(model.docvecs[3])\n"
          ]
        }
      ],
      "source": [
        "corpus = [list(tokenize(doc)) for doc in strCorpus]\n",
        "corpus = [\n",
        "    TaggedDocument(words, ['d{}'.format(idx)])\n",
        "    for idx, words in enumerate(corpus)\n",
        "]\n",
        "\n",
        "model = Doc2Vec(corpus, min_count=3)  # size=10, min_count=3 出現至少 3 次的詞才會被模型使用\n",
        "\n",
        "print(model.docvecs[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_UW0jXlmC00"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 文件分類器 (Document Classifier)\n",
        "\n",
        "使用 One-Hot Encoding → Naive Bayes → 訓練 → 預測。\n",
        "\n",
        "非常基本、非常簡化的小範例。\n",
        "\n",
        "- Step 1：向量化文字（X）: One-Hot Encoding 版本\n",
        "（每篇文章變成一個 0/1 的向量）\\\\\n",
        "\n",
        "- Step 2：做標籤（y）: 根據每篇 document 的 category （正負文本最常用）\n",
        "\n",
        "- Step 3：使用機器學習模型: Multinomial Naive Bayes\n",
        "（適合文字分類）\n",
        "\n",
        "- Step 4：進行預測: 拿文件向量去預測類別\n",
        "（示範如何分類）"
      ],
      "metadata": {
        "id": "sibOzdAen8MR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKnFUoFJpLvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "製作 X matrix：文件向量（one-hot）:作用：把每個 document 轉成數學向量"
      ],
      "metadata": {
        "id": "BW96gV2KoFBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp0S5LYRmC00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ef55d5-8f7a-429c-9650-35e183d3c485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 1, 1],\n",
              "       [0, 0, 0, ..., 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Create the X matrix (with one-hot encoding)\n",
        "freq = CountVectorizer()\n",
        "corpus = freq.fit_transform(strCorpus)\n",
        "onehot = Binarizer()\n",
        "# Converts the sparse array to a dense one (so we can view it)\n",
        "documents = onehot.fit_transform(corpus.toarray())\n",
        "documents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "製作 y vector：標注每份文件（分類類別）\n",
        "\n",
        "X：文件向量 \\\n",
        "y：文件的類別（正評？負評？哪一種案件？）"
      ],
      "metadata": {
        "id": "gXtdMuJjoJ-S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlaibfNLmC00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8400d61c-33d4-4c87-8406-623e42937b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg']\n",
            "['neg']\n",
            "['neg']\n",
            "['pos']\n",
            "['pos']\n",
            "['pos']\n",
            "['pos']\n"
          ]
        }
      ],
      "source": [
        "# Create the y vector with the labels for each document\n",
        "labels = []\n",
        "for doc in myCorpus2.fileids():\n",
        "    lab = myCorpus2.categories(doc)\n",
        "    labels.append(lab)\n",
        "    print(lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "訓練模型（Naive Bayes）\n",
        "\n",
        "使用 Multinomial Naive Bayes （常用於文字分類）訓練分類模型。\n",
        "\n",
        "alpha=0.0 = 不做 smoothing（教科書示範）\n",
        "\n",
        "class_prior=[0.4, 0.6]  假設兩類的機率（演示用）"
      ],
      "metadata": {
        "id": "YjfZreq9oeH5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL3E0s7KmC01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "becef6a9-19b7-4b17-840f-daa5eac4e7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/naive_bayes.py:898: RuntimeWarning: divide by zero encountered in log\n",
            "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Use the fit method (with a naive bayes model)\n",
        "# Note: 6 documents is way too few to train a model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])\n",
        "\n",
        "model.fit(documents, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "用模型進行預測"
      ],
      "metadata": {
        "id": "nTA2KsgloqhF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncHIpSn-mC01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd92563-ca0c-4d82-c40e-e19858d41fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg'], dtype='<U3')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Now that the model is fit, we can use the predict method\n",
        "# Here I am using the same documents for fit and predict\n",
        "# In real applications, you would use them on different documents\n",
        "model.predict(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ay3Sq6lylFkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 你其實就可以跑 topic model 了"
      ],
      "metadata": {
        "id": "HAHzgDBmoXJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import nltk\n",
        "#import string\n",
        "#from nltk.corpus import stopwords\n",
        "\n",
        "#nltk.download('stopwords')\n",
        "\n",
        "#def tokenize(text):\n",
        "#    stemmer = nltk.stem.SnowballStemmer('english')\n",
        "\n",
        "#    # 內建 stopwords\n",
        "#    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#    # 自己加的 stopwords（法律文件常見無意義字）\n",
        "#    custom_stop = {\n",
        "#        \"court\", \"judge\", \"case\", \"opinion\", \"states\",\n",
        "#        \"justice\", \"law\", \"u\", \"s\", \"v\", \"section\"\n",
        "#    }\n",
        "\n",
        "#    # 合併\n",
        "#    stop_words = stop_words.union(custom_stop)\n",
        "\n",
        "#    # 轉小寫\n",
        "#    text = text.lower()\n",
        "#    tokens = []\n",
        "\n",
        "#    for token in nltk.word_tokenize(text):\n",
        "\n",
        "#        # 去除標點符號\n",
        "#        if token in string.punctuation:\n",
        "#            continue\n",
        "\n",
        "#        # 去除停用詞\n",
        "#        if token in stop_words:\n",
        "#            continue\n",
        "\n",
        "#        # 只保留字母（刪掉純數字、No. 123、1852、lexis 之類雜訊）\n",
        "#        if not token.isalpha():\n",
        "#            continue\n",
        "\n",
        "#        # 詞幹化\n",
        "#        tokens.append(stemmer.stem(token))\n",
        "\n",
        "#    return tokens\n"
      ],
      "metadata": {
        "id": "dFnm1WiSr0F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 整理資料\n",
        "\n",
        "LDA 所需要的全部資料：\n",
        "\n",
        "tokCorpus = tokenized documents（list of tokens every document）\n",
        "\n",
        "id2word = dictionary（token → integer id）\n",
        "\n",
        "freqVectors3 = doc-term matrix（稀疏 BOW）"
      ],
      "metadata": {
        "id": "aIdxbdcEodBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokCorpus = [tokenize(doc) for doc in strCorpus]\n",
        "id2word = gensim.corpora.Dictionary(tokCorpus)\n",
        "freqVectors3 = [id2word.doc2bow(doc) for doc in tokCorpus]"
      ],
      "metadata": {
        "id": "CvIfXd4foK9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立 Topic Model（最常用是 LDA）"
      ],
      "metadata": {
        "id": "R1Rmd8Xxo0wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "num_topics = 5  # ← 你要自己決定（5, 10, 20 都可以）\n",
        "lda_model = LdaModel(corpus=freqVectors3,\n",
        "                     id2word=id2word,\n",
        "                     num_topics=num_topics,\n",
        "                     random_state=42,\n",
        "                     passes=10)\n"
      ],
      "metadata": {
        "id": "iCVGJD56n3Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 查看每個 Topic 的 Top Words"
      ],
      "metadata": {
        "id": "fvgcU8ASo2yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model.print_topics(num_words=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tbxdsS2n340",
        "outputId": "2bc731af-1678-4dfe-a7f1-506189e7db67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.063*\"the\" + 0.040*\"of\" + 0.016*\"to\" + 0.016*\"it\" + 0.016*\"i\" + 0.016*\"that\" + 0.016*\"justic\" + 0.016*\"in\" + 0.012*\"and\" + 0.012*\"\\'s\"'),\n",
              " (1,\n",
              "  '0.002*\"of\" + 0.002*\"the\" + 0.002*\"in\" + 0.002*\"that\" + 0.002*\"to\" + 0.002*\"it\" + 0.002*\"parti\" + 0.002*\"dissent\" + 0.002*\"\\'s\" + 0.002*\"justic\"'),\n",
              " (2,\n",
              "  '0.037*\"the\" + 0.030*\"dissent\" + 0.013*\"of\" + 0.013*\"that\" + 0.013*\"in\" + 0.013*\"author\" + 0.013*\"justic\" + 0.013*\"type\" + 0.013*\"violat\" + 0.013*\"brennan\"'),\n",
              " (3,\n",
              "  '0.005*\"the\" + 0.004*\"parti\" + 0.004*\"of\" + 0.003*\"that\" + 0.003*\"to\" + 0.003*\"it\" + 0.002*\"is\" + 0.002*\"\\'s\" + 0.002*\"a\" + 0.002*\"and\"'),\n",
              " (4,\n",
              "  '0.080*\"the\" + 0.037*\"of\" + 0.031*\"to\" + 0.029*\"parti\" + 0.022*\"it\" + 0.020*\"that\" + 0.013*\"is\" + 0.013*\"and\" + 0.013*\"\\'s\" + 0.013*\"by\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 查看每份文件的 Topic Distribution"
      ],
      "metadata": {
        "id": "7CYibULfo7PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(freqVectors3):\n",
        "    print(f\"Document {i}:\")\n",
        "    print(lda_model.get_document_topics(doc))\n",
        "\n",
        "# Document 0: [(4, np.float32(0.9899633))]\n",
        "# 文件 0 幾乎完全是 Topic 4，機率= 0.9899（99%）"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcLHwaufn6A2",
        "outputId": "489d4b92-3c19-4c4c-bc71-8763522288a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0:\n",
            "[(4, np.float32(0.99511147))]\n",
            "Document 1:\n",
            "[(2, np.float32(0.97303814))]\n",
            "Document 2:\n",
            "[(4, np.float32(0.97864693))]\n",
            "Document 3:\n",
            "[(4, np.float32(0.99923295))]\n",
            "Document 4:\n",
            "[(2, np.float32(0.9762821))]\n",
            "Document 5:\n",
            "[(0, np.float32(0.9960197))]\n",
            "Document 6:\n",
            "[(0, np.float32(0.99601966))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(lda_model, freqVectors3, id2word)\n",
        "\n",
        "#encoding 確認，確認是否有字體"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CP7SBBL6n9v5",
        "outputId": "849f9e38-32ec-407d-de0c-040ee5dc039b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (1.16.3)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (1.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.14.1)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim->pyLDAvis) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->pyLDAvis) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim->pyLDAvis) (2.0.1)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "4     -0.031141  0.110885       1        1  72.803919\n",
              "0      0.152976 -0.005420       2        1  23.446183\n",
              "2     -0.025593 -0.037991       3        1   3.588724\n",
              "3     -0.044157 -0.025797       4        1   0.080595\n",
              "1     -0.052084 -0.041678       5        1   0.080579, topic_info=        Term        Freq       Total Category  logprob  loglift\n",
              "79       the  127.000000  127.000000  Default  30.0000  30.0000\n",
              "121    parti   36.000000   36.000000  Default  29.0000  29.0000\n",
              "26   dissent   15.000000   15.000000  Default  28.0000  28.0000\n",
              "60        of   62.000000   62.000000  Default  27.0000  27.0000\n",
              "78      that   32.000000   32.000000  Default  26.0000  26.0000\n",
              "..       ...         ...         ...      ...      ...      ...\n",
              "192   candid    0.002591   12.369447   Topic5  -6.2774  -1.3472\n",
              "82      type    0.002590    5.476167   Topic5  -6.2777  -0.5327\n",
              "310   member    0.002589   11.435530   Topic5  -6.2782  -1.2695\n",
              "58       not    0.002589   11.189832   Topic5  -6.2782  -1.2478\n",
              "43         i    0.002588   13.531002   Topic5  -6.2785  -1.4381\n",
              "\n",
              "[313 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "0         1  0.770265        's\n",
              "0         2  0.240708        's\n",
              "1         1  0.639878        --\n",
              "1         2  0.399924        --\n",
              "136       1  0.748335       414\n",
              "...     ...       ...       ...\n",
              "92        1  0.552458      with\n",
              "92        2  0.414344      with\n",
              "93        1  0.588878  wodougla\n",
              "453       1  0.206321     would\n",
              "453       2  0.618962     would\n",
              "\n",
              "[179 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 1, 3, 4, 2])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el3421340327313179685358132674\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el3421340327313179685358132674_data = {\"mdsDat\": {\"x\": [-0.03114119872141675, 0.15297555770120394, -0.025593292648882084, -0.04415718994962772, -0.05208387638127727], \"y\": [0.11088547389070483, -0.0054196189393271275, -0.03799136576376254, -0.025796565828987258, -0.041677923358627925], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [72.80391921668146, 23.446183107341934, 3.588723705285509, 0.08059450362546673, 0.08057946706561805]}, \"tinfo\": {\"Term\": [\"the\", \"parti\", \"dissent\", \"of\", \"that\", \"be\", \"in\", \"by\", \"justic\", \"candid\", \"member\", \"democrat\", \"i\", \"author\", \"republican\", \"state\", \"it\", \"select\", \"is\", \"to\", \"'s\", \"and\", \"a\", \"no\", \"an\", \"independ\", \"for\", \"--\", \"this\", \"primari\", \"parti\", \"by\", \"candid\", \"member\", \"democrat\", \"republican\", \"state\", \"select\", \"no\", \"an\", \"independ\", \"be\", \"than\", \"may\", \"associ\", \"v.\", \"u.s.\", \"primari\", \"vote\", \"which\", \"case\", \"me\", \"requir\", \"if\", \"can\", \"there\", \"properti\", \"interest\", \"process\", \"more\", \"decis\", \"is\", \"to\", \"the\", \"it\", \"of\", \"as\", \"that\", \"a\", \"and\", \"'s\", \"not\", \"in\", \"dissent\", \"this\", \"for\", \"--\", \"i\", \"was\", \"justic\", \"great\", \"discrimin\", \"though\", \"richmond\", \"those\", \"fulfil\", \"never\", \"again\", \"act\", \"confin\", \"am\", \"shallow\", \"demonstr\", \"litig\", \"benefit\", \"approach\", \"promis\", \"strike\", \"reveal\", \"innoc\", \"pain\", \"time\", \"sensit\", \"hablackmun\", \"trade\", \"best\", \"embodi\", \"when\", \"toward\", \"lessen\", \"sought\", \"day\", \"would\", \"justic\", \"i\", \"the\", \"of\", \"join\", \"marshal\", \"in\", \"--\", \"court\", \"this\", \"who\", \"so\", \"with\", \"that\", \"it\", \"one\", \"'s\", \"and\", \"to\", \"dissent\", \"a\", \"violat\", \"petition\", \"murder\", \"jeopardi\", \"tri\", \"doubl\", \"substanc\", \"twice\", \"wjbrennan\", \"claus\", \"rational-basi\", \"fail\", \"ground\", \"challeng\", \"test\", \"affirm\", \"classif\", \"brennan\", \"wodougla\", \"they\", \"protect\", \"white\", \"guarante\", \"equal\", \"view\", \"against\", \"dougla\", \"mr.\", \"becaus\", \"dissentbi\", \"dissent\", \"type\", \"author\", \"the\", \"justic\", \"in\", \"that\", \"of\", \"be\", \"for\", \"was\", \"on\", \"fail\", \"test\", \"wjbrennan\", \"claus\", \"challeng\", \"classif\", \"ground\", \"rational-basi\", \"affirm\", \"twice\", \"substanc\", \"doubl\", \"tri\", \"jeopardi\", \"murder\", \"petition\", \"violat\", \"767\", \"been\", \"poll\", \"conflict\", \"next\", \"degre\", \"true\", \"issu\", \"him\", \"them\", \"414\", \"consid\", \"casual\", \"the\", \"parti\", \"of\", \"that\", \"it\", \"to\", \"member\", \"is\", \"a\", \"'s\", \"candid\", \"by\", \"and\", \"on\", \"in\", \"democrat\", \"state\", \"republican\", \"not\", \"primari\", \"other\", \"be\", \"select\", \"as\", \"no\", \"ani\", \"elect\", \"u.s.\", \"there\", \"--\", \"i\", \"so\", \"or\", \"dissent\", \"justic\", \"twice\", \"substanc\", \"doubl\", \"tri\", \"jeopardi\", \"murder\", \"petition\", \"wjbrennan\", \"claus\", \"fail\", \"test\", \"rational-basi\", \"challeng\", \"ground\", \"affirm\", \"classif\", \"violat\", \"been\", \"poll\", \"degre\", \"conflict\", \"next\", \"414\", \"767\", \"them\", \"true\", \"issu\", \"henceforth\", \"form\", \"him\", \"dilut\", \"american\", \"respect\", \"said\", \"pollster\", \"417\", \"made\", \"leav\", \"forward\", \"summarili\", \"their\", \"wodougla\", \"relat\", \"of\", \"guarante\", \"against\", \"the\", \"in\", \"that\", \"view\", \"dissent\", \"justic\", \"mr.\", \"dougla\", \"to\", \"it\", \"parti\", \"'s\", \"be\", \"by\", \"author\", \"is\", \"and\", \"for\", \"was\", \"a\", \"as\", \"candid\", \"type\", \"member\", \"not\", \"i\"], \"Freq\": [127.0, 36.0, 15.0, 62.0, 32.0, 15.0, 20.0, 16.0, 12.0, 12.0, 11.0, 10.0, 13.0, 8.0, 8.0, 8.0, 34.0, 8.0, 18.0, 45.0, 20.0, 20.0, 18.0, 6.0, 6.0, 6.0, 8.0, 12.0, 14.0, 5.0, 35.94678156796349, 15.786805197268036, 12.11366926889467, 11.180522650569072, 10.278607447089035, 8.442338970173497, 8.443012816533573, 8.44679123152418, 6.608146590096884, 6.615545550818892, 6.616174125847283, 14.890683563440266, 5.699182408112864, 5.700873118230781, 5.69547654333329, 5.691914037770717, 5.688383454300998, 5.683817434219414, 4.773289650087207, 4.777733495613411, 4.775953403635501, 4.777921835961253, 4.7792094571066706, 4.7721297173132085, 4.77505871443304, 4.768225935557935, 3.869957976286959, 3.857287807432125, 3.8568249370857335, 3.853081636397266, 3.8553010924531925, 16.721932146153996, 38.823101430567924, 99.47791485775568, 27.761785161144932, 46.176122198145805, 11.21045048322279, 24.99393540925705, 14.87857290181292, 15.814643583844, 15.798942557373042, 9.372252751095457, 13.052098703386859, 10.310480786201818, 9.40693697558451, 6.624070490816134, 7.549954542816467, 6.6486801028002755, 5.717776736999824, 5.723704379442078, 4.865873747448951, 4.863978794865892, 4.864533187187982, 4.863777673443582, 3.2963677752066247, 3.2940354396047877, 3.293260112783469, 1.7273431112007724, 1.7262827377539685, 1.726614139502811, 1.7261059153882579, 1.7269711487189923, 1.7262666629934493, 1.7258262893215526, 1.7265242329933959, 1.7264885320717775, 1.726897503885916, 1.7261575041545751, 1.7265825507292327, 1.7264631115202589, 1.7264747003010983, 1.727143858936663, 1.726575447928073, 1.7271098402574248, 1.7261180649165573, 1.7263825508018433, 1.726650588087709, 1.7264907750616176, 1.7264367563896403, 1.7259601210486655, 1.7262984386828477, 3.295811513726334, 3.3092657144492237, 6.4459901831288375, 6.453390554273887, 25.36941135030844, 15.869157603141755, 3.296308335975868, 3.31955916865608, 6.4452215852770385, 4.867890942978285, 3.293553196789213, 4.866217298726093, 3.3002178672667815, 3.298022727876817, 3.2970724478479876, 6.450659340312191, 6.454479152009509, 3.2970186160918304, 4.880349630043907, 4.880626639289132, 6.482364749362197, 3.3317898184213144, 3.3078189860025, 0.7828124184281086, 0.4280679619849219, 0.42796831425583765, 0.4279359280286417, 0.42793100715313137, 0.4279110089439353, 0.4278626012615895, 0.4278043232184816, 0.42604914419706597, 0.42581400073299946, 0.42571572627149945, 0.4254455358742925, 0.42544433426515627, 0.42532840759325, 0.42526663916169877, 0.4249072722007377, 0.42463994277766465, 0.7770219212200294, 0.42871130923841544, 0.4263964378471819, 0.4254999802120609, 0.42557316393040645, 0.42797752659254884, 0.41987670694210916, 0.42979661977611616, 0.42966913476870894, 0.4302721995063969, 0.42981038106170033, 0.4283168953443139, 0.425943116495663, 1.8533049411386242, 0.7836542314572718, 0.7858968918613652, 2.289932623025066, 0.7848617914197147, 0.7969554724006706, 0.8066505126677519, 0.8217359143005428, 0.4408684180159202, 0.4368162773013493, 0.433961540091046, 0.4281374550466347, 0.0024887714915278426, 0.002486214305017003, 0.0024818193816424374, 0.002482560676601453, 0.0024835292591806214, 0.002483153712568665, 0.0024788964467845386, 0.0024774310439869014, 0.0024798502516527147, 0.0024463160916107563, 0.0024463213923114385, 0.002446320749802265, 0.0024463229985843726, 0.0024463242836027196, 0.0024463120759284215, 0.00244631721600181, 0.0024786812062113904, 0.002532055728278844, 0.0025303235235468783, 0.0025302653764666693, 0.002526814459695383, 0.0025267794429454232, 0.0025262493728772212, 0.0025264981845546895, 0.0025256299940338922, 0.002525730546719557, 0.002524047333312077, 0.0025231911898382846, 0.002519642772299908, 0.0025196805197138556, 0.007430038406643326, 0.005033963319860484, 0.005004111058637713, 0.0039000653791125195, 0.0037360899704145596, 0.0038189389583107203, 0.0032627714524966667, 0.003375777250963874, 0.003336244304022807, 0.003344440151040965, 0.0031604926659369267, 0.0032312512374592876, 0.0032769651226501736, 0.0029210709387861825, 0.0032455592742456916, 0.0030374193912289286, 0.0029672133775958446, 0.002966198855610765, 0.002971306482286122, 0.0028374872416500356, 0.00270132284253039, 0.003015854534581551, 0.0028872502196528086, 0.002932185383725318, 0.0028196894162873442, 0.0027292260521751127, 0.0027284643575498364, 0.002777584505124445, 0.002746976974368133, 0.0028693467015310633, 0.002853690680498494, 0.0027780609256766527, 0.0027691040265423916, 0.002810355364268193, 0.002798741047192014, 0.002590824301956998, 0.002588718710427953, 0.0025869903620155065, 0.002586269601220574, 0.002586091819981717, 0.002584954469725543, 0.0025813871213436743, 0.002555817778829342, 0.002555828860044772, 0.002555823078541069, 0.002555830787212673, 0.0025558272540715213, 0.0025558261298902455, 0.002555827093474196, 0.0025558319113939483, 0.0025558306266153475, 0.0025897791345654165, 0.0025587366352125616, 0.0025587989469746907, 0.002559119659832863, 0.002558292904803382, 0.002558869449200398, 0.0025589095985316663, 0.0025578313480911197, 0.0025585749137062123, 0.0025586691843360308, 0.002558482570244295, 0.0025591204628194887, 0.002559158684982856, 0.0025583023800455616, 0.002558889363268707, 0.002559670187463217, 0.0025596168691512924, 0.0025590592752386355, 0.002559070677648716, 0.0025594042382928945, 0.0025591565972176303, 0.00255930787989785, 0.002559381594070059, 0.0025593461020612177, 0.0025592927837492932, 0.002592481505754437, 0.002559154027660429, 0.002805082493049955, 0.002601416659129579, 0.002595139070289761, 0.002772646008915458, 0.0026975683654166115, 0.0026799410424191636, 0.002586343475990108, 0.0026318537065669048, 0.0026245426739402358, 0.0025808210157727885, 0.002578129886396523, 0.0026369253700927416, 0.002632744058137115, 0.002631917463704959, 0.0026284890320092793, 0.002617331693447088, 0.0026009809585866533, 0.0025997766392459234, 0.002599751586063212, 0.0025958668973669967, 0.0025957279806808078, 0.0025949914813480184, 0.0025931730378362054, 0.00259153366034185, 0.002591141642271344, 0.0025903052514023588, 0.00258913610287582, 0.002588971169422969, 0.002588192111799035], \"Total\": [127.0, 36.0, 15.0, 62.0, 32.0, 15.0, 20.0, 16.0, 12.0, 12.0, 11.0, 10.0, 13.0, 8.0, 8.0, 8.0, 34.0, 8.0, 18.0, 45.0, 20.0, 20.0, 18.0, 6.0, 6.0, 6.0, 8.0, 12.0, 14.0, 5.0, 36.243398982137975, 16.051768797841692, 12.36944705411761, 11.435530292091645, 10.531151847458984, 8.68889983694569, 8.689955474520874, 8.69616842335006, 6.853360830337156, 6.86213348763256, 6.862963412179043, 15.504207723868616, 5.941859521202786, 5.944945435425222, 5.939978037527186, 5.937176407352045, 5.933624922933852, 5.929189445499459, 5.014983573588951, 5.019670104957047, 5.018433307344595, 5.020620780380093, 5.02219505023442, 5.015051001405009, 5.018869501615213, 5.011865635785175, 4.10963710633773, 4.097166030692132, 4.097399062520283, 4.0936648097667385, 4.096030204344947, 18.549801847443074, 45.409274435252456, 127.14746151550474, 34.32145963364212, 62.87482490913979, 13.0357337972126, 32.25782526865852, 18.277036844926062, 20.784643002774608, 20.772072808076125, 11.189831554860492, 20.30021888870423, 15.501017754832592, 14.359248199803405, 8.795988027349031, 12.502379801981451, 13.5310021707741, 7.884106134790786, 12.959979637711763, 5.139627781919098, 5.139391128719914, 5.139988825352575, 5.1397100350555025, 3.5661593443897597, 3.564980293307371, 3.564965328220551, 1.9924140964984902, 1.9912347077142796, 1.9919049181566293, 1.9913215687562658, 1.9923272071658806, 1.9917250601002356, 1.9913661706024874, 1.99217927768608, 1.9921884438020119, 1.9927127464357033, 1.9920246759090385, 1.9925281385806435, 1.9924099175387169, 1.992430159607286, 1.9932054800950874, 1.9925791307066965, 1.9932315395952989, 1.9921657484135844, 1.9924804583709717, 1.9927955770831847, 1.9926513043110445, 1.9926270721690118, 1.9921151768744383, 1.9925449530215253, 4.484313617785801, 4.846824936062337, 12.959979637711763, 13.5310021707741, 127.14746151550474, 62.87482490913979, 5.39703897157576, 5.780319081656068, 20.30021888870423, 12.502379801981451, 6.321425949208858, 14.359248199803405, 7.241580042301378, 7.240411946150541, 7.240368411466396, 32.25782526865852, 34.32145963364212, 8.172797328946121, 20.772072808076125, 20.784643002774608, 45.409274435252456, 15.501017754832592, 18.277036844926062, 1.1335483627938792, 0.7756589705098047, 0.7755628791353687, 0.7755319142411083, 0.7755271916845391, 0.7755076589766388, 0.7754612050178972, 0.7754038747475983, 0.7773885987128931, 0.7776239150850298, 0.778068090360188, 0.7776736530870877, 0.7783017818250172, 0.7781473844544948, 0.7780509185635689, 0.7788876854667076, 0.7789998416749087, 2.7147160939609685, 1.698145030621902, 1.696807891785578, 1.6957441116719882, 1.6986274186005565, 2.3487077900625826, 2.3582752360832995, 2.613449570122025, 2.6136244669461752, 2.620989473442764, 2.6217203435761864, 2.623343782415888, 2.6260155025703606, 15.501017754832592, 5.4761674746142415, 8.244815431272626, 127.14746151550474, 12.959979637711763, 20.30021888870423, 32.25782526865852, 62.87482490913979, 15.504207723868616, 8.795988027349031, 7.884106134790786, 6.015119464448684, 0.7776736530870877, 0.7780509185635689, 0.7773885987128931, 0.7776239150850298, 0.7781473844544948, 0.7789998416749087, 0.7783017818250172, 0.778068090360188, 0.7788876854667076, 0.7754038747475983, 0.7754612050178972, 0.7755076589766388, 0.7755271916845391, 0.7755319142411083, 0.7755628791353687, 0.7756589705098047, 1.1335483627938792, 1.3357631549410147, 1.3356071518580344, 1.3357741720758392, 1.335788836217696, 1.3362158286806922, 1.3360264623597222, 1.3362660254789973, 1.3362169004651416, 1.3363591522115799, 1.3361832442694204, 1.3363003624672598, 1.3364985382652594, 1.336543449947025, 127.14746151550474, 36.243398982137975, 62.87482490913979, 32.25782526865852, 34.32145963364212, 45.409274435252456, 11.435530292091645, 18.549801847443074, 18.277036844926062, 20.772072808076125, 12.36944705411761, 16.051768797841692, 20.784643002774608, 6.015119464448684, 20.30021888870423, 10.531151847458984, 8.689955474520874, 8.68889983694569, 11.189831554860492, 5.929189445499459, 3.169033379889381, 15.504207723868616, 8.69616842335006, 13.0357337972126, 6.853360830337156, 4.090038347730931, 4.089750311275743, 5.933624922933852, 5.011865635785175, 12.502379801981451, 13.5310021707741, 7.240411946150541, 6.586565965181545, 15.501017754832592, 12.959979637711763, 0.7754038747475983, 0.7754612050178972, 0.7755076589766388, 0.7755271916845391, 0.7755319142411083, 0.7755628791353687, 0.7756589705098047, 0.7773885987128931, 0.7776239150850298, 0.7776736530870877, 0.7780509185635689, 0.778068090360188, 0.7781473844544948, 0.7783017818250172, 0.7788876854667076, 0.7789998416749087, 1.1335483627938792, 1.3356071518580344, 1.3357741720758392, 1.3360264623597222, 1.335788836217696, 1.3362158286806922, 1.3363003624672598, 1.3357631549410147, 1.3361832442694204, 1.3362660254789973, 1.3362169004651416, 1.3367197213322586, 1.3367792963689042, 1.3363591522115799, 1.3368186153137656, 1.337830930300808, 1.3380574123472773, 1.3372376626950473, 1.3372711640833286, 1.3380420931890982, 1.337559133199398, 1.3381811104554067, 1.338577316596339, 1.3384827396769392, 1.338614708353109, 1.698145030621902, 1.338479862347035, 62.87482490913979, 2.3487077900625826, 2.6136244669461752, 127.14746151550474, 20.30021888870423, 32.25782526865852, 2.613449570122025, 15.501017754832592, 12.959979637711763, 2.6217203435761864, 2.620989473442764, 45.409274435252456, 34.32145963364212, 36.243398982137975, 20.772072808076125, 15.504207723868616, 16.051768797841692, 8.244815431272626, 18.549801847443074, 20.784643002774608, 8.795988027349031, 7.884106134790786, 18.277036844926062, 13.0357337972126, 12.36944705411761, 5.4761674746142415, 11.435530292091645, 11.189831554860492, 13.5310021707741], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.546, -4.3688, -4.6337, -4.7138, -4.798, -4.9948, -4.9947, -4.9942, -5.2397, -5.2386, -5.2385, -4.4273, -5.3877, -5.3874, -5.3883, -5.389, -5.3896, -5.3904, -5.565, -5.5641, -5.5644, -5.564, -5.5637, -5.5652, -5.5646, -5.566, -5.7748, -5.7781, -5.7782, -5.7791, -5.7786, -4.3113, -3.469, -2.5281, -3.8044, -3.2956, -4.7112, -3.9094, -4.4281, -4.3671, -4.3681, -4.8903, -4.5591, -4.7949, -4.8866, -5.2373, -5.1065, -5.2336, -5.3844, -5.3834, -4.4127, -4.4131, -4.413, -4.4131, -4.8021, -4.8028, -4.8031, -5.4484, -5.449, -5.4488, -5.4491, -5.4486, -5.449, -5.4492, -5.4488, -5.4489, -5.4486, -5.4491, -5.4488, -5.4489, -5.4489, -5.4485, -5.4488, -5.4485, -5.4491, -5.4489, -5.4488, -5.4489, -5.4489, -5.4492, -5.449, -4.8023, -4.7982, -4.1315, -4.1303, -2.7614, -3.2306, -4.8022, -4.7951, -4.1316, -4.4123, -4.803, -4.4126, -4.801, -4.8016, -4.8019, -4.1308, -4.1302, -4.8019, -4.4097, -4.4097, -4.1259, -4.7914, -4.7987, -4.3629, -4.9665, -4.9668, -4.9668, -4.9668, -4.9669, -4.967, -4.9671, -4.9712, -4.9718, -4.972, -4.9727, -4.9727, -4.9729, -4.9731, -4.9739, -4.9746, -4.3703, -4.965, -4.9704, -4.9725, -4.9724, -4.9667, -4.9858, -4.9625, -4.9628, -4.9614, -4.9625, -4.9659, -4.9715, -3.5011, -4.3618, -4.359, -3.2895, -4.3603, -4.345, -4.3329, -4.3144, -4.9371, -4.9463, -4.9528, -4.9664, -6.3179, -6.3189, -6.3207, -6.3204, -6.32, -6.3201, -6.3219, -6.3225, -6.3215, -6.3351, -6.3351, -6.3351, -6.3351, -6.3351, -6.3351, -6.3351, -6.322, -6.3006, -6.3013, -6.3014, -6.3027, -6.3027, -6.3029, -6.3028, -6.3032, -6.3031, -6.3038, -6.3042, -6.3056, -6.3055, -5.2241, -5.6135, -5.6194, -5.8687, -5.9116, -5.8897, -6.0471, -6.0131, -6.0248, -6.0224, -6.0789, -6.0568, -6.0428, -6.1577, -6.0524, -6.1187, -6.1421, -6.1424, -6.1407, -6.1868, -6.2359, -6.1258, -6.1694, -6.1539, -6.1931, -6.2257, -6.2259, -6.2081, -6.2192, -6.1756, -6.1811, -6.2079, -6.2112, -6.1964, -6.2005, -6.2775, -6.2783, -6.279, -6.2793, -6.2793, -6.2798, -6.2812, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2779, -6.29, -6.29, -6.2898, -6.2902, -6.2899, -6.2899, -6.2903, -6.29, -6.29, -6.2901, -6.2898, -6.2898, -6.2901, -6.2899, -6.2896, -6.2896, -6.2899, -6.2898, -6.2897, -6.2898, -6.2898, -6.2897, -6.2897, -6.2898, -6.2769, -6.2898, -6.1981, -6.2734, -6.2759, -6.2097, -6.2371, -6.2437, -6.2792, -6.2618, -6.2646, -6.2814, -6.2824, -6.2599, -6.2615, -6.2618, -6.2631, -6.2673, -6.2736, -6.2741, -6.2741, -6.2756, -6.2756, -6.2759, -6.2766, -6.2772, -6.2774, -6.2777, -6.2782, -6.2782, -6.2785], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3092, 0.3008, 0.2965, 0.2948, 0.2931, 0.2886, 0.2886, 0.2883, 0.281, 0.2808, 0.2808, 0.277, 0.2757, 0.2755, 0.2754, 0.2752, 0.2752, 0.2751, 0.268, 0.268, 0.2679, 0.2679, 0.2678, 0.2677, 0.2676, 0.2676, 0.2573, 0.2571, 0.2569, 0.2568, 0.2568, 0.2137, 0.1607, 0.072, 0.1053, 0.0087, 0.1666, 0.0623, 0.1117, 0.0441, 0.0437, 0.1401, -0.1243, -0.0903, -0.1055, 0.0338, -0.187, -0.3932, -0.0039, -0.4998, 1.3957, 1.3954, 1.3954, 1.3953, 1.3718, 1.3714, 1.3712, 1.3077, 1.3077, 1.3075, 1.3075, 1.3075, 1.3074, 1.3073, 1.3073, 1.3073, 1.3073, 1.3072, 1.3072, 1.3072, 1.3072, 1.3072, 1.3072, 1.3072, 1.3071, 1.3071, 1.3071, 1.3071, 1.3071, 1.307, 1.307, 1.1425, 1.0689, 0.7521, 0.7101, -0.1613, 0.0737, 0.9574, 0.8958, 0.3032, 0.5072, 0.7985, 0.3684, 0.6646, 0.6641, 0.6638, -0.1591, -0.2205, 0.5427, 0.0021, 0.0015, -0.4962, -0.0869, -0.2589, 2.9572, 2.7329, 2.7328, 2.7328, 2.7328, 2.7328, 2.7327, 2.7327, 2.726, 2.7251, 2.7243, 2.7242, 2.7234, 2.7233, 2.7233, 2.7214, 2.7206, 2.0764, 1.9509, 1.9462, 1.9448, 1.9432, 1.6248, 1.6016, 1.5223, 1.5219, 1.5205, 1.5191, 1.515, 1.5085, 1.2034, 1.3832, 0.9769, -0.6895, 0.5233, 0.0898, -0.3613, -1.0101, -0.2327, 0.3248, 0.4277, 0.6848, 1.379, 1.3775, 1.3765, 1.3765, 1.3763, 1.375, 1.3742, 1.3739, 1.3738, 1.3647, 1.3646, 1.3646, 1.3645, 1.3645, 1.3645, 1.3644, 0.9981, 0.8553, 0.8547, 0.8546, 0.8532, 0.8528, 0.8528, 0.8527, 0.8524, 0.8523, 0.8518, 0.8514, 0.8498, 0.8498, -2.6241, -1.7583, -2.3151, -1.897, -2.002, -2.26, -1.0384, -1.4881, -1.4851, -1.6106, -1.1488, -1.3872, -1.6316, -0.5066, -1.6176, -1.0276, -0.8588, -0.859, -1.1103, -0.5212, 0.0561, -1.4215, -0.8868, -1.2762, -0.6724, -0.1888, -0.189, -0.5433, -0.3856, -1.2561, -1.3406, -0.7422, -0.6508, -1.4919, -1.317, 1.4223, 1.4214, 1.4207, 1.4204, 1.4203, 1.4198, 1.4183, 1.4061, 1.4058, 1.4057, 1.4053, 1.4052, 1.4051, 1.4049, 1.4042, 1.404, 1.0421, 0.8661, 0.866, 0.8659, 0.8657, 0.8657, 0.8656, 0.8656, 0.8656, 0.8655, 0.8655, 0.8654, 0.8653, 0.8653, 0.8652, 0.8648, 0.8646, 0.865, 0.8649, 0.8645, 0.8648, 0.8644, 0.8641, 0.8641, 0.864, 0.639, 0.8641, -2.8938, 0.3181, 0.2088, -3.6096, -1.8024, -2.272, 0.2055, -1.5573, -1.381, 0.2002, 0.1994, -2.6302, -2.3518, -2.4066, -1.8513, -1.563, -1.604, -0.9382, -1.7491, -1.8644, -1.0045, -0.8953, -1.7368, -1.3995, -1.3472, -0.5327, -1.2695, -1.2478, -1.4381]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 3, 1, 1, 1, 2, 2, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 3, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 3, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 3, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2], \"Freq\": [0.7702649681537436, 0.24070780254804489, 0.6398781773316559, 0.3999238608322849, 0.7483347517422384, 0.7473606436525427, 0.7486357115787929, 0.8207019620997367, 0.16414039241994732, 1.0044019382806872, 1.0038073930087332, 0.7652208744192124, 1.004358126472338, 0.7474786068633893, 1.0200909108830238, 0.7697991251456235, 0.24056222660800736, 0.9779859404543524, 1.0039210930182287, 0.8438343534103239, 0.15342442789278615, 1.010104744848148, 0.727730056544622, 0.24257668551487402, 0.12128834275743701, 0.9674792976946257, 0.7623857816142425, 0.7487231545659565, 1.0039257121091048, 1.0037739600393252, 0.7367252894139122, 0.3683626447069561, 0.9967748851547966, 0.996240288453577, 0.9701322902712434, 0.996326880080758, 0.7481986463213267, 1.0040639900878714, 0.7486213186445797, 0.7482237887801764, 0.47457646804760206, 0.47457646804760206, 0.22299956810196636, 0.6689987043058991, 0.9765552987760976, 0.7484881685904453, 0.9495637461929538, 1.0041546597296656, 0.7480446401214195, 0.9728778905460281, 0.6451189307800388, 0.19353567923401166, 0.12902378615600776, 0.7616101268413638, 0.7630705961489147, 0.978054818889971, 1.0036152342968165, 0.8480774293850727, 0.7958173633519243, 0.22737638952912123, 0.7480666425013476, 0.7470618152582662, 0.8415193782787459, 0.9728330945656609, 0.8515320673189017, 1.0033957221076661, 0.7480999823982079, 0.7483018306456545, 0.5173304912417684, 0.44342613535008724, 0.9969988338302457, 0.6403871835704031, 0.2955633154940322, 0.049260552582338704, 1.0199675533134522, 1.0038094984342676, 0.9762845757374109, 0.9164518381280337, 0.10781786330918043, 0.7483814937918362, 0.815816119095186, 0.1748177398061113, 0.3705735701619485, 0.5558603552429228, 0.46296369035494644, 0.46296369035494644, 0.07716061505915775, 0.7472830039124393, 1.0039580156896013, 1.0043356312490235, 0.7476304973582981, 0.3460016604181992, 0.5190024906272989, 1.0092607350517828, 0.9958927827290449, 0.9619142898521427, 0.9771195703313883, 0.76285787113048, 0.8415229108265821, 0.7483820940718434, 1.0213966801534409, 0.8043016515374352, 0.17873370034165226, 0.7316123753262844, 0.25447386967870766, 0.01590461685491923, 0.6649909488317403, 0.33249547441587013, 0.6117856345576048, 0.36707138073456286, 0.759120917703006, 0.3036483670812024, 0.946660902670807, 1.0037993002445849, 0.993284322415292, 0.7486295370166991, 0.7477914927489513, 1.0119427039988222, 0.9762290513972115, 1.003656951348021, 0.9733219494809768, 0.5897116157543423, 0.7471162085670023, 0.9207149524251103, 0.9955806076800254, 0.7473520872663882, 1.00374994022653, 0.972817525871575, 0.7478102269305039, 0.9199453840520407, 1.0037242532449246, 1.003851171035823, 0.5524547539213777, 0.4143410654410332, 1.003741469906197, 0.9206031059026899, 1.0040036271575412, 0.7471146024948842, 1.009784896224784, 0.7750057479631097, 0.18600137951114634, 0.031000229918524393, 0.7786234881923115, 0.19662209297785646, 0.015729767438228518, 0.7470409474510369, 0.7484003442557506, 0.9976324912422925, 0.5893419077322207, 0.6267737610471292, 0.3482076450261829, 0.8412411533768296, 0.972764760759383, 1.00340884067035, 0.8588553876941764, 0.13213159810679637, 1.0037001042161706, 1.0039325300079345, 0.7483539811180491, 0.547828387993435, 0.36521892532895667, 0.18260946266447833, 1.0111862610003548, 1.0105813922877818, 0.7652720843994009, 0.8821855624538861, 0.9970122387503199, 0.7610247626580458, 0.25367492088601523, 1.0036878984662578, 0.9960813948833764, 0.5887106195565047, 0.5523656407350567, 0.41427423055129253, 0.5524580757058297, 0.41434355677937224, 0.588877853167686, 0.20632063530077097, 0.6189619059023129], \"Term\": [\"'s\", \"'s\", \"--\", \"--\", \"414\", \"417\", \"767\", \"a\", \"a\", \"act\", \"again\", \"against\", \"am\", \"american\", \"an\", \"and\", \"and\", \"ani\", \"approach\", \"as\", \"as\", \"associ\", \"author\", \"author\", \"author\", \"be\", \"becaus\", \"been\", \"benefit\", \"best\", \"brennan\", \"brennan\", \"by\", \"can\", \"candid\", \"case\", \"casual\", \"confin\", \"conflict\", \"consid\", \"court\", \"court\", \"day\", \"day\", \"decis\", \"degre\", \"democrat\", \"demonstr\", \"dilut\", \"discrimin\", \"dissent\", \"dissent\", \"dissent\", \"dissentbi\", \"dougla\", \"elect\", \"embodi\", \"equal\", \"for\", \"for\", \"form\", \"forward\", \"fulfil\", \"great\", \"guarante\", \"hablackmun\", \"henceforth\", \"him\", \"i\", \"i\", \"if\", \"in\", \"in\", \"in\", \"independ\", \"innoc\", \"interest\", \"is\", \"is\", \"issu\", \"it\", \"it\", \"join\", \"join\", \"justic\", \"justic\", \"justic\", \"leav\", \"lessen\", \"litig\", \"made\", \"marshal\", \"marshal\", \"may\", \"me\", \"member\", \"more\", \"mr.\", \"never\", \"next\", \"no\", \"not\", \"not\", \"of\", \"of\", \"of\", \"on\", \"on\", \"one\", \"one\", \"or\", \"or\", \"other\", \"pain\", \"parti\", \"poll\", \"pollster\", \"primari\", \"process\", \"promis\", \"properti\", \"protect\", \"relat\", \"republican\", \"requir\", \"respect\", \"reveal\", \"richmond\", \"said\", \"select\", \"sensit\", \"shallow\", \"so\", \"so\", \"sought\", \"state\", \"strike\", \"summarili\", \"than\", \"that\", \"that\", \"that\", \"the\", \"the\", \"the\", \"their\", \"them\", \"there\", \"they\", \"this\", \"this\", \"those\", \"though\", \"time\", \"to\", \"to\", \"toward\", \"trade\", \"true\", \"type\", \"type\", \"type\", \"u.s.\", \"v.\", \"view\", \"violat\", \"vote\", \"was\", \"was\", \"when\", \"which\", \"white\", \"who\", \"who\", \"with\", \"with\", \"wodougla\", \"would\", \"would\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 1, 3, 4, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el3421340327313179685358132674\", ldavis_el3421340327313179685358132674_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el3421340327313179685358132674\", ldavis_el3421340327313179685358132674_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el3421340327313179685358132674\", ldavis_el3421340327313179685358132674_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhLOTsDloAhJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}