{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnsonYu0924/114_2_text-analysis/blob/main/L8_corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建構 Corpus（語料庫）\n"
      ],
      "metadata": {
        "id": "P7krTRlAm1aE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PlaintextCorpusReader 是不分類，整體語料庫\n",
        "- CategorizedPlaintextCorpusReader 是有分類，分類後的語料庫"
      ],
      "metadata": {
        "id": "GcivSP4_vsGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 掛接雲端硬碟，開啟資料夾\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, json\n",
        "path = \"/content/drive/MyDrive/combine/\"\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlQRt0U1DIF4",
        "outputId": "81af81f4-146a-4dab-cc24-3a37095464f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['191227_Tsai_combine.txt', '191229_Tsai_combine.txt', '191225_Han_combine.txt', '191227_Soong_combine.txt', '191225_Soong_combine.txt', '191227_Han_combine.txt', '191229_Soong_combine.txt', '191229_Han_combine.txt', '191218_Soong_combine.txt', '191225_Tsai_combine.txt', '191218_Han_combine.txt', '191218_Tsai_combine.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader, CategorizedPlaintextCorpusReader\n",
        "\n",
        "## PlaintextCorpusReader: 以全部的.txt建構語料庫\n",
        "txtPattern = r\"[\\w\\s.]+\\.txt\"\n",
        "\n",
        "myCorpus1 = PlaintextCorpusReader(path, txtPattern)\n",
        "print(myCorpus1.fileids())\n",
        "\n",
        "\n",
        "## CategorizedPlaintextCorpusReader: 以分類的.txt建構語料庫\n",
        "# 有三個參數：資料夾路徑, 抽取全部.txt的pattern, cat_pattern = 分類的pattern\n",
        "Pattern = r\".*(_Han|_Soong|_Tsai).*\\.txt\"\n",
        "catePattern = r\".*(_Han|_Soong|_Tsai).*\"\n",
        "\n",
        "myCorpus2 = CategorizedPlaintextCorpusReader(path, Pattern, cat_pattern = catePattern)\n",
        "print(myCorpus2.fileids())\n",
        "myCorpus2.categories()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUKB9hFRGNYt",
        "outputId": "fe7c93ec-93fa-40c3-b30b-94084a77a8da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['191218_Han_combine.txt', '191218_Soong_combine.txt', '191218_Tsai_combine.txt', '191225_Han_combine.txt', '191225_Soong_combine.txt', '191225_Tsai_combine.txt', '191227_Han_combine.txt', '191227_Soong_combine.txt', '191227_Tsai_combine.txt', '191229_Han_combine.txt', '191229_Soong_combine.txt', '191229_Tsai_combine.txt']\n",
            "['191218_Han_combine.txt', '191218_Soong_combine.txt', '191218_Tsai_combine.txt', '191225_Han_combine.txt', '191225_Soong_combine.txt', '191225_Tsai_combine.txt', '191227_Han_combine.txt', '191227_Soong_combine.txt', '191227_Tsai_combine.txt', '191229_Han_combine.txt', '191229_Soong_combine.txt', '191229_Tsai_combine.txt']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Han', '_Soong', '_Tsai']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IaFLBvK6mC0k",
        "outputId": "f485c5ea-33a9-4fc4-fe5b-ea5be27d9344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "分類語料庫有15個句子\n",
            "取前三句：\n",
            "[['謝謝主持人李進勇主委', '，', '蔡英文蔡總統', '、', '宋楚瑜宋主席', '、', '全國各位所有的台灣同胞', '、', '各位海內外關切中華民國第', '15', '任總統選舉的所有的好朋友大家晚安', '，', '大家好', '！！', '首先非常感謝大家這麼長的一段時間', '，', '對韓國瑜的愛護以及支持', '！', '更要感謝高雄市', '280', '萬市民朋友選我為高雄市長', '，', '一路陪著我走上這一段神奇的旅程', '，', '讓我有這個機會跟大家一起來做出對中華民國未來的改變', '，', '以及我們共同來創造未來', '。', '今天是公辦政見發表', '，', '所有的政見國防', '、', '內政', '、', '外交', '、', '交通', '、', '青年人的未來', '、', '毒品治安等等非常非常的多', '，', '國家要做的事情非常多', '，', '但是這麼多事情之前', '，', '有一個最重要的就是我們到底是什麼國家', '？', '我們現在到底在辯論什麼', '？', '我們是中華民國第', '15', '任總統的政見發表', '，', '還是', '「', '這個國家', '」', '的政見發表', '？', '蔡英文總統擔任總統三年半以來', '，', '從來沒有對國家講得清楚', '，', '前三年用', '「', '這個國家', '」', '來代替', '，', '所以今天我們政見發表是不是應該改名為', '「', '這個國家', '」', '政見發表會', '，', '還是中華民國總統的政見發表會', '？', '沒有國就不會有家', '，', '我長期一直問蔡英文總統到底要帶兩千三百萬同胞何去何從', '？', '蔡英文總統身為中華民國總統', '，', '享受到中華民國憲法授予的一切權力跟待遇', '，', '但是都是用', '「', '這個國家', '」', '來稱呼', '，', '所以請問蔡英文總統如果不把國家定位講清楚', '，', '我們後面的', '，', '我們政見說明有什麼意義', '？', '蔡英文總統眼前有三條路去選擇', '，', '我們看的非常清楚', '，', '第一', '，', '你根本就不愛中華民國', '。', '第二', '，', '你不要九二共識', '，', '我們國民黨的立場非常清楚', '，', '在中華民國完整的國格現任體制之下', '，', '發展兩岸的交流', '，', '是九二共識', '，', '你一定要扣一個帽子', '，', '叫做我們認同一國兩制', '。', '第三', '，', '我覺得蔡英文總統更講不清楚', '，', '而且完全對不起長期支持台灣獨立的朋友', '，', '很多台獨的朋友把選票投給蔡英文總統', '，', '希望台灣獨立', '，', '但是你完全讓他們失望', '。', '所以蔡英文總統必須有責任告訴我們台灣同胞', '，', '未來兩千三百萬民眾', '，', '到底何去何從', '？', '韓國瑜的立場非常清楚', '，', '我就是支持中華民國', '，', '捍衛中華民國主權', '、', '捍衛中華民國憲政體制', '，', '以及服務跟保護兩千三百萬台澎金馬的同胞生命財產', '，', '一清二楚', '，', '沒有任何含糊空間', '。', '如果蔡英文總統支持台灣獨立', '，', '也請大聲地講出來', '；', '如果不支持台獨', '，', '也請大聲地講出來', '，', '這樣子兩千三百萬民眾在投票給你的時候', '，', '才知道你要把我們帶到哪裡去', '。', '所以我希望蔡總統如果不支持台獨', '，', '請講清楚之後請跟著我的方向', '，', '我大喊三聲', '，', '我希望蔡英文總統你也大喊三聲', '：', '中華民國萬歲', '！', '中華民國萬歲', '！', '中華民國萬歲', '！', '希望你勇敢地喊出來', '，', '否則', '，', '請你喊出台灣獨立', '！', '我不支持台獨', '，', '但是你敢喊出來', '，', '我還是覺得', '，', '你是有勇氣的', '。', '第二個部分', '，', '人活著', '，', '要穿衣服', '、', '要吃飯', '，', '要受教育', '，', '要賺錢養家', '，', '但是人如果沒有一口空氣人是活不下去的', '。', '今天一個政府這麼多的事情要做', '，', '國防', '、', '內政', '、', '外交', '、', '交通', '，', '那麼多事情要做', '，', '但是各位台灣同胞', '，', '沒有一個清廉的政府', '，', '一切都是', '「', '竹籃子打水', '，', '一場空', '」。', '今天我們看看蔡英文總統領導的整個民進黨執政團隊', '，', '套一句台北市長柯文哲的講法', '，', '每一個都貪汙', '，', '我不相信', '，', '這句話我不相信', '，', '這句話太極端', '，', '但是我相信', '，', '你民進黨執政在蔡英文領導之下', '，', '很多人都在貪汙', '，', '這個我絕對相信', '。', '現在我們回想', '，', '為什麼民進黨執政', '，', '蔡英文總統你堅決要廢除特偵組', '，', '特偵組所有查辦的重大貪汙案件', '，', '立法委員', '、', '部長級以上', '，', '重要的國營事業以上總經理', '，', '凡是這種貪污', '，', '特偵組就會偵查', '，', '民進黨為什麼要廢除特偵組', '，', '很清楚', '，', '你為貪官汙吏開了一條路', '，', '讓他們一路有綠燈', '，', '不會被調查', '。', '各位台灣同胞', '，', '我們沒有清廉的政府', '，', '我們沒有一個有效率的政府', '，', '我們納稅人納再多的稅', '，', '我們再怎麼衝刺經濟', '，', '再怎麼發展', '，', '最後都是空的', '。', '貪官污吏充斥了整個政府', '，', '另外還有肥貓', '，', '這個像一個政府嗎', '？', '韓國瑜當上總統', '，', '我跟全台灣同胞報告', '，', '我一定立刻成立特偵組', '，', '馬上展開調查', '，', '為什麼要', '8800', '億', '？', '我們前瞻計畫為什麼花這麼多錢', '？', '為什麼我們風力發電要花兩兆台幣', '？', '為什麼我高雄市負債全國第一名', '3300', '億', '，', '特偵組一併調查', '，', '為什麼會欠這麼多錢', '，', '每一個高雄人身上背了將近', '9', '萬塊錢的債', '，', '為什麼', '？', '錢到哪裡去', '？', '另外', '，', '如果我選上總統', '，', '成立特偵組', '，', '我要拜託特偵組', '，', '我下台之後要對我像', 'X', '光一樣嚴密的檢查', '，', '我願意接受檢查', '。', '我在這裡同時呼籲全台灣所有的法官', '、', '檢察官', '，', '韓國瑜如果貪污', '，', '你們審查到我的案件', '，', '你們絕對不能讓我假釋', '，', '你們就把我關到死', '，', '我也呼籲全國典獄長', '，', '管監獄的', '，', '韓國瑜如果貪污被抓到監獄', '，', '你一天給我一頓飯就好', '，', '我沒資格吃三頓飯', '，', '哪有人用政府的權力來貪污的', '。', '今天要賺大錢去開公司', '，', '開公司賺大錢', '，', '你民進黨執政', '，', '你現在是在開政府賺大錢', '，', '世界上哪有這個道理', '？', '人民投票給政治人物', '，', '是希望謀求生活的快樂', '，', '大家能夠安居樂業', '。', '每一個公職人員有這個選票', '，', '有這個職務', '，', '要戰戰競競', '、', '為人民盡心盡力', '，', '怎麼能拿來貪汙', '、', '腐敗', '、', '亂投資', '，', '怎麼可以這樣子做呢', '？', '沒有一個清廉的政府', '，', '就絕對沒有辦法有一個乾淨的政治', '，', '就絕對沒有辦法有一個有效率的執政', '，', '這是雙胞胎', '。', '所以我今天開宗明義', '，', '我要跟全國台灣同胞宣佈', '，', '如果韓國瑜能選上總統', '，', '成立特偵組', '，', '針對這一段時間', '，', '大家懷疑的案件', '，', '展開立刻立案調查', '。', '另外對我韓國瑜本人', '，', '特偵組也必須一樣的標準來檢查我的團隊', '，', '所有韓國瑜用的政務官', '、', '用的國營事業董事長', '，', '如果貪汙', '，', '我拜託全國法官一樣讓他們不能假釋', '，', '我們一定要建立一個清廉的政治', '，', '沒有清廉的政治', '，', '臺灣在走向墮落', '，', '所以這是第一個階段', '，', '我要特別提出', '，', '到底國家目標是什麼', '?', '國家方向是什麼', '？', '我們叫做什麼國家', '？', '第二', '，', '我們必須要建立一個有效率的', '、', '乾淨的', '、', '廉潔的政府', '，', '而蔡英文政府完全沒有辦法達到', '，', '讓廣大的台灣人民失望', '，', '讓愛護民進黨的朋友失望', '，', '讓台獨的朋友失望', '，', '這不是我們要的政府', '，', '非常感謝', '。', '謝謝宋楚瑜主席', '，', '謝謝蔡英文總統對我的指教', '。', '蔡英文總統', '，', '我非常遺憾聽到妳剛才第一輪的論述', '。', '我跟妳談的是一個大海的問題', '，', '妳跟我談的是一個浴缸的問題', '。', '我跟妳談的是公部門', '，', '兩千三百萬台澎金馬同胞', '，', '我們的國家是什麼國家', '？', '要往哪一個方向', '？', '妳跟我談太平島開石油', '、', '我的房子的事情', '。', '妳為什麼我希望第二輪的時候妳繼續問我', '，', '我們家的柴米油鹽醬醋茶怎麼來的', '，', '醬油', '、', '麻油', '、', '醋是不是去偷來的', '。', '我覺得這個實在是這個問題的', '⋯⋯', '蔡英文總統的問題', '，', '我實在覺得非常地狹窄', '。', '我們今天追求的是中華民國兩千三百萬同胞最廣大的公部門的利益', '，', '是', '「', '台灣安全', '，', '人民有錢', '」，', '還是', '「', '台灣危險', '，', '人民貧窮', '」', '這麼重大的問題', '。', '我就舉最簡單的一個小例子', '，', '買房子', '。', '我從來選到現在沒有對蔡英文總統個人操守', '、', '品德', '，', '提出過任何質疑', '，', '我就說妳的團隊', '，', '因為我覺得這是一個候選人互相之間基本的尊重', '。', '我們夫妻去買房的貸款', '，', '千辛萬苦', '，', '最後付不起', '，', '忍痛殺出', '。', '拜託', '，', '蔡英文總統', '，', '妳', '30', '多歲時是買土地耶', '！', '我韓國瑜有說過嗎', '？', '妳買', '10', '幾塊土地耶', '！', '若干年之後', '，', '妳把土地全部賣了', '，', '妳賺了', '1', '億', '8', '千萬耶', '！', '我有說過嗎', '？', '我覺得這是一個尊重', '。', '太平島挖石油', '，', '我有說過高雄市要挖石油嗎', '？', '妳硬套到我的身上', '。', '何況這些媒體在黑韓的', '，', '網路帶風向', '，', '不就是妳民進黨一手在豢養的嗎', '？', '今天抓到的楊蕙如在網路帶風向', '，', '蔡英文總統勇敢告訴全國人民', '，', '沒有抓到的楊蕙如還有多少', '？', '妳用納稅人的錢養網軍', '，', '用網軍打擊政治對手', '，', '我都沒有說耶', '！', '妳居然說今天網軍跟媒體黑我的資料', '，', '妳拿在這裡政見發表會來提出來', '。', '我這真的妳講的口氣', '，', '真的聽得是我完全無法接受', '。', '而且我根本就不怕面對這些問題', '，', '但是我們希望能夠探討更廣大的國家前途跟未來', '。', '誠如妳剛剛結束的時候', '，', '第一段妳說', '，', '蔡英文總統值得信賴', '，', '經濟發展的這麼好', '，', '克服了一切困難', '。', '各位親愛的', '、', '我們台灣同胞', '，', '2016', '年', '，', '蔡英文總統當第一年總統', '，', '兩千三百萬人選一個字', '，', '代表那一年台灣人民廣大的心聲', '，', '是什麼字', '？', '辛苦的', '「', '苦', '」；', '第二年', '，', '2017', '年', '，', '妳繼續當總統', '，', '年底', '，', '台灣人民選什麼字代表台灣人心聲', '？', '茫然的', '「', '茫', '」；', '第三年', '，', '2018', '年台灣人民選什麼字', '，', '翻轉的', '「', '翻', '」；', '今年', '2019', '年', '，', '妳當了第四年總統', '，', '台灣人民用一個字表達心中的廣大的心聲', '，', '是什麼字', '？「', '亂', '」，', '亂七八糟的亂', '。「', '苦', '、', '忙', '、', '翻', '、', '亂', '」，', '然後妳告訴大家', '，', '妳執政地非常好', '，', '亞洲四小龍老大', '。', '拜託蔡總統', '，', '真的紮紮實實地執政', '，', '讓人民感動化為行動繼續投妳一票', '，', '不要用欺騙', '，', '用這些數字', '。', '我這邊一個板', '，', '請大家看清楚', '，', '我為什麼那麼擔憂台灣的未來', '。', '蔡英文總統說', '20', '年來經濟最好', '，', '2018', '年蔡英文總統執政', '，', '有三萬家公司創下全部解散', '，', '比前一年', '2017', '年增加', '30', '％；', '2018', '年', '，', '我們歇業的工廠', '，', '高達', '4000', '家', '，', '比前一年增加', '45', '％；', '2019', '年', '，', '我們', '10', '月份出口訂單連續', '、', '連續', '12', '個月負成長', '，', '妳還要說我們是亞洲四小龍最好', '；', '2019', '第三季就是今年第三季', '，', '我們整個製造業的生產值成長下降', '，', '負成長', '7', '％；', '2019', '年', '10', '月份景氣概況連續', '10', '個月', '，', '我們是轉虛弱的黃藍燈', '；', '也是今年', '，', '妳自己用的金管會的主委顧主委顧立雄所公佈的', '，', '今年前三季全台灣股票上市公司損失', '、', '衰退將近', '20', '％。', '另外', '，', '我再告訴一個可怕的數字', '，', '2018', '年我們統計台灣勞動階層不到', '30', '歲', '，', '一年實質收入只有', '39', '萬', '2000', '塊', '，', '比', '1998', '年', '、', '20', '年前的', '43', '萬', '3000', '塊', '，', '還要低', '4', '萬塊', '。', '這都是妳的政府公佈的數字', '，', '這麼差的成績', '、', '這麼差的經濟表現', '，', '妳還要告訴台灣人民', '，', '我們經濟好得不得了', '，', '蔡總統', '，', '面對問題', '、', '解決問題', '、', '突破困難', '。', '臺灣人心軟', '，', '會因為感動投妳一票', '，', '可是不能用欺騙的數字', '。', '妳動不動講觀光業創下歷史最高', '，', '公佈的', '1100', '萬的觀光客到台灣', '。', '親愛的台灣同胞', '，', '現在民進黨怎麼統計數字', '？', '是只要轉機', '，', '兩隻腳踏進桃園中正機場', '，', '不進台灣轉飛出去的外國人', '，', '也算一個觀光客', '。', '麻煩妳苦民所苦', '，', '接近基層民眾', '，', '看一看觀光業', '、', '遊覽車', '、', '計程車', '、', '餐廳', '、', '民宿', '、', '伴手禮', '（', '御土産', '/', 'おみやげ', '），', '甚至賣茶葉的茶農', '、', '賣珊瑚的商人', '，', '你去問一問', '，', '真的是淒慘的', '「', '慘', '」，', '慘得不得了', '。', '高雄市遊覽車公會理事長', '128', '輛遊覽車', '、', '128', '輛', '，', '妳執政三年', '，', '妳知道他現在剩下多少輛嗎', '？', '他只剩下', '1', '輛', '，', '賣掉了', '127', '輛', '。', '然後妳還要告訴全台灣同胞說我們觀光業非常好', '？', '不斷地欺騙', '，', '我覺得我們完全無法忍受', '！', '妳說台商大量投資回台灣', '，', '妳很驕傲地跟國人宣布', '，', '7000', '億台幣', '，', '結果一查', '，', '0', '！', '1', '毛錢沒有回台灣', '，', '這個都不斷地欺騙', '。', '為什麼啊', '？', '為什麼不能開大門', '、', '走大路', '？', '為什麼治理國家要用欺騙的數字', '，', '要走邪魔歪道', '？', '我是百思不得其解', '。', '台灣人民這麼信任妳', '，', '這麼信任民進黨', '，', '讓你們立法院過半', '，', '妳就好好執政', '，', '讓我們老百姓能夠安居樂業', '，', '票就自然投妳了嘛', '！', '怎麼不斷地欺騙呢', '？', '另外一點', '，', '我還要跟全臺灣同胞講', '，', '蔡英文總統執政', '，', '我們所有對外貿易', '，', '台灣已經變一個孤兒了', '。', '大家看一看', '，', '明年開始', '，', '我們整個', '，', '在我左邊這一圈', 'RCEP', '所有的國家', '，', '韓國', '、', '中國大陸', '、', '印度尼西亞', '、', '寮國', '、', '泰國', '，', '全部變一個經濟圈', '；', '然後以日本為主', 'CPTPP', '，', '又是一個圈', '，', '加拿大', '、', '墨西哥', '、', '智利', '；', '全台灣', '，', '然後中間重疊的有日本', '、', '馬來西亞', '、', '汶萊', '、', '新加坡', '、', '澳大利亞', '、', '紐西蘭全部互相經濟整合', '。', '各位親愛的臺灣同胞', '，', '看看我們中華民國國旗', '，', '我們變成國際經濟的孤兒啊', '，', '我們進不去啊', '。', '我們所有的產品將來進去', '，', '賣到這些國家全部要加關稅', '，', '他們互相零關稅或者優惠關稅', '。', '我們東西賣不出去', '，', '人進不來', '，', '民進黨執政台灣怎麼發大財', '？', '如何發大財', '？', '如何讓人民安居樂業', '，', '這個圖清清楚楚', '。', '蔡英文總統妳執政三年半', '，', '妳沒有在所有自由貿易簽訂裡面', '，', '得到任何突破啊', '。', '連陳水扁總統當總統都可以用中國台灣加入各種國際組織開會', '，', '馬英九總統是用中華台北', '，', '我們現在外交在妳當總統之下', '，', '一步都走不出去呀', '，', '再加這個經濟圈', '，', '我們未來怎麼得了', '。', '所以我覺得蔡英文總統我們很多一句話', '，', '知恥近乎勇', '，', '妳民進黨執政三年半真的不行', '，', '台灣人民用苦', '、', '忙', '、', '翻跟亂表達心聲', '，', '妳要面對這個問題', '。', '如果妳希望台灣人給妳這個機會妳要先承認', '，', '過去四年的執政真的是一敗塗地', '。', '我覺得台灣人民或許會感動', '，', '但是不能再用欺騙的方法', '，', '欺騙的數字', '，', '來告訴大家', '，', '妳的經濟做得非常好', '，', '我相信我們絕對無法接受', '。', '再次謝謝主持人', '，', '謝謝蔡英文總統對我的指教', '。', '各位親愛的台灣同胞', '，', '政治應該是很單純的', '，', '選票多的人', '，', '獲得執政權', '，', '選票少的去監督', '，', '政治是非常單純', '。', '不管是執政或者監督', '，', '都要一心一意為人民努力', '，', '打拼', '，', '我時常講', '，', '我去宮廟拜拜', '，', '我的感慨特別多', '，', '天上最大的神是玉皇大帝', '，', '最小的神是住在家裡隔壁的土地公', '。', '台灣社會最大的官是總統', '，', '最小的是村長', '、', '里長', '。', '不管是玉皇大帝', '、', '土地公', '、', '總統', '、', '村里長', '，', '都應該只有一個目標', '：', '保護人民', '、', '讓人民安居樂業', '。', '但是為什麼單純的政治會變複雜', '？', '甚至變得黑暗', '？', '因為人性讓他變得複雜跟黑暗', '，', '人性太多的慾望', '、', '金錢', '、', '權力', '，', '使得整個政治被扭曲', '，', '這段話完全可以答覆剛才蔡英文總統對我的質疑', '，', '我去香港中聯辦', '，', '就隱射韓國瑜好像要賣台', '。', '我請問蔡總統', '，', '今天民進黨在中央的三巨頭', '，', '妳本人', '，', '妳的副手賴清德副總統候選人', '、', '你的秘書長陳菊', '，', '你們三巨頭去過中國大陸沒有', '，', '有沒有跟高級長官', '，', '中國大陸共產黨高官吃過飯', '、', '喝過酒', '、', '談過話', '、', '聊過天', '、', '照過相', '？', '有沒有', '？', '你們派出的日本大使謝長廷', '2013', '年到香港', '，', '中聯辦從頭到尾陪著他', '，', '各位親愛的台灣同胞', '，', '政治是單純的', '，', '人性讓他複雜', '。', '蔡英文總統', '、', '賴清德', '、', '陳菊', '3', '位', '，', '去過中國大陸', '，', '可是今天誰能說蔡英文', '、', '陳菊', '、', '賴清德', '、', '謝長廷不愛台灣', '？', '沒有人敢這樣講', '，', '我們只能說你的執政', '、', '你的團隊出了問題', '。', '蔡英文執政團隊有貪污', '、', '腐敗', '、', '施政無方', '，', '有這種現象', '，', '誰敢講你的團隊不愛台灣', '？', '你們可以去隨便照相喝酒談話', '，', '韓國瑜不行', '，', '謝長廷去中聯辦接待可以', '，', '我帶的高雄市', '10', '位議員', '，', '帶著官員去吃飯喝酒', '，', '希望將來保持良好關係', '，', '把台灣的水果', '、', '蔬菜', '、', '雞蛋', '、', '雞肉', '、', '鴨肉', '、', '鵝肉', '、', '豬肉', '、', '花朵能夠大量外銷出去', '，', '也吸他們觀光客來台灣', '、', '來高雄', '，', '我有什麼錯', '？', '為什麼你們去就不是出賣台灣主權', '？', '為什麼我去就是出賣台灣主權', '？', '是不是蔡英文總統妳對台灣民主完全沒有信心', '？', '我覺得這個就是蔡英文總統所講的', '，', '政治是單純的', '。', '因為慾望', '，', '妳把事情搞複雜了', '，', '妳應該還我一個清白', '。', '在這', '，', '大家都說', '，', '我在高雄才做了幾個月就出來選總統', '，', '親愛的高雄市民', '、', '親愛的台灣同胞', '，', '事情不在難不難', '，', '事情在於有沒有心', '。', '我把這個板子拿出來', '，', '我不做自我宣傳', '，', '大家可以看一看', '，', '高雄這一年', '，', '韓國瑜加上所有韓國瑜的團隊', '，', '我們前', '10', '個月農產品是去年外銷的', '3', '倍', '；', '去年兩億一千萬', '，', '我們今年賣了六億多', '；', '第二', '，', '高雄觀光', '，', '我們', '2019', '年上半年', '，', '我們住房率成長', '21', '％。', '另外清水溝', '，', '韓國瑜當高雄市長', '，', '200', '公分的衛生下水道阻塞了', '195', '公分', '，', '水只能流', '5', '公分', '，', '10', '、', '20', '年都沒有人清理', '，', '過去', '10', '、', '20', '年誰在執政', '，', '妳民進黨在執政', '，', '所以登革熱這麼囂張', '，', '到處淹水', '。', '蔡英文總統你應該跟高雄市民道歉', '。', '因為我韓國瑜團隊', '，', '花了九牛二虎之力', '，', '去挖這些', '，', '所以今年登革熱才沒有大爆發', '、', '沒有淹水', '，', '因為水溝', '200', '公分的衛生下水道阻塞了', '195', '公分', '。', '再來學生開始裝冷氣', '，', '未來', '6', '萬的高雄孩子要吹冷氣', '，', '因為工業污染區非常嚴重', '，', '高雄支撐了台灣重工業', '60', '％，', '但是高雄的孩子在讀書', '，', '這麼炎熱的天', '，', '空氣又不是這麼的好', '，', '我們幫他裝冷氣', '。', '再來', '，', '很多家庭經濟不好', '，', '禮拜六', '、', '禮拜天不上課', '，', '沒有營養午餐', '，', '我們發愛心餐券', '，', '我們已經發了', '113', '萬張', '，', '113', '萬張愛心餐券', '，', '怕孩子禮拜六', '、', '禮拜天寒假暑假會餓肚子', '；', '再來未婚媽媽', '，', '很多女學生懷孕不知道人生該怎麼辦', '，', '我們成立未婚媽媽的珍珠之家', '。', '妳來', '，', '政府一定照顧妳', '，', '妳不要害怕', '，', '妳也不孤單', '，', '這是高雄首創', '。', '再來雙語教育', '，', '高雄市是全台灣現在衝刺雙語教育第一名', '，', '我們這麼財政這麼困難', '，', '擠出兩千七百萬', '，', '開拓雙語教育', '，', '今年達到', '24', '所', '，', '明年預計有', '48', '所', '。', '再來最後一點', '，', '空污', '，', '我們跟台電談判', '，', '所有興達火力發電廠', '，', '拜託你在冬天的時候', '，', '千萬要降低', '，', '興達火力發電廠同意', '。', '我們降低生煤', '。', '蔡英文總統', '，', '你的能源政策', '，', '你大量地燒煤炭', '，', '要花兩兆蓋風力發電', '，', '你知道現在中部人有多痛苦嗎', '？', '台中', '、', '彰化', '、', '苗栗', '、', '南投', '、', '雲林', '，', '你知道現在台灣肺癌死亡率是全亞洲第二', '，', '每', '1', '年發生連環車禍有人傷亡我們心裡都很難過', '，', '每一年有', '1', '萬人死於肺腺癌', '，', '你執政這', '3', '年半你自己去中部看一下那邊的空氣', '，', '看看那個空汙', '，', '中部人的肺都快爆炸了', '！', '而且不抽香菸的佔百分之', '50', '，', '死亡的肺腺癌不抽香菸佔', '50', '％，', '就是你能源政策一錯再錯', '，', '我們強力改善高雄空氣', '，', '已經達到', '76', '.', '4', '％。', '各位親愛的台灣同胞', '，', '真的', '，', '政治沒有這麼複雜', '，', '凡是乾淨選舉', '，', '一定乾淨執政', '，', '凡是骯髒選舉', '，', '一定骯髒執政', '，', '千古不變', '，', '我們全力衝經濟', '。', '但是政治人物有兩大神聖目標在我們的肩膀上', '，', '絕對不能忘記', '，', '我們賺了錢', '，', '繁榮了臺灣的經濟', '，', '我們最重要這兩大目標', '，', '第一個', '，', '辦好教育', '，', '第二個', '，', '關心弱勢', '，', '這是我們神聖的工作', '，', '也是我們對選民最重要的承諾', '。', '親愛的台灣同胞', '，', '現在臺灣的危險', '，', '我想了我都擔心', '、', '害怕', '。', '我的年紀已經大了', '，', '我也知道我的來日無多', '，', '我這一代人很快就會凋謝', '，', '我們要把這個棒子交給下一代', '，', '我們辦不好教育', '，', '下一代沒有辦法比我們更強大', '，', '我們這一代人有什麼臉面對下一代', '，', '世上苦人這麼多', '，', '台灣將近有一百四十萬左右的身心障礙跟弱勢族群', '，', '我們不去照顧他誰要照顧他', '？', '所以希望大家能夠睜亮眼睛了解台灣的處境', '，', '週邊的國家已經沒有一個看得起台灣了', '，', '世界開始忘記台灣', '、', '台灣也開始忘記了世界', '，', '我們一定要打開門全力迎接世界接軌', '，', '全力培養下一代只要不貪污', '，', '只要不貪汙', '、', '我們錢一定夠用', '，', '我們大力栽培我們下一代孩子', '，', '讓他們跟國際接軌', '，', '整個台灣一定要欣欣向榮', '，', '這四年我們被鎖住了', '，', '每一個人心裡都覺得好悶', '，', '像全民大悶鍋一樣', '，', '大家眉頭深鎖', '。', '用四個字代表民進黨蔡英文總統的執政', '，', '我剛才說過', '「', '苦', '、', '忙', '、', '翻', '、', '亂', '」，', '我們一定要改變', '。', '我們再不奮起直追', '，', '我們再不追分趕秒', '，', '沒有人', '、', '沒有人會像台灣人一樣', '，', '這麼愛台灣', '。', '我們同舟共濟', '，', '都在一條船上', '，', '讓我們全體台灣同胞', '，', '我們自己努力加油', '，', '選出最棒的總統', '、', '最好的立法院', '，', '願台灣人民幸福', '，', '願中華民國萬歲', '！', '謝謝', '！'], ['主持人', '、', '監察人', '、', '兩位候選人', '、', '各位海內外的同胞', '、', '各位鄉親', '，', '大家好', '。', '我是中華民國第', '15', '任總統候選人宋楚瑜', '。', '我首先應該向諸位報告', '，', '我為什麼參選', '？', '我對今天中華民國在台所面臨的國內外環境和未來', '，', '我們應該了解得到', '，', '如何去處理很多重大問題', '。', '宋楚瑜經歷', '44', '年從政經驗', '，', '我追隨蔣經國先生', '、', '孫運璿先生', '、', '李登輝先生', '，', '我從他們那裡學習到很多治國的重大的絕學', '。', '我想在我有生之年', '，', '把這些我所學到的經驗', '，', '奉獻給我心愛的國家中華民國', '。', '我自信我不僅有經驗', '，', '有能力更有執行力', '，', '但是我沒有包袱', '，', '我沒有私心', '，', '我只有包容和一直保持從政的初心', '，', '那就是腳踏實地', '，', '認真地為人民好好地處理好他們希望政府處理的事', '。', '我是一個身體力行來推動民主主義的實踐者', '。', '我曾經全程參與過', '，', '我們初次台灣', '，', '從威權體制轉型成開放的民主', '，', '解除戒嚴', '、', '開放黨禁', '、', '解除報禁', '、', '修改刑法', '100', '條', '，', '讓台灣人不會再因為政治理念不同而被判為政治犯', '，', '同時我也曾全程地參與終結萬年國會', '，', '推動總統直選這些重要的民主化的過程', '。', '坦白地說', '，', '當時在推動這些過程當中', '，', '連當時的國民黨內部還是有不同意見', '，', '但我很自豪地說', '，', '宋楚瑜是重要的民主的推手', '，', '並且曾經做出關鍵的貢獻', '。', '今天臺灣面臨的環境', '，', '跟全世界一樣', '，', '都面臨了六項重大的危機', '。', '第一', '，', '是劇烈氣候變化的危機', '。', '第二', '，', '是人口結構改變的危機', '，', '也就是老人化跟少子化', '。', '第三', '，', '是國際區域經濟整合重組的危機', '，', '如何避免台灣被邊緣化', '，', '這是未來我們必須要去處理的重大危機', '。', '第四', '，', '是因為數位科技所帶來的產業結構的轉型', '，', '也帶來對於我們傳統中小企業的衝擊的危機', '，', '造成可能會有失業', '，', '我們必須要重視這些挑戰', '。', '第五', '，', '是貧富差距擴大的危機', '，', '讓人民感覺到生活不下去', '。', '而最後也是最重要的', '，', '那就是我們也面臨了', '，', '全世界也同樣面臨的', '，', '叫作人文', '、', '價值淪喪的危機', '。', '道德', '、', '人與人之間的感情和處理', '，', '這都是政府必須要去處理的重大挑戰跟危機', '。', '台灣面臨這樣的非常之局', '，', '必須要有非常之人才能處理這些非常之事', '，', '而必須要用非常的努力才能盡非常之功', '。', '而這六項危機如何處理', '，', '我會在下次政見發表會再詳細地向大家報告', '，', '我對處理這些問題的方法', '。', '但是', '，', '當我們看到全世界面臨這些危機的時候', '，', '但是台灣明年面臨所面臨的狀況可能還有一個更重要的坎', '，', '我很清楚地說我們作為中華民國的領導人', '，', '必須認識四個地方', '：', '美國', '、', '日本', '、', '大陸', '、', '台灣', '。', '美國跟日本', '，', '明年的動態我們必須密切注意', '，', '中國大陸跟台灣能不能夠建立建設性的對話管道', '，', '這四個相互關聯的問題', '，', '明年都可能有一些微妙的變化', '，', '我們必須重視', '，', '預為綢繆', '。', '具體來說', '，', '我們兩個很重要的盟友', '，', '日本跟美國', '，', '明年三月份', '，', '中國大陸的領導人習近平將到日本進行國是訪問', '，', '而日本更會在明年的八月份邀請習近平再度去到東京參加奧運', '，', '因為日本奧運需要大陸的觀光客', '。', '而美國要求日本支付天文數字的美軍駐日的開銷以及加稅', '，', '把日本跟大陸越推越近', '。', '而美國方面', '，', '明年', '11', '月', '，', '美國的總統大選', '，', '當日本跟大陸的關係因為經濟因素拉近', '，', '美國跟大陸的關係也因為經濟的因素', '，', '他們已經彼此有交換', '，', '而大陸明文ㄉ承諾', '，', '將對美國採購超過', '500', '億美元的農產品', '，', '這個也是因為美國的川普總統要面臨大選', '，', '要爭取美國農業州的選票', '。', '這些變化我們可以掉以輕心嗎', '？', '所以我們要有一位能夠洞察世局變化具國際觀和國際溝通經驗的國家領導人', '，', '妥為因應', '。', '然而台灣最大問題還不是國際性的', '，', '是藍綠所築起的對決高牆', '。', '藍綠兩大黨面對問題的對策', '，', '就是一方面講藍軍要團結', '，', '一方面要講', '，', '綠軍也要團結', '。', '當我們的社會跟國家陷入藍綠', '，', '在那邊相互對戰', '，', '撕裂對立', '，', '而對於台灣這些急切需要去解決的重大問題', '，', '藍綠兩大黨都不願面對現實', '，', '只想相互杯葛', '，', '看對方出狀況', '，', '看對方鬧笑話', '，', '相互消磨', '，', '以對方的失敗來造就自己成功的機會', '，', '來獲取下一次選舉的勝利', '。', '這就是為什麼今天台灣', '，', '我們這麼多的鄉親這麼討厭政黨', '，', '因為各位鄉親了解得到台灣真正需要一位腳踏實地', '，', '以真正的行動', '，', '和他內心真正地感受得到要放下藍綠', '。', '宋楚瑜就是那一位不計個人毀譽', '、', '奮不顧身去為台灣打拼的人', '。', '因為我深信', '，', '我們雖然有不同的過去', '，', '但是我們卻有共同的未來', '，', '我們更有共同守護的價值', '，', '那就是我們珍惜今天在台灣', '，', '我們奮鬥這麼多年來所創造的我們自由民主的價值', '。', '因此', '，', '我們要守護這塊土地', '、', '守住我們共同的價值', '，', '那就是要選一位能夠真心誠意', '、', '放下藍綠', '，', '而真正讓我們全民在一起共同創造我們台灣未來的願景', '，', '讓全世界看到台灣的自由民主的價值', '，', '是不分黨派', '、', '不分族群', '、', '不分年齡', '，', '共同只有民主的價值是我們共同的', 'DNA', '。', '我們絕不放棄自由民主的制度', '，', '我們願為這一個時刻來選一個為大家服務的好總統', '，', '謝謝', '。', '各位親愛的朋友們', '，', '各位鄉親', '，', '聽到剛剛這兩位所發表的這些看法', '，', '就像我在參加這次的政見發表之前', '，', '我的同仁就跟我說', '，', '我相信蔡總統會把她這三年多以來的政績向大家來報告', '，', '而韓市長', '，', '我相信他會準備很多資料', '，', '來挑戰蔡總統所說這許多她的政績', '。', '我不需要再重複地把剛剛韓市長所說的', '，', '他準備的這些圖表', '，', '我相信回頭由蔡總統自己本身來做一些解說', '。', '坦白講', '，', '我們今天看到台灣面臨的環境', '，', '跟他們兩位所講的一樣', '，', '我們要面對世界變局', '。', '但是很顯然', '，', '確實台灣逐漸地被世界主流這些經濟體', '，', '把我們邊緣化了', '。', '坦白嚴格來講起來', '，', '剛剛蔡總統講到她這三年多來以來', '，', '她確實想要去推動一些改革', '。', '其實政治管三件事情', '。', '哪三件', '？', '管的就是政策', '，', '管的是資源分配', '，', '管的是用人', '。', '在民進黨這幾年的執政之下', '，', '我們看到蔡總統曾經反覆地說', '，', '她要追求社會的正義', '。', '以蘭嶼剛剛來說', '，', '不是靠道歉就可以去解決他們心中許許多多的這些不平', '。', '嚴格地講起來', '，', '何止是蘭嶼的鄉親', '、', '原住民', '，', '妳去看看三鶯地區', '，', '我們有多少原住民現在幾乎', '46', '％', '以上的', '，', '我們的原住民鄉親', '，', '都從山上部落已經到了我們平地', '。', '但是他們工作的問題', '、', '他們住的問題', '、', '他們的小朋友教育的問題', '、', '他們老人照顧的問題', '，', '坦白講不是用口去講', '，', '而是要去幫他們去解決這些問題', '。', '我們把今天看了那麼多的電', '，', '你去到了蘭嶼看', '，', '核廢料放在他們那裏', '，', '但到了夏天', '，', '我們蘭嶼的鄉親在迎接更多的觀光客', '，', '在民宿的地方', '，', '竟然停電', '，', '沒有電', '。', '花幾百萬塊錢', '，', '重加幾組發電機就可以解決的問題', '。', '有上百億的這些核廢料', '，', '這些預備金都沒有去幫他們去解決', '。', '我如果有機會回到政府', '，', '就像我走遍我們所有的', '55', '個原住民的鄉一樣', '，', '我會幫他們好好的', '、', '很快的把住的問題把都市住的問題', '，', '我們許許多多原住民的這些許多民宿的問題', '，', '我會好好幫大家去解決', '。', '蔡總統特別提到了改革要有魄力', '，', '但改革更需要的是方法', '，', '改革更重要的是要真正了解到', '，', '溝通是一個必要的手段', '。', '蔡政府在過去這幾年推動的幾項重大改革', '，', '坦白講', '，', '引起來的這些抗爭', '，', '那就是改革胡亂暴衝', '。', '為什麼我說改革暴衝呢', '？', '沒有經過行政院各部會跟立法部門好好研商', '，', '反而看到行政跟立法的脫勾', '，', '年金改革就是這樣一個例子', '。', '明明國民黨那邊妳索取清查他的黨產', '，', '婦聯會已經交出', '370', '億', '，', '這麼多錢可以把那些過去老兵這麼多平均', '84', '歲老兵的錢', '，', '你一毛不要去減少它', '，', '他們現在平均年齡', '84', '歲', '，', '一共現在從民國', '38', '年到台灣', '，', '還剩下只剩下', '10', '萬', '1225', '人', '，', '從', '79', '萬變成今天只剩下', '10', '萬多人', '，', '讓他們好好地在台灣', '，', '曾經為他們為台灣安全國防提出這麼多貢獻', '，', '但是為什麼要去扣他們一點點安老的錢呢', '？', '我曾經向陳副總統提出這些問題', '，', '我也曉得他想要去做些改革', '。', '改革要有方法', '，', '改革的財源明明有但是不會用', '。', '所以因此我們不管是年金改革', '、', '一例一休', '、', '公投法的所有這些事情', '，', '不過', '，', '每一次改革', '，', '只是讓被改革的人期待下一次的政黨輪替再改回來', '，', '台灣經得起這樣子不斷地折騰嗎', '？', '因此', '，', '我特別提到最近蔡總統也一樣到了高雄', '，', '但是韓市長沒有把這個問題講清楚', '，', '我也希望韓市長也特別了解一下', '，', '高雄你們在那邊所講的許許多多那些天花亂墜的話', '，', '國民黨', '、', '民進黨都要負責任', '。', '當年高雄港外面有多少船想進高雄還排不進去', '，', '我們那時候號稱要做亞太營運中心', '，', '卻戒急用忍', '，', '不跟大陸商來往', '。', '蔡英文開出了四道未來在高雄的大南方計畫', '，', '我隨便講一件事情', '，', '那就是所謂要有聚集的這一些問題要去處理好', '。', '您所說的要讓我們南方將來能夠聚落來帶動產業', '，', '請問五缺的問題解決了嗎', '？', '水在哪裡', '？', '電在哪裡', '？', '勞工在哪裏', '？', '優秀人才在哪裡', '？', '我們現在土地取得容易嗎', '？', '五缺的問題還在那裡', '。', '但是我很痛心地說', '，', '這些改革坦白講都不但沒有解決', '，', '反而是民進黨這些派系他們都不缺', '。', '你看所有這些重要的這些許許多多的職務', '，', '諸侯在分贓', '，', '人事酬庸', '，', '把重要職務', '、', '國營事業經營', '，', '都變成派系分贓的囊中物', '。', '所以因此這兩個政黨為什麼會變成台灣最大的兩個黨', '？', '一個叫做討厭國民黨', '，', '一個叫做討厭民進黨', '，', '大家都覺得', '，', '你們開了很多支票卻沒有辦法去兌現', '。', '其中關鍵的一件事情', '，', '就是要把兩岸問題處理好', '。', '蔡總統在', '2016', '年', '，', '您在總統選舉政見會辯論的時候', '，', '您曾經公開的說', '，', '兩岸問題絕不能被選舉拿來操弄', '，', '但很顯然', '，', '您開始有聽見我的話', '，', '那就是要把', '《', '中華民國憲法', '》', '跟', '《', '增修條文', '》', '以及', '《', '兩岸關係條例', '》', '作為基本架構', '，', '但是一到了選舉', '，', '很可惜您還是被那些派系綁架', '，', '把兩岸問題拿來作為選舉的操作', '，', '來製造一些情緒勒索', '，', '這些情緒勒索讓大家覺得不安', '。', '但是我必須說', '，', '台灣人真是要有自信', '，', '台灣民主價值是什麼', '？', '就是台灣人才是這塊土地的我們的真正主人', '，', '沒有任何人能夠出賣台灣', '，', '也沒有任何人能夠不重視我們的民意而妄做任何的決定', '。', '因此', '，', '我們需要一個真正解決問題的領導人', '。', '領導的人要有決斷力沒有錯', '，', '像蔡總統剛剛所說的', '，', '但是他的團隊要有紀律', '，', '不能夠在那邊胡搞瞎搞', '。', '要有策略', '，', '要能夠整合民意', '，', '最重要的是要有真正的經驗', '，', '能夠整合不同的這些意見', '，', '然後拿出可行的辦法', '。', '我有這個履歷表', '，', '我曾經操盤過台灣民主發展的過程', '，', '我也領導過省府團隊', '，', '謝謝', '。', '我剛剛聽到韓市長講的這段話', '，', '我可以說', '，', '韓市長你非常認真希望把高雄市好好辦好', '，', '繼續留在高雄', '，', '把你未完成的事情好好完成', '，', '我當選總統之後', '，', '我一定不會像民進黨那樣小裡小氣', '，', '我會大力支持你', '，', '讓你的夢想成真', '，', '讓高雄市民覺得唉呀我們終於培養出一個好的未來領導人', '。', '相對地', '，', '我也特別跟剛剛蔡總統特別提到的', '，', '那就是在選舉的時候', '，', '大家不要製造恐慌和戴帽子', '，', '嚴格講起來', '，', '蔡總統剛剛最後這段話非常重要', '，', '兩岸的問題', '，', '他所說的這些四點非常重要他的看法', '，', '我在這個地方也要向各位鄉親特別表達', '，', '楚瑜在這邊鄭重地宣示', '，', '我只做一任', '，', '在我這一任', '，', '我將撥亂反正', '，', '未來這四年', '，', '獨立和統一都不可能', '，', '但是宋楚瑜捍衛中華民國主權', '，', '堅持維護台灣自由民主的決心絕不改變', '，', '只求臺灣勝', '，', '中華民國贏', '，', '只做一任撥亂反正', '\\\\*', '3', '，', '因為很重要所以要說三遍', '。', '我為什麼要特別強調呢', '，', '那就是今天我們台灣面臨的環境', '，', '剛剛總統特別提到', '，', '就是兩岸問題必須好好地處理好', '，', '台灣的民主必須讓全世界覺得', '，', '這塊土地', '，', '我們台灣人自己能夠管好自己', '，', '我們要證明我們的治理是有效的', '。', '所以我作為中華民國人民選出的總統', '，', '我將來一定會樹立範例', '，', '那就是宋楚瑜未來的四年', '，', '要做五件重要的事情作為優先', '：', '第一', '，', '我要把國家的利益放在前面', '，', '把政黨的利益放在兩邊', '。', '我當選之後會邀請各黨各派的領導人到總統府共商國事', '，', '聽取不同政黨聲音', '，', '把當前台灣面對許許多多', '，', '包括兩岸問題', '、', '年改問題', '、', '健保問題', '，', '我希望聽大家不同的聲音', '，', '而且我會要求未來任命的行政院長要例行地到各個縣市好好溝通', '，', '資源共享不分黨派不分族群', '，', '而不是到選舉的時候鬥嘴', '。', '這是我非常堅持一定會說到做到的事情', '。', '第二', '，', '我會認真地網羅各黨各派的人才組成', '「', '大聯合政府', '」，', '換言之', '，', '過去幾任總統以來', '，', '把我們文官制度幾乎完全破壞了', '，', '我們要重新找回我們公務人員的榮譽', '。', '我簡單講一個事情', '，', '我在省政府的時候對一位公共衛生員在雲林', '，', '他去發現一位學生患了開放性的肺結核', '，', '他馬上繼續追蹤他的家人', '、', '學校同學有沒有', '，', '結果發現從一個案子發現', '2000', '個', '，', '一一追蹤幫他們治療', '，', '這就是一個公務員應盡的責任', '，', '讓我很感動', '，', '我對她一再表揚', '。', '大肚火車站交流道', '，', '因為枕木的下陷', '，', '出了車禍', '，', '去處理善後', '，', '不是只有去修這個交流道', '，', '全省', '770', '個這些交流道', '，', '欲全部重新好好地把它整修', '，', '這就是我們真正公務人員', '，', '我對這些省政府的以前老同仁', '，', '你們的貢獻', '，', '你們自認為是一個好的公務員的榮譽感要找回來', '，', '楚瑜會說到做到', '。', '第三', '，', '我會任命', '，', '立法院能夠同意的人來擔任行政院長', '，', '總統依照現在的憲法修改之後可以自由任命行政院長', '，', '但我向大家保證', '，', '總統的權力是要傾聽民意', '，', '要得到民意有基礎的人來當行政院長', '，', '宋楚瑜也說到做到', '。', '第四', '，', '我會尊重民意', '、', '尊重立法院', '，', '我當選後每年一定會到立法院做國情報告', '，', '直接聽取各政黨提問', '、', '聽他們意見', '，', '找回台灣民主的價值', '，', '做一個向人民負責的國家領導人', '。', '第五', '，', '作為中華民國總統要遵守憲法', '，', '要遵守中華民國憲法和增修條文', '，', '以及兩岸關係條例的精神來處理好兩岸關係', '，', '要在三個前提之下', '，', '這就是我回應剛剛蔡總統的話', '：', '一', '、', '尊重中華民國政府存在的事實', '，', '不諱言的', '，', '兩岸還存有政治經濟社會的差異', '，', '需要時間化解', '，', '因此兩岸要對等分治', '，', '共同努力', '，', '來求同化異', '。', '二', '、', '要用和平對等', '、', '有尊嚴的協商方式', '，', '解決兩岸爭議', '。', '三', '、', '確保台灣自有民主法治多元的共同價值的生活方式絕不妥協', '。', '如果兩岸有重要的協商結果', '，', '我一定親自到立法院報告', '，', '沒有台灣人民的同意我絕對不會輕作承諾', '，', '我確信台灣只有一個底線', '，', '任何台灣現狀的改變都要得到台灣', '2300', '萬人民用民主方式共同決定', '，', '而維護亞太地區的和平與安定', '，', '是我們中華民國政府對世界所應該盡的責任', '。', '因此目前', '，', '大家對於九二共識', '，', '或是對岸目前這些所謂滲透等等的話', '，', '我要跟蔡總統特別提醒', '，', '反滲透法如果', '12', '月', '31', '日你要強行通過的話', '，', '我到安全局去聽過簡報', '，', '他們也了解的到連宋楚瑜公開地在廣東', '23', '次的公開演講', '，', '我到底有沒有講過一國兩制他們都無法查證', '，', '都不能替我澄清', '。', '我還是您任命的', '，', '執政的', '。', '那', '200', '多萬的台商', '，', '到底如何證明他們的清白', '，', '讓政府的施政和法律的執行無效', '，', '這是對政府威信的傷害', '。', '做不到的事情要嚴謹的做', '，', '那就是', '，', '我們現在非常清楚地', '，', '我必須要提醒民進黨跟國民黨', '，', '三天之後', '，', '也就是', '12', '/', '21', '，', '韓市長', '，', '在高雄市', '，', '有兩場如同火車對撞的遊行同時舉行', '，', '集會遊行法是人民權力', '，', '但無論中央政府蔡總統或是地方政府都要負起責任', '，', '維護人民安全', '，', '不要讓有心人透過煽動製造社會混亂', '。', '當父母官沒有假期', '，', '隨時要心存百姓', '，', '我誠懇呼籲民進黨國民黨', '，', '雙方都應該自我克制', '，', '天佑台灣', '。', '我進來的時候記者問我', '，', '你會不會覺得被邊緣化', '？', '坦白講', '，', '我最擔心台灣民主被邊緣化', '。', '每位台灣鄉親如果感受不到政府在照顧他們', '，', '感覺被邊緣化', '，', '這才是我們做國家領導人的最重要的責任', '。', '因此', '，', '維護', '12', '/', '21', '安全', '，', '不要對撞', '。', '台灣過去選舉從來沒有流過血', '。', '這是我們光榮傳統', '，', '不要這次選舉選不下去', '。', '謝謝', '。'], ['主持人', '、', '監察人', '、', '還有親民黨的候選人宋先生', '、', '國民黨的候選人韓國瑜先生', '、', '電視機前面的觀眾朋友', '，', '還有我們在線上看直播的朋友們', '，', '全體的國人同胞', '，', '大家晚安', '。', '剛才我很仔細地聆聽了韓國瑜先生的發言', '，', '我也聽到他對我很多的指教跟批評', '。', '但是在過去這段時間他跟他的政黨也對我很多地批評跟指教', '，', '不過仔細聽一聽', '，', '這些發言不脫是歧視性的發言', '、', '情緒性的發言', '，', '或者挑起社會對立', '，', '甚而至於是沒有根據的指控', '，', '有時候還無中生有', '、', '斷章取義', '。', '那剛才他提的幾個問題', '，', '比如說中華民國', '，', '我們現在不就是正在選中華民國的總統嗎', '？', '我現在就是第', '14', '任總統', '，', '我們現在在選第', '15', '任的總統', '。', '另外', '，', '我們這滿場不就是國旗嗎', '？', '我已經擔任總統', '3', '年多了', '，', '這個政府的運作不就是跟著我們中華民國的憲政體制在運作嗎', '？', '所以我剛才聽他講了一大堆關於中華民國的事', '，', '也就是無中生有', '。', '他講到清廉的問題', '。', '我倒是要問一下', '，', '這段期間以來', '，', '高雄市政府一直在討論一件事情', '，', '就是閨蜜變主秘的事情', '。', '那閨蜜第一號閨蜜辭職了以後', '，', '第二號閨蜜又變成主秘', '，', '這件事情韓市長有沒有好好解釋一下呢', '？', '那我要再說一個', '，', '我們剛才有說特偵組要重新設立', '，', '要來調查所有的人', '，', '包括他自己', '，', '可是韓國瑜市長', '，', '您自己的豪宅的事情都迴避都講不清楚', '，', '不用等到做總統', '，', '你連現在都說不清楚', '，', '又何況是將來的特偵組呢', '？', '我們', '2020', '的大選', '，', '對台灣的未來是一個很具關鍵性的選舉', '，', '因為我們', '2020', '要選出一個值得人民信賴的總統', '。', '那麼去年韓國瑜先生當選了市長', '，', '不過才短短不到三個月', '，', '他就宣佈要選總統', '，', '說要來跟', '、', '爭取國民黨的候選人', '。', '這是台灣民主的發展歷史上', '，', '選民從來沒有見過的事情', '，', '也是一個政治人物違背了責任政治', '，', '而且背棄自己對選民承諾的最壞的示範', '。', '韓市長為了選總統也請假三個月', '，', '高雄市民沒有市長', '，', '高雄市議會找不到市長監督', '。', '面對社會普遍的質疑', '，', '我們韓市長自己沒有反省', '，', '反而回來問我說', '，', '做總統的我為什麼不請假', '？', '他的這個問題顯現出來', '，', '他對總統職務的不了解跟一個總統角色的不了解', '。', '總統的工作是', '24', '小時的', '，', '總統沒有請假的問題', '，', '總統只有能不能擔任和執行他的職務的問題', '，', '不論是在內政還有國安', '，', '每一分鐘總統都是這個國家的領導人', '，', '他必須掌握隨時地國內外情勢的變化', '。', '那我也很好奇', '，', '我想問一下韓市長', '，', '如果你當選總統', '，', '有一天你發現不能請假', '，', '你也不能迴避的時候', '，', '那你怎麼辦', '？', '再來', '，', '韓市長很多政策的宣示', '，', '有很多的許多人都在覺得說還是有一些娛樂的效果', '。', '比如說選市長的時候', '，', '他說要在太平島挖石油', '，', '在選總統的時候他說要在花東蓋一個不限速的腳踏車高速公路', '，', '以及在臺灣的高山上蓋升旗台', '。', '他的承諾天馬行空', '，', '當被問到錢從哪裡來', '，', '他常常說就從前瞻基礎建設計畫裡面來', '，', '但是他剛剛已經批評了前瞻基礎建設計畫', '，', '那我們把他近來所做的很多政策的這個承諾把它計算了一下', '，', '其實他的政策承諾需要好幾個前瞻基礎建設計畫的錢', '。', '那我倒是要問說', '，', '如果前瞻基礎建設計畫是這麼有用的話', '，', '你為什麼不讓你的', '，', '你要去試問一下國民黨', '，', '為什麼要杯葛前瞻基礎建設計畫呢', '？', '國家的領導人要擔任國家的領導人必須要有一定的條件', '，', '如果背棄了對選民的承諾', '、', '天馬行空地開政策支票', '，', '那沒有帶領國家的能力', '，', '我相信這絕對不是我們要選擇的一個總統候選人', '。', '除此之外', '，', '一個好的國家元首還要具備幾個要件', '。', '第一個', '，', '他必須有堅定地改革的意志力', '。', '做總統壓力很大', '，', '你每次要做什麼樣的事情都會有很多不同意見', '，', '你要能沉得住氣', '、', '能夠忍受攻擊', '，', '在不同意見當中縮小社會的分歧', '，', '而不是遇到紛擾就退縮', '、', '放棄', '。', '那我上任的時候', '，', '軍公教的年金已經到了破產的邊緣', '，', '連我在交接的時候', '，', '馬前總統都跟我說要趕快做這件事情', '，', '我就決定開始做這件事情', '。', '一旦我開始做的時候', '，', '這個壓力是排山倒海而來', '，', '所以我沉得住氣', '，', '我忍受了壓力', '、', '忍受了攻擊', '，', '我討論再討論', '、', '溝通再溝通', '，', '終於完成了年金改革', '。', '在這個年金改革完成之後', '，', '很多退休的人或者是現職的人都不用擔心將來退休的時候', '，', '或者現在正在退休的人領不到退休金', '，', '那這就是一個總統需要的一個意志力一個改革的意志力', '。', '另外', '，', '總統也需要有能力在變局中創造機遇', '。', '剛才宋主席講得很對', '，', '現在的國際情勢是在變化當中', '，', '在變化的國際情勢當中', '，', '你要去怎麼樣利用這個變局去創造一個國家的際遇', '，', '這就是一個領導人的責任', '。', '美中的貿易戰影響了全世界的經濟', '，', '在這個過程當中', '，', '很多國家的經濟受到衝擊', '、', '受到影響', '，', '經濟往下走', '。', '但是台灣在這三年多以來', '，', '因為我們開始了經濟轉型的工程', '，', '我們開始了改善投資環境', '，', '我們也做好了基礎建設', '，', '我們也降低了對中國的依賴', '。', '因此', '，', '在今年我們看到', '，', '我們前三季是四小龍第一名', '，', '我們未來的一年也會是四小龍第一名', '。', '我們不但減輕了美中貿易戰的衝擊', '，', '還因為轉單的效應跟台商的回流迎來投資大爆發', '、', '股市上萬點', '，', '連聯合國都說', '，', '台灣是美中貿易戰的贏家', '。', '總統還要有一個能力', '，', '就是治國的能力', '。', '我們的財政是有限的', '，', '但是我們要做的事是很多', '。', '我們面臨一個少子化', '、', '高齡化的社會', '，', '在這個時候', '，', '我們必須要有全面性的長照', '，', '也必須要對我們', '0', '-', '6', '歲小朋友有一個周全的照顧', '，', '這些都要錢', '，', '而且要找財源', '，', '也要把民間力量集結起來', '，', '建構起一個完善的服務體系', '。', '過去三年半', '，', '我們找到了財源', '，', '我們也集合了民間的力量', '。', '我們現在的長照據點有七千多個', '，', '我們現在有很多的選擇給年輕的父母', '，', '他們可以到托嬰中心', '，', '可以找保母', '，', '可以到育兒園', '、', '幼兒園', '，', '而這些費用', '，', '我們都把它在壓制在一定的範圍之內', '。', '但是我們做了那麼多', '，', '我們財政還是平衡的', '，', '我們財政的狀況比前一個政府比起來好得太多', '。', '我們在上一個政府在財務的壓力最大', '、', '財政的狀況最差的時候', '，', 'GDP', '國家債務佔', 'GDP', '到達了', '36', '％，', '我們現在只有', '31', '.', '5', '％，', '那麼連國際上都稱讚我們財政的能力', '。', '最重要的', '，', '一個總統要有抗壓的能力', '。', '這幾年中國對我們文攻武嚇是不斷的', '，', '我沒有退讓過', '。', '中國拿觀光客當作工具來威脅我', '，', '我也沒有低頭', '。', '那麼在這個過程中', '，', '我把觀光客源拓寬', '，', '今年我們再一次地創造紀錄', '，', '我們有前幾天我們就有', '1111', '萬人次的觀光客', '，', '這是歷史新高', '，', '而且客源來自歐', '、', '美', '、', '日', '、', '韓', '、', '新南向', '，', '大陸客現在是從已經從', '44', '％', '降到', '24', '％，', '這就是一個政府的抗壓能力', '。', '另外', '，', '一個總統也要有正義感', '。', '我們為青年做社會住宅', '，', '我們向原住民道歉', '、', '我們對於威權時代的轉型正義', '，', '我們都著墨很深', '。', '各位親愛的國人同胞', '，', '三年多以前', '，', '我接手政府的時候', '，', '我們政府只有逆風', '，', '沒有高飛', '。', '三年多來', '，', '過去政府做不到', '、', '不敢做', '、', '不願意做的', '，', '蔡英文都做到了', '。', '蔡英文是值得信賴', '、', '會做事的', '、', '會有能力的一個政府', '。。', '謝謝主持人', '。', '剛才我也仔細地聆聽這個韓國瑜市長的發言', '，', '那我聽到的都是他以前一講再講講過很多次的事情', '。', '這些呢我們都已經解釋過', '，', '可是韓先生的慣例是', '，', '他講了他從來不聽解釋的', '。', '而且他的指控很多都是沒有根據', '，', '很多都是沒有在一個合理的經濟的這個基礎上去解釋', '。', '沒有錯', '，', '台灣的經濟受到跟其他國家一樣', '，', '受到全世界的美中貿易的衝突的影響', '，', '但是我們在全體的國家受到衝擊的狀況下', '，', '我們依然表現得最好', '，', '這就是我們的能力', '。', '而且我們不但表現得最好', '，', '而且讓很多的外商', '、', '台商對台灣有信心', '，', '都進來投資', '。', '超過', '7000', '多億的台商返台投資', '，', '是真真實實的存在', '，', '跟匯款這件事是兩回事', '。', '如果韓國瑜先生要拿匯款當作有沒有投資', '，', '那就太外行了', '。', '另外', '，', '他又說有', '3', '萬家公司關起來', '，', '這經管會主委也解釋過了', '，', '這', '3', '萬家是因為我們做洗錢防治的問題', '，', '這些都是殭屍公司', '，', '也就是沒有用的公司', '，', '它被勒令關起來', '。', '像這些事情', '，', '不就明理就拿來當作攻擊的工具', '，', '我想不是一個做總統候選人應該有的態度', '。', '那麼在第二輪', '，', '我想談一談剛才宋主席講的兩岸跟外交還有主權的事情', '。', '當前的國際政治情勢確實很複雜', '，', '那國際經濟也進入到新的變局', '，', '總統必須要有國際的視野', '，', '提前為變局來做準備', '，', '也能帶領國家在變局中穩定的前進', '。', '但是一個總統是不可以信口開河的', '，', '總統的每一句話都很重要', '，', '如果不重視承諾', '、', '信口開河', '，', '台灣好不容易建立起來的負責任', '、', '守信用的國際形象就被破壞', '。', '所以很多選民對我們韓市長有很大的疑慮', '，', '就是韓市長常常今天說一件事明天就把它否認掉了', '，', '而且他的立場常常是曖昧的', '，', '沒有守住國家基本的立場的決心', '。', '比如說今年初', '，', '中國政府提出來一國兩制台灣方案', '，', '全台灣的人都在議論紛紛之餘', '，', '韓市長卻到香港去訪問', '，', '進入了中聯辦', '，', '強化了一國兩制的氛圍', '。', '這幾年來', '，', '國民黨不論在朝在野', '，', '對中國進逼是處處退讓', '，', '加上香港民主抗爭的議題上', '，', '國民黨也選擇模糊以對', '，', '包括韓市長都模糊以對', '，', '這次不分區的提名更讓人民感到不安', '，', '這就是台灣年輕人為什麼有亡國感的原因', '。', '如果你不知道這些原因', '，', '還當成政治操作', '，', '那你就真的不知道這個國家的人在想什麼', '。', '作為總統也要在變局中確保國家利益', '，', '美中矛盾持續升高', '，', '台灣必須依自己照國家利益做出正確選擇', '。', '中國節節進逼', '，', '挑戰是嚴峻的', '，', '戰略模糊的可能性是越來越低', '。', '一個國家領導人的選擇', '，', '也必須要基於是國家的利益', '，', '身為國家的領導人', '，', '必須捍衛台灣主權和民主自由', '。', '我們跟主流國際社會在一起', '，', '不是因為個人偏好', '，', '而是因為這是基於國家利益跟價值理念的必然選擇', '，', '沒有模糊或是猶豫的空間', '。', '兩岸問題上', '，', '我處理的方式很清楚', '，', '我們遇到壓力不屈服', '，', '得到支持不冒進', '，', '撐住台灣的主權', '，', '穩住兩岸的情勢', '，', '同時贏得國際肯定', '。', '台灣在西太平洋的戰鏈是在第一線', '，', '經過三年多的努力', '，', '已經成為全世界公認亞太地區最穩定', '、', '最值得信賴的民主夥伴', '。', '但中國對台灣持續進行武力的威脅', '、', '經濟的洗腦', '、', '還有外交的打壓', '、', '以及社會的滲透', '，', '今年', '1', '月還提出一國兩制台灣方案', '。', '香港的情況', '，', '讓我們大家都很清楚地看到', '，', '民主跟威權是衝突的', '，', '這兩個制度不可能共存在一個國家', '。', '台灣絕對不可能接受一國兩制', '，', '這點我的立場比誰都還要清楚', '。', '為了保護國家主權', '，', '對一國兩制說不', '，', '我們必須強化自己的實力', '，', '因此在過去三年', '，', '我們和理念相近的國家積極合作', '，', '也強化台灣自我防禦能力', '。', '這三年多來台美關係在史上是最好的狀態', '，', '台日關係比以前更好', '，', '對歐關係也顯著成長', '，', '各國支持台灣加入國際組織的聲量創下歷史新高', '。', '同時我們致力加強和全球經濟的連結', '，', '新南向政策的開展', '，', '國際重要經貿夥伴的合作關係提升', '，', '我們都看到初步成果', '。', '我們也努力強化台灣自我防衛能力', '，', '也逐年增加國防預算', '，', '除了必要軍購', '，', '國機國造', '，', '國艦國造計畫都在進行', '，', '歷任總統都想做卻沒做到的潛艦', '，', '在我任內開始建造', '。', '同時我們提高了軍人待遇', '、', '部隊裝備改善', '，', '讓國軍更有尊嚴', '，', '更有戰力', '。', '我雖然沒有當過兵', '，', '但是自從有民選總統以來', '，', '我比誰', '、', '比任何總統都重視國防', '。', '守護主權', '，', '保護國家', '，', '最重要的是人民有沒有團結', '，', '團結的前提是對現在情勢要有共同認知', '。', '這裡有四個認知', '，', '要請韓國瑜先生特別注意', '。', '第一個', '，', '我們要認知破壞臺海現狀的是中國', '。', '全世界都知道片面改變台海現狀的是中國不是台灣', '，', '中國正在崛起', '，', '試圖改變世界秩序', '，', '很多民主國家對這個現象都充滿戒心', '。', '第二個認知是', '，', '中國利用九二共識正在掏空中華民國', '，', '我知道台灣還有人沒有感受到局勢變化', '，', '還要用虛幻的九二共識附從在對岸的壓力之下', '，', '但是在中國操縱之下', '，', '他們所認定的所謂的九二共識之中', '，', '一中是越來越大', '，', '各表是越來越小', '，', '甚至是沒有空間', '，', '中華民國在這過程中正在被掏空', '。', '第三個認知是', '，', '我們不能以主權交換短期的經濟利益', '。', '我們樂見兩岸關係良性互動', '，', '我們也從未緊縮過兩岸正常互動', '，', '但身為中華民國總統', '，', '我不能拿主權交換短期經濟利益', '，', '我也不能拿主權交換經濟發展或是外交空間', '，', '都不能拿主權交換', '。', '第四個認知是', '，', '我們要警覺到中國正在全面滲透', '，', '分化台灣的社會', '，', '過去的經驗看出來', '，', '中國會利用假訊息', '、', '統戰滲透', '、', '各式各樣的手法', '，', '擴大對台灣社會的影響', '。', '近期我們看到幾個共諜案', '，', '甚至是退役的', '、', '現役的軍人網絡的滲透', '，', '甚至有退將的涉案', '，', '都引起國內高度重視', '。', '我們要建構一個國家安全網', '，', '確實是一個非常要緊的事情', '，', '也有時間上的很大的壓力', '。', '那我們推出的國安五法', '，', '反滲透法', '，', '將是國安安全網的最後一個拼圖', '。', '未來我們將繼續在國際上強化價值連結', '，', '以永續', '、', '負責', '、', '互惠互利的台灣模式', '，', '來加強和理念相近國家之間的連結', '，', '跟友邦全面性的合作', '。', '未來四年', '，', '我也會繼續凝聚國人對於所處情勢的共同認知', '，', '促成團結', '，', '有共同認知才不會被分化', '，', '失去立場', '，', '有共同認知才會團結', '。', '中國', '，', '最害怕的是台灣人的團結', '，', '中國最害怕台灣的民主', '，', '中國最害怕的是台灣的壯大', '。', '3', '年多來我做的一切', '，', '以及未來四年多', '，', '都是讓台灣更團結', '、', '更民主', '、', '更壯大', '。', '面對激烈的變局只有堅定立場', '，', '強化國力', '，', '團結台灣', '，', '才能獲得更廣泛的國際支持', '，', '讓國家在穩定中前進', '。', '那麼在這裡', '，', '我要問韓先生一個問題', '。', '他兩次評論新南向政策', '，', '一次說瑪利亞變成英文老師', '，', '一次說鳳凰走了來了一堆雞', '，', '這些歧視性文字言語', '，', '引起移工跟新住民甚至外國代表處的抗議', '，', '你有沒有警覺到一個總統候選人講話', '，', '如果隨便說說是危險的事', '？', '謝謝主持人', '，', '謝謝宋主席最後的提醒', '，', '我也希望這次選舉都能平安完成', '，', '我想大家都有共同的責任確保這次選舉的平順', '。', '剛剛韓國瑜先生提到世界忘記台灣這件事', '，', '我想很可能是韓國瑜先生比較少出國', '，', '或比較不注意國際間情勢跟國際友人對台灣評價', '。', '大概是他只是出入中國比較多一點', '，', '其實我們只要出國大家講到台灣都覺得台灣是很好的地方', '，', '有民主自由', '、', '有科技', '、', '有經濟發展', '，', '有很多令人稱羨之處', '，', '所以與其說世界忘記台灣', '，', '不如說韓國瑜先生很可能已經忘記了世界', '。', '至於剛才很多苦人跟庶民的事', '，', '這次選舉來', '，', '我們聽到韓國瑜先生講了很多庶民跟苦人的事情', '，', '他也講他在高雄做很多', '，', '姑且不論真假', '，', '但他顯然有注意到他做了些事情', '，', '他當選高雄市長', '，', '原本有機會好好替高雄做事', '，', '就像剛剛宋楚瑜講', '，', '不過', '，', '他選擇落跑', '，', '急著來選總統', '，', '拋下市民', '，', '來追逐個人的權力', '。', '但人民要問', '：', '高雄人發大財了嗎', '？', '如果沒有', '，', '台灣人民憑什麼相信', '，', '他當總統台灣就會發大財', '？', '他為庶民', '、', '苦人做了什麼', '？', '很多人都覺得他只是把苦民', '、', '苦人跟庶民當成選舉工具而已', '。', '我要告訴韓市長', '，', '作為一個領導人', '，', '如何替庶民', '、', '替苦人解決問題', '、', '創造機會', '，', '我在', '2016', '年擔任總統以後', '，', '沒有多久我就解除了健保的欠費的鎖卡', '，', '讓沒有金錢無力繳健保費的人也能受到健保的醫療的照顧', '。', 'Ｃ肝在一些縣市很嚴重', '，', '一個療程要花一兩百萬很貴', '，', '我把', 'C', '肝納入健保', '，', '不讓人們因為肝病而受苦', '。', '過去三年多以來', '，', '我們日以繼夜的做', '，', '認真的做', '，', '就是希望把經濟從谷底拉起來', '。', '韓國瑜先生你要記得', '，', '前個政府交給我是連續三季的負成長的經濟', '，', '我為了要把這個經濟從谷底拉起來', '，', '我們是日以繼夜地做', '，', '我們希望人民能過更好的生活', '。', '現在的經濟是穩定的在成長', '，', '但我們也不能否認', '，', '有人在經濟發展的過程中落後了', '，', '沒有直接享受到經濟發展的果實', '，', '還有一些人想加入', '，', '就需要國家拉他一把', '。', '因此要努力找尋這些人在哪裡', '？', '需要什麼', '？', '也必須要有對應的政策', '。', '我舉幾個例子', '，', '我曾在幼兒園前面碰到一個阿嬤跟一個孫子', '，', '他告訴我私立幼兒園太貴', '，', '公立抽籤抽不到', '，', '他的三歲的孫女沒有辦法上幼兒園', '。', '這就是我', '，', '為什麼要花那麼多力氣', '，', '那麼多的國家資源來增班', '，', '來提供大量補助給年輕父母', '，', '讓他們的子女可以進幼兒園', '，', '可以在托嬰中心', '，', '可以受到保母照顧', '。', '同時', '，', '我也看到很多小攤商', '，', '還有街上傳統商家', '，', '路上的計程車司機', '，', '他們因為電子商務跟共享經濟的發展影響', '，', '生意受到了衝擊', '，', '甚至極速萎縮', '，', '我們針對他們的需求', '，', '一個一個的提出具體的解決方案', '，', '為了提升攤商的小店鋪的生計我們用了國旅補助', '，', '用了這個夜市抵用券', '。', '我們現在已經回收抵用券', '260', '萬張', '，', '為夜市的老闆帶動商機', '，', '營業額普遍提高兩到三成', '。', '我們也補助一萬多個小店家', '，', '數位服務系統設置', '，', '來幫助小店家提升行動支付的環境', '，', '讓營業模式跟得上時代', '，', '錢就能進入口袋', '。', '為了計程車運將', '，', '爭取乘客時能更有競爭力', '，', '我們提出各種協助', '，', '包括一萬兩千輛老舊計程車汰舊換新', '，', '以及其他專業的協助', '。', '民進黨中央黨部曾經接到一位', '5', '、', '60', '歲男性電話', '，', '他說他沒有工作', '、', '退休金', '，', '也擔心未來沒有依靠', '，', '沒有人照顧', '，', '以後人生怎麼辦', '？', '我知道他們的焦慮', '，', '所以我們通過法令協助中高齡者就業', '，', '同時我們也開始研擬協助中老年民眾養老退休規劃', '，', '也幫助農民規畫退休制度', '，', '當然要做更完整的長照', '。', '一位來自苗栗年輕人寫信說', '，', '他返鄉創業遇到的種種困難', '，', '希望政府能夠提供年輕人更大的助力', '。', '創業需要資金', '，', '資金需要貸款', '，', '借貸需要擔保', '，', '但年輕人沒財產', '，', '哪裡來擔保', '？', '這就是年輕人的挫折', '。', '我要求行政院召集相關部會', '，', '做成協助年輕人創業跟就業的方案', '，', '其中如果創業過程中第一個一百萬', '，', '在', '100', '萬以下', '，', '100', '％', '的借款由政府保證', '。', '也有年輕人從事文創', '，', '但他們的創作沒有鑑價制度', '，', '因此他們無法融資', '，', '為了這些年輕人', '，', '我們現在試圖要建立鑑價制度提供融資的協助', '。', '我以上所講的', '，', '都是庶民', '，', '都是韓市長口中的庶民', '，', '也是莫忘世上苦人多的苦人', '，', '我們沒有忘', '，', '我們一直在做', '，', '一直在為他們解決問題', '，', '忘掉責任', '、', '承諾的人', '，', '應該就是韓市長', '。', '庶民最痛的是什麼', '？', '有人假裝是他們', '，', '一直拿他們來消費', '，', '拿他們當做選舉工具', '。', '今天政見發表最後', '，', '我要提台灣很可愛的年輕人', '，', '我認為政府應該帶給人民希望', '，', '而人民也會為國家帶來希望', '。', '我們都知道', '，', '我上任以後', '，', '一直推國防自主政策', '。', '有一次我去宜蘭', '，', '參加沱江艦的開工典禮', '，', '在那我遇到三組年輕人', '。', '一組是負責造艦的公司員工', '，', '95', '％', '是宜蘭人', '，', '他們很年輕很開心', '，', '對未來充滿信心', '。', '第二組是海軍的年輕人勢力', '，', '他們看到新的船', '，', '也都很高興', '。', '還有第三組人就是中科院年輕工程師', '，', '為了台灣科技努力研發', '，', '他們因為參加國家重大建設而感到光榮', '。', '政策如果做對了', '，', '人民參與其中會有很大的光榮感', '，', '你會以國家為榮', '，', '國家也會以你為榮', '。', '事實上不只是國艦國造', '，', '在國機國造的部分', '，', '漢翔有年輕團隊', '，', '正在做', 'F16', '構改升級工作', '。', '跟漢翔合作的美國洛克希德', '・', '馬丁告訴我', '，', '這個團隊是世界上最好的團隊', '，', '聽到這些話的時候', '，', '我心裡很高興', '，', '不只為台灣高興', '，', '也為年輕人高興', '。', '台灣年輕人正在挑起這個國家的責任', '。', '我同時也在', 'Facebook', '、', 'Google', '、', 'Line', '和波特王的公司', '，', '看到在網路社群裡面創造未來的年輕人', '，', '不要忘了在電競比賽', '，', '體育賽事中', '，', '有許許多多很有成就的年輕人', '，', '政府給他們支持', '。', '比如', '，', '我們體育總經費預算提高將近', '70', '％。', '當政府做對事情', '，', '苦人得到照顧', '，', '庶民會得到幫助', '，', '年輕人會有更多揮灑的空間', '，', '可以實現夢想', '。', '各位同胞', '，', '這就是領導人要做的事情', '，', '而這些事情都正在發生', '。', '我很高興能夠參與這些年輕人的人生故事', '，', '我知道還有很多很長故事', '。', '年輕人加油', '，', '我們正在一起改變這個國家', '。', '我拜託大家', '，', '蔡英文再做四年', '，', '讓改變的故事繼續下去', '，', '2020', '年選一個值得信賴的總統', '，', '選擇一個可以帶領國家抵抗壓力的總統', '，', '也要選擇一個能夠創造未來的總統', '。', '謝謝大家', '。']]\n",
            "-----\n",
            "分類語料庫有19346個單詞\n",
            "取前10詞：\n",
            "['謝謝主持人李進勇主委', '，', '蔡英文蔡總統', '、', '宋楚瑜宋主席', '、', '全國各位所有的台灣同胞', '、', '各位海內外關切中華民國第', '15']\n",
            "-----\n",
            "分類語料庫有12個段落\n",
            "取前兩段：\n",
            "[[['謝謝主持人李進勇主委', '，', '蔡英文蔡總統', '、', '宋楚瑜宋主席', '、', '全國各位所有的台灣同胞', '、', '各位海內外關切中華民國第', '15', '任總統選舉的所有的好朋友大家晚安', '，', '大家好', '！！', '首先非常感謝大家這麼長的一段時間', '，', '對韓國瑜的愛護以及支持', '！', '更要感謝高雄市', '280', '萬市民朋友選我為高雄市長', '，', '一路陪著我走上這一段神奇的旅程', '，', '讓我有這個機會跟大家一起來做出對中華民國未來的改變', '，', '以及我們共同來創造未來', '。', '今天是公辦政見發表', '，', '所有的政見國防', '、', '內政', '、', '外交', '、', '交通', '、', '青年人的未來', '、', '毒品治安等等非常非常的多', '，', '國家要做的事情非常多', '，', '但是這麼多事情之前', '，', '有一個最重要的就是我們到底是什麼國家', '？', '我們現在到底在辯論什麼', '？', '我們是中華民國第', '15', '任總統的政見發表', '，', '還是', '「', '這個國家', '」', '的政見發表', '？', '蔡英文總統擔任總統三年半以來', '，', '從來沒有對國家講得清楚', '，', '前三年用', '「', '這個國家', '」', '來代替', '，', '所以今天我們政見發表是不是應該改名為', '「', '這個國家', '」', '政見發表會', '，', '還是中華民國總統的政見發表會', '？', '沒有國就不會有家', '，', '我長期一直問蔡英文總統到底要帶兩千三百萬同胞何去何從', '？', '蔡英文總統身為中華民國總統', '，', '享受到中華民國憲法授予的一切權力跟待遇', '，', '但是都是用', '「', '這個國家', '」', '來稱呼', '，', '所以請問蔡英文總統如果不把國家定位講清楚', '，', '我們後面的', '，', '我們政見說明有什麼意義', '？', '蔡英文總統眼前有三條路去選擇', '，', '我們看的非常清楚', '，', '第一', '，', '你根本就不愛中華民國', '。', '第二', '，', '你不要九二共識', '，', '我們國民黨的立場非常清楚', '，', '在中華民國完整的國格現任體制之下', '，', '發展兩岸的交流', '，', '是九二共識', '，', '你一定要扣一個帽子', '，', '叫做我們認同一國兩制', '。', '第三', '，', '我覺得蔡英文總統更講不清楚', '，', '而且完全對不起長期支持台灣獨立的朋友', '，', '很多台獨的朋友把選票投給蔡英文總統', '，', '希望台灣獨立', '，', '但是你完全讓他們失望', '。', '所以蔡英文總統必須有責任告訴我們台灣同胞', '，', '未來兩千三百萬民眾', '，', '到底何去何從', '？', '韓國瑜的立場非常清楚', '，', '我就是支持中華民國', '，', '捍衛中華民國主權', '、', '捍衛中華民國憲政體制', '，', '以及服務跟保護兩千三百萬台澎金馬的同胞生命財產', '，', '一清二楚', '，', '沒有任何含糊空間', '。', '如果蔡英文總統支持台灣獨立', '，', '也請大聲地講出來', '；', '如果不支持台獨', '，', '也請大聲地講出來', '，', '這樣子兩千三百萬民眾在投票給你的時候', '，', '才知道你要把我們帶到哪裡去', '。', '所以我希望蔡總統如果不支持台獨', '，', '請講清楚之後請跟著我的方向', '，', '我大喊三聲', '，', '我希望蔡英文總統你也大喊三聲', '：', '中華民國萬歲', '！', '中華民國萬歲', '！', '中華民國萬歲', '！', '希望你勇敢地喊出來', '，', '否則', '，', '請你喊出台灣獨立', '！', '我不支持台獨', '，', '但是你敢喊出來', '，', '我還是覺得', '，', '你是有勇氣的', '。', '第二個部分', '，', '人活著', '，', '要穿衣服', '、', '要吃飯', '，', '要受教育', '，', '要賺錢養家', '，', '但是人如果沒有一口空氣人是活不下去的', '。', '今天一個政府這麼多的事情要做', '，', '國防', '、', '內政', '、', '外交', '、', '交通', '，', '那麼多事情要做', '，', '但是各位台灣同胞', '，', '沒有一個清廉的政府', '，', '一切都是', '「', '竹籃子打水', '，', '一場空', '」。', '今天我們看看蔡英文總統領導的整個民進黨執政團隊', '，', '套一句台北市長柯文哲的講法', '，', '每一個都貪汙', '，', '我不相信', '，', '這句話我不相信', '，', '這句話太極端', '，', '但是我相信', '，', '你民進黨執政在蔡英文領導之下', '，', '很多人都在貪汙', '，', '這個我絕對相信', '。', '現在我們回想', '，', '為什麼民進黨執政', '，', '蔡英文總統你堅決要廢除特偵組', '，', '特偵組所有查辦的重大貪汙案件', '，', '立法委員', '、', '部長級以上', '，', '重要的國營事業以上總經理', '，', '凡是這種貪污', '，', '特偵組就會偵查', '，', '民進黨為什麼要廢除特偵組', '，', '很清楚', '，', '你為貪官汙吏開了一條路', '，', '讓他們一路有綠燈', '，', '不會被調查', '。', '各位台灣同胞', '，', '我們沒有清廉的政府', '，', '我們沒有一個有效率的政府', '，', '我們納稅人納再多的稅', '，', '我們再怎麼衝刺經濟', '，', '再怎麼發展', '，', '最後都是空的', '。', '貪官污吏充斥了整個政府', '，', '另外還有肥貓', '，', '這個像一個政府嗎', '？', '韓國瑜當上總統', '，', '我跟全台灣同胞報告', '，', '我一定立刻成立特偵組', '，', '馬上展開調查', '，', '為什麼要', '8800', '億', '？', '我們前瞻計畫為什麼花這麼多錢', '？', '為什麼我們風力發電要花兩兆台幣', '？', '為什麼我高雄市負債全國第一名', '3300', '億', '，', '特偵組一併調查', '，', '為什麼會欠這麼多錢', '，', '每一個高雄人身上背了將近', '9', '萬塊錢的債', '，', '為什麼', '？', '錢到哪裡去', '？', '另外', '，', '如果我選上總統', '，', '成立特偵組', '，', '我要拜託特偵組', '，', '我下台之後要對我像', 'X', '光一樣嚴密的檢查', '，', '我願意接受檢查', '。', '我在這裡同時呼籲全台灣所有的法官', '、', '檢察官', '，', '韓國瑜如果貪污', '，', '你們審查到我的案件', '，', '你們絕對不能讓我假釋', '，', '你們就把我關到死', '，', '我也呼籲全國典獄長', '，', '管監獄的', '，', '韓國瑜如果貪污被抓到監獄', '，', '你一天給我一頓飯就好', '，', '我沒資格吃三頓飯', '，', '哪有人用政府的權力來貪污的', '。', '今天要賺大錢去開公司', '，', '開公司賺大錢', '，', '你民進黨執政', '，', '你現在是在開政府賺大錢', '，', '世界上哪有這個道理', '？', '人民投票給政治人物', '，', '是希望謀求生活的快樂', '，', '大家能夠安居樂業', '。', '每一個公職人員有這個選票', '，', '有這個職務', '，', '要戰戰競競', '、', '為人民盡心盡力', '，', '怎麼能拿來貪汙', '、', '腐敗', '、', '亂投資', '，', '怎麼可以這樣子做呢', '？', '沒有一個清廉的政府', '，', '就絕對沒有辦法有一個乾淨的政治', '，', '就絕對沒有辦法有一個有效率的執政', '，', '這是雙胞胎', '。', '所以我今天開宗明義', '，', '我要跟全國台灣同胞宣佈', '，', '如果韓國瑜能選上總統', '，', '成立特偵組', '，', '針對這一段時間', '，', '大家懷疑的案件', '，', '展開立刻立案調查', '。', '另外對我韓國瑜本人', '，', '特偵組也必須一樣的標準來檢查我的團隊', '，', '所有韓國瑜用的政務官', '、', '用的國營事業董事長', '，', '如果貪汙', '，', '我拜託全國法官一樣讓他們不能假釋', '，', '我們一定要建立一個清廉的政治', '，', '沒有清廉的政治', '，', '臺灣在走向墮落', '，', '所以這是第一個階段', '，', '我要特別提出', '，', '到底國家目標是什麼', '?', '國家方向是什麼', '？', '我們叫做什麼國家', '？', '第二', '，', '我們必須要建立一個有效率的', '、', '乾淨的', '、', '廉潔的政府', '，', '而蔡英文政府完全沒有辦法達到', '，', '讓廣大的台灣人民失望', '，', '讓愛護民進黨的朋友失望', '，', '讓台獨的朋友失望', '，', '這不是我們要的政府', '，', '非常感謝', '。', '謝謝宋楚瑜主席', '，', '謝謝蔡英文總統對我的指教', '。', '蔡英文總統', '，', '我非常遺憾聽到妳剛才第一輪的論述', '。', '我跟妳談的是一個大海的問題', '，', '妳跟我談的是一個浴缸的問題', '。', '我跟妳談的是公部門', '，', '兩千三百萬台澎金馬同胞', '，', '我們的國家是什麼國家', '？', '要往哪一個方向', '？', '妳跟我談太平島開石油', '、', '我的房子的事情', '。', '妳為什麼我希望第二輪的時候妳繼續問我', '，', '我們家的柴米油鹽醬醋茶怎麼來的', '，', '醬油', '、', '麻油', '、', '醋是不是去偷來的', '。', '我覺得這個實在是這個問題的', '⋯⋯', '蔡英文總統的問題', '，', '我實在覺得非常地狹窄', '。', '我們今天追求的是中華民國兩千三百萬同胞最廣大的公部門的利益', '，', '是', '「', '台灣安全', '，', '人民有錢', '」，', '還是', '「', '台灣危險', '，', '人民貧窮', '」', '這麼重大的問題', '。', '我就舉最簡單的一個小例子', '，', '買房子', '。', '我從來選到現在沒有對蔡英文總統個人操守', '、', '品德', '，', '提出過任何質疑', '，', '我就說妳的團隊', '，', '因為我覺得這是一個候選人互相之間基本的尊重', '。', '我們夫妻去買房的貸款', '，', '千辛萬苦', '，', '最後付不起', '，', '忍痛殺出', '。', '拜託', '，', '蔡英文總統', '，', '妳', '30', '多歲時是買土地耶', '！', '我韓國瑜有說過嗎', '？', '妳買', '10', '幾塊土地耶', '！', '若干年之後', '，', '妳把土地全部賣了', '，', '妳賺了', '1', '億', '8', '千萬耶', '！', '我有說過嗎', '？', '我覺得這是一個尊重', '。', '太平島挖石油', '，', '我有說過高雄市要挖石油嗎', '？', '妳硬套到我的身上', '。', '何況這些媒體在黑韓的', '，', '網路帶風向', '，', '不就是妳民進黨一手在豢養的嗎', '？', '今天抓到的楊蕙如在網路帶風向', '，', '蔡英文總統勇敢告訴全國人民', '，', '沒有抓到的楊蕙如還有多少', '？', '妳用納稅人的錢養網軍', '，', '用網軍打擊政治對手', '，', '我都沒有說耶', '！', '妳居然說今天網軍跟媒體黑我的資料', '，', '妳拿在這裡政見發表會來提出來', '。', '我這真的妳講的口氣', '，', '真的聽得是我完全無法接受', '。', '而且我根本就不怕面對這些問題', '，', '但是我們希望能夠探討更廣大的國家前途跟未來', '。', '誠如妳剛剛結束的時候', '，', '第一段妳說', '，', '蔡英文總統值得信賴', '，', '經濟發展的這麼好', '，', '克服了一切困難', '。', '各位親愛的', '、', '我們台灣同胞', '，', '2016', '年', '，', '蔡英文總統當第一年總統', '，', '兩千三百萬人選一個字', '，', '代表那一年台灣人民廣大的心聲', '，', '是什麼字', '？', '辛苦的', '「', '苦', '」；', '第二年', '，', '2017', '年', '，', '妳繼續當總統', '，', '年底', '，', '台灣人民選什麼字代表台灣人心聲', '？', '茫然的', '「', '茫', '」；', '第三年', '，', '2018', '年台灣人民選什麼字', '，', '翻轉的', '「', '翻', '」；', '今年', '2019', '年', '，', '妳當了第四年總統', '，', '台灣人民用一個字表達心中的廣大的心聲', '，', '是什麼字', '？「', '亂', '」，', '亂七八糟的亂', '。「', '苦', '、', '忙', '、', '翻', '、', '亂', '」，', '然後妳告訴大家', '，', '妳執政地非常好', '，', '亞洲四小龍老大', '。', '拜託蔡總統', '，', '真的紮紮實實地執政', '，', '讓人民感動化為行動繼續投妳一票', '，', '不要用欺騙', '，', '用這些數字', '。', '我這邊一個板', '，', '請大家看清楚', '，', '我為什麼那麼擔憂台灣的未來', '。', '蔡英文總統說', '20', '年來經濟最好', '，', '2018', '年蔡英文總統執政', '，', '有三萬家公司創下全部解散', '，', '比前一年', '2017', '年增加', '30', '％；', '2018', '年', '，', '我們歇業的工廠', '，', '高達', '4000', '家', '，', '比前一年增加', '45', '％；', '2019', '年', '，', '我們', '10', '月份出口訂單連續', '、', '連續', '12', '個月負成長', '，', '妳還要說我們是亞洲四小龍最好', '；', '2019', '第三季就是今年第三季', '，', '我們整個製造業的生產值成長下降', '，', '負成長', '7', '％；', '2019', '年', '10', '月份景氣概況連續', '10', '個月', '，', '我們是轉虛弱的黃藍燈', '；', '也是今年', '，', '妳自己用的金管會的主委顧主委顧立雄所公佈的', '，', '今年前三季全台灣股票上市公司損失', '、', '衰退將近', '20', '％。', '另外', '，', '我再告訴一個可怕的數字', '，', '2018', '年我們統計台灣勞動階層不到', '30', '歲', '，', '一年實質收入只有', '39', '萬', '2000', '塊', '，', '比', '1998', '年', '、', '20', '年前的', '43', '萬', '3000', '塊', '，', '還要低', '4', '萬塊', '。', '這都是妳的政府公佈的數字', '，', '這麼差的成績', '、', '這麼差的經濟表現', '，', '妳還要告訴台灣人民', '，', '我們經濟好得不得了', '，', '蔡總統', '，', '面對問題', '、', '解決問題', '、', '突破困難', '。', '臺灣人心軟', '，', '會因為感動投妳一票', '，', '可是不能用欺騙的數字', '。', '妳動不動講觀光業創下歷史最高', '，', '公佈的', '1100', '萬的觀光客到台灣', '。', '親愛的台灣同胞', '，', '現在民進黨怎麼統計數字', '？', '是只要轉機', '，', '兩隻腳踏進桃園中正機場', '，', '不進台灣轉飛出去的外國人', '，', '也算一個觀光客', '。', '麻煩妳苦民所苦', '，', '接近基層民眾', '，', '看一看觀光業', '、', '遊覽車', '、', '計程車', '、', '餐廳', '、', '民宿', '、', '伴手禮', '（', '御土産', '/', 'おみやげ', '），', '甚至賣茶葉的茶農', '、', '賣珊瑚的商人', '，', '你去問一問', '，', '真的是淒慘的', '「', '慘', '」，', '慘得不得了', '。', '高雄市遊覽車公會理事長', '128', '輛遊覽車', '、', '128', '輛', '，', '妳執政三年', '，', '妳知道他現在剩下多少輛嗎', '？', '他只剩下', '1', '輛', '，', '賣掉了', '127', '輛', '。', '然後妳還要告訴全台灣同胞說我們觀光業非常好', '？', '不斷地欺騙', '，', '我覺得我們完全無法忍受', '！', '妳說台商大量投資回台灣', '，', '妳很驕傲地跟國人宣布', '，', '7000', '億台幣', '，', '結果一查', '，', '0', '！', '1', '毛錢沒有回台灣', '，', '這個都不斷地欺騙', '。', '為什麼啊', '？', '為什麼不能開大門', '、', '走大路', '？', '為什麼治理國家要用欺騙的數字', '，', '要走邪魔歪道', '？', '我是百思不得其解', '。', '台灣人民這麼信任妳', '，', '這麼信任民進黨', '，', '讓你們立法院過半', '，', '妳就好好執政', '，', '讓我們老百姓能夠安居樂業', '，', '票就自然投妳了嘛', '！', '怎麼不斷地欺騙呢', '？', '另外一點', '，', '我還要跟全臺灣同胞講', '，', '蔡英文總統執政', '，', '我們所有對外貿易', '，', '台灣已經變一個孤兒了', '。', '大家看一看', '，', '明年開始', '，', '我們整個', '，', '在我左邊這一圈', 'RCEP', '所有的國家', '，', '韓國', '、', '中國大陸', '、', '印度尼西亞', '、', '寮國', '、', '泰國', '，', '全部變一個經濟圈', '；', '然後以日本為主', 'CPTPP', '，', '又是一個圈', '，', '加拿大', '、', '墨西哥', '、', '智利', '；', '全台灣', '，', '然後中間重疊的有日本', '、', '馬來西亞', '、', '汶萊', '、', '新加坡', '、', '澳大利亞', '、', '紐西蘭全部互相經濟整合', '。', '各位親愛的臺灣同胞', '，', '看看我們中華民國國旗', '，', '我們變成國際經濟的孤兒啊', '，', '我們進不去啊', '。', '我們所有的產品將來進去', '，', '賣到這些國家全部要加關稅', '，', '他們互相零關稅或者優惠關稅', '。', '我們東西賣不出去', '，', '人進不來', '，', '民進黨執政台灣怎麼發大財', '？', '如何發大財', '？', '如何讓人民安居樂業', '，', '這個圖清清楚楚', '。', '蔡英文總統妳執政三年半', '，', '妳沒有在所有自由貿易簽訂裡面', '，', '得到任何突破啊', '。', '連陳水扁總統當總統都可以用中國台灣加入各種國際組織開會', '，', '馬英九總統是用中華台北', '，', '我們現在外交在妳當總統之下', '，', '一步都走不出去呀', '，', '再加這個經濟圈', '，', '我們未來怎麼得了', '。', '所以我覺得蔡英文總統我們很多一句話', '，', '知恥近乎勇', '，', '妳民進黨執政三年半真的不行', '，', '台灣人民用苦', '、', '忙', '、', '翻跟亂表達心聲', '，', '妳要面對這個問題', '。', '如果妳希望台灣人給妳這個機會妳要先承認', '，', '過去四年的執政真的是一敗塗地', '。', '我覺得台灣人民或許會感動', '，', '但是不能再用欺騙的方法', '，', '欺騙的數字', '，', '來告訴大家', '，', '妳的經濟做得非常好', '，', '我相信我們絕對無法接受', '。', '再次謝謝主持人', '，', '謝謝蔡英文總統對我的指教', '。', '各位親愛的台灣同胞', '，', '政治應該是很單純的', '，', '選票多的人', '，', '獲得執政權', '，', '選票少的去監督', '，', '政治是非常單純', '。', '不管是執政或者監督', '，', '都要一心一意為人民努力', '，', '打拼', '，', '我時常講', '，', '我去宮廟拜拜', '，', '我的感慨特別多', '，', '天上最大的神是玉皇大帝', '，', '最小的神是住在家裡隔壁的土地公', '。', '台灣社會最大的官是總統', '，', '最小的是村長', '、', '里長', '。', '不管是玉皇大帝', '、', '土地公', '、', '總統', '、', '村里長', '，', '都應該只有一個目標', '：', '保護人民', '、', '讓人民安居樂業', '。', '但是為什麼單純的政治會變複雜', '？', '甚至變得黑暗', '？', '因為人性讓他變得複雜跟黑暗', '，', '人性太多的慾望', '、', '金錢', '、', '權力', '，', '使得整個政治被扭曲', '，', '這段話完全可以答覆剛才蔡英文總統對我的質疑', '，', '我去香港中聯辦', '，', '就隱射韓國瑜好像要賣台', '。', '我請問蔡總統', '，', '今天民進黨在中央的三巨頭', '，', '妳本人', '，', '妳的副手賴清德副總統候選人', '、', '你的秘書長陳菊', '，', '你們三巨頭去過中國大陸沒有', '，', '有沒有跟高級長官', '，', '中國大陸共產黨高官吃過飯', '、', '喝過酒', '、', '談過話', '、', '聊過天', '、', '照過相', '？', '有沒有', '？', '你們派出的日本大使謝長廷', '2013', '年到香港', '，', '中聯辦從頭到尾陪著他', '，', '各位親愛的台灣同胞', '，', '政治是單純的', '，', '人性讓他複雜', '。', '蔡英文總統', '、', '賴清德', '、', '陳菊', '3', '位', '，', '去過中國大陸', '，', '可是今天誰能說蔡英文', '、', '陳菊', '、', '賴清德', '、', '謝長廷不愛台灣', '？', '沒有人敢這樣講', '，', '我們只能說你的執政', '、', '你的團隊出了問題', '。', '蔡英文執政團隊有貪污', '、', '腐敗', '、', '施政無方', '，', '有這種現象', '，', '誰敢講你的團隊不愛台灣', '？', '你們可以去隨便照相喝酒談話', '，', '韓國瑜不行', '，', '謝長廷去中聯辦接待可以', '，', '我帶的高雄市', '10', '位議員', '，', '帶著官員去吃飯喝酒', '，', '希望將來保持良好關係', '，', '把台灣的水果', '、', '蔬菜', '、', '雞蛋', '、', '雞肉', '、', '鴨肉', '、', '鵝肉', '、', '豬肉', '、', '花朵能夠大量外銷出去', '，', '也吸他們觀光客來台灣', '、', '來高雄', '，', '我有什麼錯', '？', '為什麼你們去就不是出賣台灣主權', '？', '為什麼我去就是出賣台灣主權', '？', '是不是蔡英文總統妳對台灣民主完全沒有信心', '？', '我覺得這個就是蔡英文總統所講的', '，', '政治是單純的', '。', '因為慾望', '，', '妳把事情搞複雜了', '，', '妳應該還我一個清白', '。', '在這', '，', '大家都說', '，', '我在高雄才做了幾個月就出來選總統', '，', '親愛的高雄市民', '、', '親愛的台灣同胞', '，', '事情不在難不難', '，', '事情在於有沒有心', '。', '我把這個板子拿出來', '，', '我不做自我宣傳', '，', '大家可以看一看', '，', '高雄這一年', '，', '韓國瑜加上所有韓國瑜的團隊', '，', '我們前', '10', '個月農產品是去年外銷的', '3', '倍', '；', '去年兩億一千萬', '，', '我們今年賣了六億多', '；', '第二', '，', '高雄觀光', '，', '我們', '2019', '年上半年', '，', '我們住房率成長', '21', '％。', '另外清水溝', '，', '韓國瑜當高雄市長', '，', '200', '公分的衛生下水道阻塞了', '195', '公分', '，', '水只能流', '5', '公分', '，', '10', '、', '20', '年都沒有人清理', '，', '過去', '10', '、', '20', '年誰在執政', '，', '妳民進黨在執政', '，', '所以登革熱這麼囂張', '，', '到處淹水', '。', '蔡英文總統你應該跟高雄市民道歉', '。', '因為我韓國瑜團隊', '，', '花了九牛二虎之力', '，', '去挖這些', '，', '所以今年登革熱才沒有大爆發', '、', '沒有淹水', '，', '因為水溝', '200', '公分的衛生下水道阻塞了', '195', '公分', '。', '再來學生開始裝冷氣', '，', '未來', '6', '萬的高雄孩子要吹冷氣', '，', '因為工業污染區非常嚴重', '，', '高雄支撐了台灣重工業', '60', '％，', '但是高雄的孩子在讀書', '，', '這麼炎熱的天', '，', '空氣又不是這麼的好', '，', '我們幫他裝冷氣', '。', '再來', '，', '很多家庭經濟不好', '，', '禮拜六', '、', '禮拜天不上課', '，', '沒有營養午餐', '，', '我們發愛心餐券', '，', '我們已經發了', '113', '萬張', '，', '113', '萬張愛心餐券', '，', '怕孩子禮拜六', '、', '禮拜天寒假暑假會餓肚子', '；', '再來未婚媽媽', '，', '很多女學生懷孕不知道人生該怎麼辦', '，', '我們成立未婚媽媽的珍珠之家', '。', '妳來', '，', '政府一定照顧妳', '，', '妳不要害怕', '，', '妳也不孤單', '，', '這是高雄首創', '。', '再來雙語教育', '，', '高雄市是全台灣現在衝刺雙語教育第一名', '，', '我們這麼財政這麼困難', '，', '擠出兩千七百萬', '，', '開拓雙語教育', '，', '今年達到', '24', '所', '，', '明年預計有', '48', '所', '。', '再來最後一點', '，', '空污', '，', '我們跟台電談判', '，', '所有興達火力發電廠', '，', '拜託你在冬天的時候', '，', '千萬要降低', '，', '興達火力發電廠同意', '。', '我們降低生煤', '。', '蔡英文總統', '，', '你的能源政策', '，', '你大量地燒煤炭', '，', '要花兩兆蓋風力發電', '，', '你知道現在中部人有多痛苦嗎', '？', '台中', '、', '彰化', '、', '苗栗', '、', '南投', '、', '雲林', '，', '你知道現在台灣肺癌死亡率是全亞洲第二', '，', '每', '1', '年發生連環車禍有人傷亡我們心裡都很難過', '，', '每一年有', '1', '萬人死於肺腺癌', '，', '你執政這', '3', '年半你自己去中部看一下那邊的空氣', '，', '看看那個空汙', '，', '中部人的肺都快爆炸了', '！', '而且不抽香菸的佔百分之', '50', '，', '死亡的肺腺癌不抽香菸佔', '50', '％，', '就是你能源政策一錯再錯', '，', '我們強力改善高雄空氣', '，', '已經達到', '76', '.', '4', '％。', '各位親愛的台灣同胞', '，', '真的', '，', '政治沒有這麼複雜', '，', '凡是乾淨選舉', '，', '一定乾淨執政', '，', '凡是骯髒選舉', '，', '一定骯髒執政', '，', '千古不變', '，', '我們全力衝經濟', '。', '但是政治人物有兩大神聖目標在我們的肩膀上', '，', '絕對不能忘記', '，', '我們賺了錢', '，', '繁榮了臺灣的經濟', '，', '我們最重要這兩大目標', '，', '第一個', '，', '辦好教育', '，', '第二個', '，', '關心弱勢', '，', '這是我們神聖的工作', '，', '也是我們對選民最重要的承諾', '。', '親愛的台灣同胞', '，', '現在臺灣的危險', '，', '我想了我都擔心', '、', '害怕', '。', '我的年紀已經大了', '，', '我也知道我的來日無多', '，', '我這一代人很快就會凋謝', '，', '我們要把這個棒子交給下一代', '，', '我們辦不好教育', '，', '下一代沒有辦法比我們更強大', '，', '我們這一代人有什麼臉面對下一代', '，', '世上苦人這麼多', '，', '台灣將近有一百四十萬左右的身心障礙跟弱勢族群', '，', '我們不去照顧他誰要照顧他', '？', '所以希望大家能夠睜亮眼睛了解台灣的處境', '，', '週邊的國家已經沒有一個看得起台灣了', '，', '世界開始忘記台灣', '、', '台灣也開始忘記了世界', '，', '我們一定要打開門全力迎接世界接軌', '，', '全力培養下一代只要不貪污', '，', '只要不貪汙', '、', '我們錢一定夠用', '，', '我們大力栽培我們下一代孩子', '，', '讓他們跟國際接軌', '，', '整個台灣一定要欣欣向榮', '，', '這四年我們被鎖住了', '，', '每一個人心裡都覺得好悶', '，', '像全民大悶鍋一樣', '，', '大家眉頭深鎖', '。', '用四個字代表民進黨蔡英文總統的執政', '，', '我剛才說過', '「', '苦', '、', '忙', '、', '翻', '、', '亂', '」，', '我們一定要改變', '。', '我們再不奮起直追', '，', '我們再不追分趕秒', '，', '沒有人', '、', '沒有人會像台灣人一樣', '，', '這麼愛台灣', '。', '我們同舟共濟', '，', '都在一條船上', '，', '讓我們全體台灣同胞', '，', '我們自己努力加油', '，', '選出最棒的總統', '、', '最好的立法院', '，', '願台灣人民幸福', '，', '願中華民國萬歲', '！', '謝謝', '！']], [['主持人', '、', '監察人', '、', '兩位候選人', '、', '各位海內外的同胞', '、', '各位鄉親', '，', '大家好', '。', '我是中華民國第', '15', '任總統候選人宋楚瑜', '。', '我首先應該向諸位報告', '，', '我為什麼參選', '？', '我對今天中華民國在台所面臨的國內外環境和未來', '，', '我們應該了解得到', '，', '如何去處理很多重大問題', '。', '宋楚瑜經歷', '44', '年從政經驗', '，', '我追隨蔣經國先生', '、', '孫運璿先生', '、', '李登輝先生', '，', '我從他們那裡學習到很多治國的重大的絕學', '。', '我想在我有生之年', '，', '把這些我所學到的經驗', '，', '奉獻給我心愛的國家中華民國', '。', '我自信我不僅有經驗', '，', '有能力更有執行力', '，', '但是我沒有包袱', '，', '我沒有私心', '，', '我只有包容和一直保持從政的初心', '，', '那就是腳踏實地', '，', '認真地為人民好好地處理好他們希望政府處理的事', '。', '我是一個身體力行來推動民主主義的實踐者', '。', '我曾經全程參與過', '，', '我們初次台灣', '，', '從威權體制轉型成開放的民主', '，', '解除戒嚴', '、', '開放黨禁', '、', '解除報禁', '、', '修改刑法', '100', '條', '，', '讓台灣人不會再因為政治理念不同而被判為政治犯', '，', '同時我也曾全程地參與終結萬年國會', '，', '推動總統直選這些重要的民主化的過程', '。', '坦白地說', '，', '當時在推動這些過程當中', '，', '連當時的國民黨內部還是有不同意見', '，', '但我很自豪地說', '，', '宋楚瑜是重要的民主的推手', '，', '並且曾經做出關鍵的貢獻', '。', '今天臺灣面臨的環境', '，', '跟全世界一樣', '，', '都面臨了六項重大的危機', '。', '第一', '，', '是劇烈氣候變化的危機', '。', '第二', '，', '是人口結構改變的危機', '，', '也就是老人化跟少子化', '。', '第三', '，', '是國際區域經濟整合重組的危機', '，', '如何避免台灣被邊緣化', '，', '這是未來我們必須要去處理的重大危機', '。', '第四', '，', '是因為數位科技所帶來的產業結構的轉型', '，', '也帶來對於我們傳統中小企業的衝擊的危機', '，', '造成可能會有失業', '，', '我們必須要重視這些挑戰', '。', '第五', '，', '是貧富差距擴大的危機', '，', '讓人民感覺到生活不下去', '。', '而最後也是最重要的', '，', '那就是我們也面臨了', '，', '全世界也同樣面臨的', '，', '叫作人文', '、', '價值淪喪的危機', '。', '道德', '、', '人與人之間的感情和處理', '，', '這都是政府必須要去處理的重大挑戰跟危機', '。', '台灣面臨這樣的非常之局', '，', '必須要有非常之人才能處理這些非常之事', '，', '而必須要用非常的努力才能盡非常之功', '。', '而這六項危機如何處理', '，', '我會在下次政見發表會再詳細地向大家報告', '，', '我對處理這些問題的方法', '。', '但是', '，', '當我們看到全世界面臨這些危機的時候', '，', '但是台灣明年面臨所面臨的狀況可能還有一個更重要的坎', '，', '我很清楚地說我們作為中華民國的領導人', '，', '必須認識四個地方', '：', '美國', '、', '日本', '、', '大陸', '、', '台灣', '。', '美國跟日本', '，', '明年的動態我們必須密切注意', '，', '中國大陸跟台灣能不能夠建立建設性的對話管道', '，', '這四個相互關聯的問題', '，', '明年都可能有一些微妙的變化', '，', '我們必須重視', '，', '預為綢繆', '。', '具體來說', '，', '我們兩個很重要的盟友', '，', '日本跟美國', '，', '明年三月份', '，', '中國大陸的領導人習近平將到日本進行國是訪問', '，', '而日本更會在明年的八月份邀請習近平再度去到東京參加奧運', '，', '因為日本奧運需要大陸的觀光客', '。', '而美國要求日本支付天文數字的美軍駐日的開銷以及加稅', '，', '把日本跟大陸越推越近', '。', '而美國方面', '，', '明年', '11', '月', '，', '美國的總統大選', '，', '當日本跟大陸的關係因為經濟因素拉近', '，', '美國跟大陸的關係也因為經濟的因素', '，', '他們已經彼此有交換', '，', '而大陸明文ㄉ承諾', '，', '將對美國採購超過', '500', '億美元的農產品', '，', '這個也是因為美國的川普總統要面臨大選', '，', '要爭取美國農業州的選票', '。', '這些變化我們可以掉以輕心嗎', '？', '所以我們要有一位能夠洞察世局變化具國際觀和國際溝通經驗的國家領導人', '，', '妥為因應', '。', '然而台灣最大問題還不是國際性的', '，', '是藍綠所築起的對決高牆', '。', '藍綠兩大黨面對問題的對策', '，', '就是一方面講藍軍要團結', '，', '一方面要講', '，', '綠軍也要團結', '。', '當我們的社會跟國家陷入藍綠', '，', '在那邊相互對戰', '，', '撕裂對立', '，', '而對於台灣這些急切需要去解決的重大問題', '，', '藍綠兩大黨都不願面對現實', '，', '只想相互杯葛', '，', '看對方出狀況', '，', '看對方鬧笑話', '，', '相互消磨', '，', '以對方的失敗來造就自己成功的機會', '，', '來獲取下一次選舉的勝利', '。', '這就是為什麼今天台灣', '，', '我們這麼多的鄉親這麼討厭政黨', '，', '因為各位鄉親了解得到台灣真正需要一位腳踏實地', '，', '以真正的行動', '，', '和他內心真正地感受得到要放下藍綠', '。', '宋楚瑜就是那一位不計個人毀譽', '、', '奮不顧身去為台灣打拼的人', '。', '因為我深信', '，', '我們雖然有不同的過去', '，', '但是我們卻有共同的未來', '，', '我們更有共同守護的價值', '，', '那就是我們珍惜今天在台灣', '，', '我們奮鬥這麼多年來所創造的我們自由民主的價值', '。', '因此', '，', '我們要守護這塊土地', '、', '守住我們共同的價值', '，', '那就是要選一位能夠真心誠意', '、', '放下藍綠', '，', '而真正讓我們全民在一起共同創造我們台灣未來的願景', '，', '讓全世界看到台灣的自由民主的價值', '，', '是不分黨派', '、', '不分族群', '、', '不分年齡', '，', '共同只有民主的價值是我們共同的', 'DNA', '。', '我們絕不放棄自由民主的制度', '，', '我們願為這一個時刻來選一個為大家服務的好總統', '，', '謝謝', '。', '各位親愛的朋友們', '，', '各位鄉親', '，', '聽到剛剛這兩位所發表的這些看法', '，', '就像我在參加這次的政見發表之前', '，', '我的同仁就跟我說', '，', '我相信蔡總統會把她這三年多以來的政績向大家來報告', '，', '而韓市長', '，', '我相信他會準備很多資料', '，', '來挑戰蔡總統所說這許多她的政績', '。', '我不需要再重複地把剛剛韓市長所說的', '，', '他準備的這些圖表', '，', '我相信回頭由蔡總統自己本身來做一些解說', '。', '坦白講', '，', '我們今天看到台灣面臨的環境', '，', '跟他們兩位所講的一樣', '，', '我們要面對世界變局', '。', '但是很顯然', '，', '確實台灣逐漸地被世界主流這些經濟體', '，', '把我們邊緣化了', '。', '坦白嚴格來講起來', '，', '剛剛蔡總統講到她這三年多來以來', '，', '她確實想要去推動一些改革', '。', '其實政治管三件事情', '。', '哪三件', '？', '管的就是政策', '，', '管的是資源分配', '，', '管的是用人', '。', '在民進黨這幾年的執政之下', '，', '我們看到蔡總統曾經反覆地說', '，', '她要追求社會的正義', '。', '以蘭嶼剛剛來說', '，', '不是靠道歉就可以去解決他們心中許許多多的這些不平', '。', '嚴格地講起來', '，', '何止是蘭嶼的鄉親', '、', '原住民', '，', '妳去看看三鶯地區', '，', '我們有多少原住民現在幾乎', '46', '％', '以上的', '，', '我們的原住民鄉親', '，', '都從山上部落已經到了我們平地', '。', '但是他們工作的問題', '、', '他們住的問題', '、', '他們的小朋友教育的問題', '、', '他們老人照顧的問題', '，', '坦白講不是用口去講', '，', '而是要去幫他們去解決這些問題', '。', '我們把今天看了那麼多的電', '，', '你去到了蘭嶼看', '，', '核廢料放在他們那裏', '，', '但到了夏天', '，', '我們蘭嶼的鄉親在迎接更多的觀光客', '，', '在民宿的地方', '，', '竟然停電', '，', '沒有電', '。', '花幾百萬塊錢', '，', '重加幾組發電機就可以解決的問題', '。', '有上百億的這些核廢料', '，', '這些預備金都沒有去幫他們去解決', '。', '我如果有機會回到政府', '，', '就像我走遍我們所有的', '55', '個原住民的鄉一樣', '，', '我會幫他們好好的', '、', '很快的把住的問題把都市住的問題', '，', '我們許許多多原住民的這些許多民宿的問題', '，', '我會好好幫大家去解決', '。', '蔡總統特別提到了改革要有魄力', '，', '但改革更需要的是方法', '，', '改革更重要的是要真正了解到', '，', '溝通是一個必要的手段', '。', '蔡政府在過去這幾年推動的幾項重大改革', '，', '坦白講', '，', '引起來的這些抗爭', '，', '那就是改革胡亂暴衝', '。', '為什麼我說改革暴衝呢', '？', '沒有經過行政院各部會跟立法部門好好研商', '，', '反而看到行政跟立法的脫勾', '，', '年金改革就是這樣一個例子', '。', '明明國民黨那邊妳索取清查他的黨產', '，', '婦聯會已經交出', '370', '億', '，', '這麼多錢可以把那些過去老兵這麼多平均', '84', '歲老兵的錢', '，', '你一毛不要去減少它', '，', '他們現在平均年齡', '84', '歲', '，', '一共現在從民國', '38', '年到台灣', '，', '還剩下只剩下', '10', '萬', '1225', '人', '，', '從', '79', '萬變成今天只剩下', '10', '萬多人', '，', '讓他們好好地在台灣', '，', '曾經為他們為台灣安全國防提出這麼多貢獻', '，', '但是為什麼要去扣他們一點點安老的錢呢', '？', '我曾經向陳副總統提出這些問題', '，', '我也曉得他想要去做些改革', '。', '改革要有方法', '，', '改革的財源明明有但是不會用', '。', '所以因此我們不管是年金改革', '、', '一例一休', '、', '公投法的所有這些事情', '，', '不過', '，', '每一次改革', '，', '只是讓被改革的人期待下一次的政黨輪替再改回來', '，', '台灣經得起這樣子不斷地折騰嗎', '？', '因此', '，', '我特別提到最近蔡總統也一樣到了高雄', '，', '但是韓市長沒有把這個問題講清楚', '，', '我也希望韓市長也特別了解一下', '，', '高雄你們在那邊所講的許許多多那些天花亂墜的話', '，', '國民黨', '、', '民進黨都要負責任', '。', '當年高雄港外面有多少船想進高雄還排不進去', '，', '我們那時候號稱要做亞太營運中心', '，', '卻戒急用忍', '，', '不跟大陸商來往', '。', '蔡英文開出了四道未來在高雄的大南方計畫', '，', '我隨便講一件事情', '，', '那就是所謂要有聚集的這一些問題要去處理好', '。', '您所說的要讓我們南方將來能夠聚落來帶動產業', '，', '請問五缺的問題解決了嗎', '？', '水在哪裡', '？', '電在哪裡', '？', '勞工在哪裏', '？', '優秀人才在哪裡', '？', '我們現在土地取得容易嗎', '？', '五缺的問題還在那裡', '。', '但是我很痛心地說', '，', '這些改革坦白講都不但沒有解決', '，', '反而是民進黨這些派系他們都不缺', '。', '你看所有這些重要的這些許許多多的職務', '，', '諸侯在分贓', '，', '人事酬庸', '，', '把重要職務', '、', '國營事業經營', '，', '都變成派系分贓的囊中物', '。', '所以因此這兩個政黨為什麼會變成台灣最大的兩個黨', '？', '一個叫做討厭國民黨', '，', '一個叫做討厭民進黨', '，', '大家都覺得', '，', '你們開了很多支票卻沒有辦法去兌現', '。', '其中關鍵的一件事情', '，', '就是要把兩岸問題處理好', '。', '蔡總統在', '2016', '年', '，', '您在總統選舉政見會辯論的時候', '，', '您曾經公開的說', '，', '兩岸問題絕不能被選舉拿來操弄', '，', '但很顯然', '，', '您開始有聽見我的話', '，', '那就是要把', '《', '中華民國憲法', '》', '跟', '《', '增修條文', '》', '以及', '《', '兩岸關係條例', '》', '作為基本架構', '，', '但是一到了選舉', '，', '很可惜您還是被那些派系綁架', '，', '把兩岸問題拿來作為選舉的操作', '，', '來製造一些情緒勒索', '，', '這些情緒勒索讓大家覺得不安', '。', '但是我必須說', '，', '台灣人真是要有自信', '，', '台灣民主價值是什麼', '？', '就是台灣人才是這塊土地的我們的真正主人', '，', '沒有任何人能夠出賣台灣', '，', '也沒有任何人能夠不重視我們的民意而妄做任何的決定', '。', '因此', '，', '我們需要一個真正解決問題的領導人', '。', '領導的人要有決斷力沒有錯', '，', '像蔡總統剛剛所說的', '，', '但是他的團隊要有紀律', '，', '不能夠在那邊胡搞瞎搞', '。', '要有策略', '，', '要能夠整合民意', '，', '最重要的是要有真正的經驗', '，', '能夠整合不同的這些意見', '，', '然後拿出可行的辦法', '。', '我有這個履歷表', '，', '我曾經操盤過台灣民主發展的過程', '，', '我也領導過省府團隊', '，', '謝謝', '。', '我剛剛聽到韓市長講的這段話', '，', '我可以說', '，', '韓市長你非常認真希望把高雄市好好辦好', '，', '繼續留在高雄', '，', '把你未完成的事情好好完成', '，', '我當選總統之後', '，', '我一定不會像民進黨那樣小裡小氣', '，', '我會大力支持你', '，', '讓你的夢想成真', '，', '讓高雄市民覺得唉呀我們終於培養出一個好的未來領導人', '。', '相對地', '，', '我也特別跟剛剛蔡總統特別提到的', '，', '那就是在選舉的時候', '，', '大家不要製造恐慌和戴帽子', '，', '嚴格講起來', '，', '蔡總統剛剛最後這段話非常重要', '，', '兩岸的問題', '，', '他所說的這些四點非常重要他的看法', '，', '我在這個地方也要向各位鄉親特別表達', '，', '楚瑜在這邊鄭重地宣示', '，', '我只做一任', '，', '在我這一任', '，', '我將撥亂反正', '，', '未來這四年', '，', '獨立和統一都不可能', '，', '但是宋楚瑜捍衛中華民國主權', '，', '堅持維護台灣自由民主的決心絕不改變', '，', '只求臺灣勝', '，', '中華民國贏', '，', '只做一任撥亂反正', '\\\\*', '3', '，', '因為很重要所以要說三遍', '。', '我為什麼要特別強調呢', '，', '那就是今天我們台灣面臨的環境', '，', '剛剛總統特別提到', '，', '就是兩岸問題必須好好地處理好', '，', '台灣的民主必須讓全世界覺得', '，', '這塊土地', '，', '我們台灣人自己能夠管好自己', '，', '我們要證明我們的治理是有效的', '。', '所以我作為中華民國人民選出的總統', '，', '我將來一定會樹立範例', '，', '那就是宋楚瑜未來的四年', '，', '要做五件重要的事情作為優先', '：', '第一', '，', '我要把國家的利益放在前面', '，', '把政黨的利益放在兩邊', '。', '我當選之後會邀請各黨各派的領導人到總統府共商國事', '，', '聽取不同政黨聲音', '，', '把當前台灣面對許許多多', '，', '包括兩岸問題', '、', '年改問題', '、', '健保問題', '，', '我希望聽大家不同的聲音', '，', '而且我會要求未來任命的行政院長要例行地到各個縣市好好溝通', '，', '資源共享不分黨派不分族群', '，', '而不是到選舉的時候鬥嘴', '。', '這是我非常堅持一定會說到做到的事情', '。', '第二', '，', '我會認真地網羅各黨各派的人才組成', '「', '大聯合政府', '」，', '換言之', '，', '過去幾任總統以來', '，', '把我們文官制度幾乎完全破壞了', '，', '我們要重新找回我們公務人員的榮譽', '。', '我簡單講一個事情', '，', '我在省政府的時候對一位公共衛生員在雲林', '，', '他去發現一位學生患了開放性的肺結核', '，', '他馬上繼續追蹤他的家人', '、', '學校同學有沒有', '，', '結果發現從一個案子發現', '2000', '個', '，', '一一追蹤幫他們治療', '，', '這就是一個公務員應盡的責任', '，', '讓我很感動', '，', '我對她一再表揚', '。', '大肚火車站交流道', '，', '因為枕木的下陷', '，', '出了車禍', '，', '去處理善後', '，', '不是只有去修這個交流道', '，', '全省', '770', '個這些交流道', '，', '欲全部重新好好地把它整修', '，', '這就是我們真正公務人員', '，', '我對這些省政府的以前老同仁', '，', '你們的貢獻', '，', '你們自認為是一個好的公務員的榮譽感要找回來', '，', '楚瑜會說到做到', '。', '第三', '，', '我會任命', '，', '立法院能夠同意的人來擔任行政院長', '，', '總統依照現在的憲法修改之後可以自由任命行政院長', '，', '但我向大家保證', '，', '總統的權力是要傾聽民意', '，', '要得到民意有基礎的人來當行政院長', '，', '宋楚瑜也說到做到', '。', '第四', '，', '我會尊重民意', '、', '尊重立法院', '，', '我當選後每年一定會到立法院做國情報告', '，', '直接聽取各政黨提問', '、', '聽他們意見', '，', '找回台灣民主的價值', '，', '做一個向人民負責的國家領導人', '。', '第五', '，', '作為中華民國總統要遵守憲法', '，', '要遵守中華民國憲法和增修條文', '，', '以及兩岸關係條例的精神來處理好兩岸關係', '，', '要在三個前提之下', '，', '這就是我回應剛剛蔡總統的話', '：', '一', '、', '尊重中華民國政府存在的事實', '，', '不諱言的', '，', '兩岸還存有政治經濟社會的差異', '，', '需要時間化解', '，', '因此兩岸要對等分治', '，', '共同努力', '，', '來求同化異', '。', '二', '、', '要用和平對等', '、', '有尊嚴的協商方式', '，', '解決兩岸爭議', '。', '三', '、', '確保台灣自有民主法治多元的共同價值的生活方式絕不妥協', '。', '如果兩岸有重要的協商結果', '，', '我一定親自到立法院報告', '，', '沒有台灣人民的同意我絕對不會輕作承諾', '，', '我確信台灣只有一個底線', '，', '任何台灣現狀的改變都要得到台灣', '2300', '萬人民用民主方式共同決定', '，', '而維護亞太地區的和平與安定', '，', '是我們中華民國政府對世界所應該盡的責任', '。', '因此目前', '，', '大家對於九二共識', '，', '或是對岸目前這些所謂滲透等等的話', '，', '我要跟蔡總統特別提醒', '，', '反滲透法如果', '12', '月', '31', '日你要強行通過的話', '，', '我到安全局去聽過簡報', '，', '他們也了解的到連宋楚瑜公開地在廣東', '23', '次的公開演講', '，', '我到底有沒有講過一國兩制他們都無法查證', '，', '都不能替我澄清', '。', '我還是您任命的', '，', '執政的', '。', '那', '200', '多萬的台商', '，', '到底如何證明他們的清白', '，', '讓政府的施政和法律的執行無效', '，', '這是對政府威信的傷害', '。', '做不到的事情要嚴謹的做', '，', '那就是', '，', '我們現在非常清楚地', '，', '我必須要提醒民進黨跟國民黨', '，', '三天之後', '，', '也就是', '12', '/', '21', '，', '韓市長', '，', '在高雄市', '，', '有兩場如同火車對撞的遊行同時舉行', '，', '集會遊行法是人民權力', '，', '但無論中央政府蔡總統或是地方政府都要負起責任', '，', '維護人民安全', '，', '不要讓有心人透過煽動製造社會混亂', '。', '當父母官沒有假期', '，', '隨時要心存百姓', '，', '我誠懇呼籲民進黨國民黨', '，', '雙方都應該自我克制', '，', '天佑台灣', '。', '我進來的時候記者問我', '，', '你會不會覺得被邊緣化', '？', '坦白講', '，', '我最擔心台灣民主被邊緣化', '。', '每位台灣鄉親如果感受不到政府在照顧他們', '，', '感覺被邊緣化', '，', '這才是我們做國家領導人的最重要的責任', '。', '因此', '，', '維護', '12', '/', '21', '安全', '，', '不要對撞', '。', '台灣過去選舉從來沒有流過血', '。', '這是我們光榮傳統', '，', '不要這次選舉選不下去', '。', '謝謝', '。']]]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "print(\"\\n\")\n",
        "# .words() 切成單詞\n",
        "myCorpus2.words()\n",
        "print(f\"分類語料庫有{len(myCorpus2.words())}個單詞\")\n",
        "print(f\"取前10詞：\\n{myCorpus2.words()[:10]}\")\n",
        "\n",
        "print(\"-----\")\n",
        "# .sents() 切成句子\n",
        "myCorpus2.sents()\n",
        "print(f\"分類語料庫有{len(myCorpus2.sents())}個句子\")\n",
        "print(f\"取前三句：\\n{myCorpus2.sents()[:3]}\")\n",
        "\n",
        "print(\"-----\")\n",
        "# .paras() 切成段落\n",
        "# 回傳：一個 list，其中每個元素是一個段落（paragraph）\n",
        "# 每個段落本身會是一個「由句子構成的 list」，\n",
        "# 每個句子又是一份「由 tokens 構成的 list」\n",
        "myCorpus2.paras()\n",
        "print(f\"分類語料庫有{len(myCorpus2.paras())}個段落\")\n",
        "print(f\"取前兩段：\\n{myCorpus2.paras()[:2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YON3bcbmC0k",
        "outputId": "2a1b819a-eb3d-4232-ebce-700c1aa93f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'have', 'no', 'doubt', 'that', 'the', 'military', 'had', 'authority', 'to', 'select', 'this', 'particular', 'property', 'for', 'destruction', '.', 'But', 'whatever', 'the', 'weight', 'of', 'authority', 'may', 'be', ',', 'I', 'believe', 'that', 'the', 'Fifth', 'Amendment', 'requires', 'compensation', 'for', 'the', 'taking', '.']\n"
          ]
        }
      ],
      "source": [
        "print(myCorpus2.words()[26:64]) #經過 tokenizer 後的所有 tokens（字詞）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_lBTTdimC0k",
        "outputId": "af266b9b-f6f7-4c72-c3ca-94baa415563a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(myCorpus2.paras(\"1952 U.S. LEXIS 2631.opin.neg.txt\"))\n",
        "\n",
        "# paras() 會回傳：\n",
        "# 一個 list，其中每個元素是一個段落（paragraph）\n",
        "# 每個段落本身會是一個「由句子構成的 list」，\n",
        "# 每個句子又是一份「由 tokens 構成的 list」"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "用 loop 總結你的文本"
      ],
      "metadata": {
        "id": "Hn7N5e4syw-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqKy8yOQmC0k",
        "outputId": "d2630e1e-3b99-4adc-91ad-fe4c74e34be0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1952 U.S. LEXIS 2631.opin.neg.txt\n",
            "7 paragraphs, 11 sentences, and 190 words\n",
            "\n",
            "1959 U.S. LEXIS 1490.opin.neg.txt\n",
            "2 paragraphs, 2 sentences, and 35 words\n",
            "\n",
            "1985 U.S. LEXIS 63.opin.neg.txt\n",
            "6 paragraphs, 7 sentences, and 45 words\n",
            "\n",
            "1986 U.S. LEXIS 25.opin.pos.txt\n",
            "8 paragraphs, 38 sentences, and 1230 words\n",
            "\n",
            "1986 U.S. LEXIS 72.opin.2.pos.txt\n",
            "6 paragraphs, 6 sentences, and 44 words\n",
            "\n",
            "1989 U.S. LEXIS 579.opin.6.pos 2.txt\n",
            "5 paragraphs, 10 sentences, and 231 words\n",
            "\n",
            "1989 U.S. LEXIS 579.opin.6.pos.txt\n",
            "5 paragraphs, 10 sentences, and 231 words\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Building a loop to summarize each document in your corpus       ## for publish: use the function prevuos people have done.\n",
        "for file in myCorpus2.fileids():  ##() : empty: all the files.\n",
        "    paras = len(myCorpus2.paras(file))   ## paragragh!\n",
        "    sents = len(myCorpus2.sents(file))   ## sentences!\n",
        "    words = len(myCorpus2.words(file))   ## words!\n",
        "    print(file)\n",
        "    print(str(paras) + \" paragraphs, \" + str(sents) + \\\n",
        "          \" sentences, and \" + str(words) + \" words\" + \"\\n\")\n",
        "\n",
        "# for file in myCorpus2.fileids():\n",
        "# myCorpus2.fileids() 會回傳 corpus 裡所有的檔案名稱（list）\n",
        "# for file in ... 表示要對 corpus 中 每一個文件都做一次統計\n",
        "\n",
        "# paras = len(myCorpus2.paras(file))\n",
        "# myCorpus2.paras(file) → 回傳「段落列表」\n",
        "# len(...) → 計算這篇文件有幾段（paragraphs）\n",
        "\n",
        "# sents = len(myCorpus2.sents(file))\n",
        "# myCorpus2.sents(file) → 回傳「句子列表」\n",
        "# len(...) → 計算句子的數量\n",
        "\n",
        "# words = len(myCorpus2.words(file))\n",
        "# myCorpus2.words(file) → 回傳整篇文章 tokenize 後的「字詞 list」\n",
        "# len(...) → 計算單字數量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRKmlf3fmC0l",
        "outputId": "0bc7b15b-8842-45fd-8a21-0c4fe8e32bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1986 U.S. LEXIS 25.opin.pos.txt\n",
            "1986 U.S. LEXIS 72.opin.2.pos.txt\n",
            "1989 U.S. LEXIS 579.opin.6.pos 2.txt\n",
            "1989 U.S. LEXIS 579.opin.6.pos.txt\n"
          ]
        }
      ],
      "source": [
        "## 設定只看某個類別\n",
        "for file in myCorpus2.fileids(categories=\"pos\"):   ## the files in that category\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhWOlyMUmC0l"
      },
      "outputs": [],
      "source": [
        "# 用函數總結你的文本   ## codes from the book and reword a bit!\n",
        "import time, nltk\n",
        "from nltk import pos_tag, sent_tokenize, wordpunct_tokenize\n",
        "\n",
        "def describe(self, fileids=None, categories=None):\n",
        "    \"\"\"\n",
        "    Performs a single pass of the corpus and\n",
        "    returns a dictionary with a variety of metrics\n",
        "    concerning the state of the corpus.\n",
        "    \"\"\"\n",
        "    started = time.time()   ## how much time needed\n",
        "\n",
        "    # Structures to perform counting.\n",
        "    counts  = nltk.FreqDist()\n",
        "    tokens  = nltk.FreqDist() # 一個專門用來計數的字典（frequency dictionary）。自動處理 key-value 增加（比 defaultdict 更方便）。\n",
        "\n",
        "    # 計算段落數\n",
        "    for para in self.paras(fileids, categories): # 走訪所有選到的段落，每遇到一個句子就加一。\n",
        "        counts['paras'] += 1\n",
        "    # 計算句子數\n",
        "    for sent in self.sents(fileids, categories):\n",
        "        counts['sents'] += 1\n",
        "\n",
        "    for word in self.words(fileids, categories):\n",
        "        counts['words'] += 1\n",
        "        tokens[word] += 1\n",
        "\n",
        "    # Compute the number of files and categories in the corpus\n",
        "    n_fileids = len(self.fileids())\n",
        "    n_topics  = len(self.categories())\n",
        "\n",
        "    # Return data structure with information\n",
        "    return {\n",
        "        'files':  n_fileids,\n",
        "        'topics': n_topics,\n",
        "        'paras':  counts['paras'],\n",
        "        'sents':  counts['sents'],\n",
        "        'words':  counts['words'],\n",
        "        'vocab':  len(tokens),\n",
        "        'lexical diversity': float(counts['words']) / float(len(tokens)),\n",
        "        'paragraphs per doc':  float(counts['paras']) / float(n_fileids),\n",
        "        'sentences per paragraph':  float(counts['sents']) / float(counts['paras']),\n",
        "        'secs':   time.time() - started,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjwQY_kBmC0s",
        "outputId": "c489f080-47a7-4994-d40d-37df292ce8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'files': 7,\n",
              " 'topics': 2,\n",
              " 'paras': 39,\n",
              " 'sents': 84,\n",
              " 'words': 2006,\n",
              " 'vocab': 638,\n",
              " 'lexical diversity': 3.1442006269592477,\n",
              " 'paragraphs per doc': 5.571428571428571,\n",
              " 'sentences per paragraph': 2.1538461538461537,\n",
              " 'secs': 0.03154444694519043}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "describe(myCorpus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DGweuIEmC0t",
        "outputId": "4feb3771-aaf6-4dd5-8405-d42d6314591f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'files': 7,\n",
              " 'topics': 2,\n",
              " 'paras': 15,\n",
              " 'sents': 20,\n",
              " 'words': 270,\n",
              " 'vocab': 140,\n",
              " 'lexical diversity': 1.9285714285714286,\n",
              " 'paragraphs per doc': 2.142857142857143,\n",
              " 'sentences per paragraph': 1.3333333333333333,\n",
              " 'secs': 0.00561213493347168}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "describe(myCorpus2, categories=\"neg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlsiwtEpmC0t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 如何使用課本中的程式碼 (Slide 15)"
      ],
      "metadata": {
        "id": "W4S1LynK1e3z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnBird_5mC0t",
        "outputId": "002331d4-effe-4e7c-bd22-61f160a12055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting readability-lxml\n",
            "  Downloading readability_lxml-0.8.4.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from readability-lxml) (5.2.0)\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.12/dist-packages (from readability-lxml) (6.0.2)\n",
            "Collecting cssselect (from readability-lxml)\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting lxml_html_clean (from lxml[html_clean]->readability-lxml)\n",
            "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading readability_lxml-0.8.4.1-py3-none-any.whl (19 kB)\n",
            "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: lxml_html_clean, cssselect, readability-lxml\n",
            "Successfully installed cssselect-1.3.0 lxml_html_clean-0.4.3 readability-lxml-0.8.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install readability-lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr0z0AAVmC0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8bbb58-c285-4176-9277-585beb084c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-01 07:06:31--  https://raw.githubusercontent.com/foxbook/atap/refs/heads/master/snippets/ch03/reader.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9710 (9.5K) [text/plain]\n",
            "Saving to: ‘reader.py’\n",
            "\n",
            "reader.py           100%[===================>]   9.48K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-12-01 07:06:31 (2.86 MB/s) - ‘reader.py’ saved [9710/9710]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#from ch03 import reader\n",
        "\n",
        "!wget https://raw.githubusercontent.com/foxbook/atap/refs/heads/master/snippets/ch03/reader.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "reader = importlib.import_module(\"reader\")"
      ],
      "metadata": {
        "id": "kpWAXFej3xN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0pnSyIfmC0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "d7c5b5e5-b7a6-4b45-cc32-9509ebb85e05"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No such file or directory: '/content/mc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1876612917.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmyTags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'h1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'li'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m myCorpus3 = reader.HTMLCorpusReader(mydir + \"mc/\",\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocumentPattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 tags=myTags)\n",
            "\u001b[0;32m/content/reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, encoding, tags, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Initialize the NLTK corpus reader objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mCategorizedCorpusReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mCorpusReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Save the tags that we specifically want to extract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, encoding, tagset)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPathPointer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CorpusReader: expected a string or a PathPointer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or directory: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/content/mc'"
          ]
        }
      ],
      "source": [
        "documentPattern = r'.*\\.json'\n",
        "myTags = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'li']\n",
        "\n",
        "myCorpus3 = reader.HTMLCorpusReader(mydir + \"mc/\",\n",
        "                fileids = documentPattern, encoding='utf8', \\\n",
        "                tags=myTags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-8JYTqgmC0u",
        "outputId": "de8a2378-bc21-4653-a17b-e02d82ad21b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'myCorpus3' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3442422359.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyCorpus3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'myCorpus3' is not defined"
          ]
        }
      ],
      "source": [
        "myCorpus3.fileids()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Vectorization"
      ],
      "metadata": {
        "id": "pK6UDFlp5DMu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGAgblYvmC0v"
      },
      "outputs": [],
      "source": [
        "## Slide 17\n",
        "## Function to tokenize and create frequency vectors using NLTK\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "# okenize() 函式 — 分詞 + 清理 + 詞幹化\n",
        "def tokenize(text):\n",
        "   stem = nltk.stem.SnowballStemmer('english')  #建立一個 詞幹化器（例如：running → run）\n",
        "   text = text.lower() #把整串文字變成小寫\n",
        "   tokens = []\n",
        "\n",
        "   for token in nltk.word_tokenize(text):\n",
        "       if token in string.punctuation: continue #丟掉標點符號\n",
        "       yield stem.stem(token) #例如 running → run 或是 studies → studi\n",
        "       tokens.append(token)\n",
        "   return tokens\n",
        "\n",
        "def tokenize(text):\n",
        "    stem = nltk.stem.SnowballStemmer('english')\n",
        "    text = text.lower()\n",
        "    tokens = []\n",
        "\n",
        "    for token in nltk.word_tokenize(text):\n",
        "        if token in string.punctuation:\n",
        "            continue\n",
        "        tokens.append(stem.stem(token))   # 用 stem 過的 token\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# vectorize function\n",
        "from collections import defaultdict\n",
        "\n",
        "def vectorize(doc):\n",
        "    features = defaultdict(int) # 建立一個 frequency dictionary\n",
        "    for token in tokenize(doc): # 逐一取得分詞結果（從 tokenize 函式）\n",
        "        features[token] += 1\n",
        "    return features\n",
        "\n",
        "# vectorize\"\n",
        "# 例如輸入：\"This is great, great!\"\n",
        "# tokenize 後：['this', 'is', 'great', 'great']\n",
        "# vector 會是：{'this': 1, 'is': 1 'great': 2}\n",
        "\n",
        "## 英文文件之間的重複字很少，所以如果把兩篇文章變成 Bag-of-Words vector 來比較，你會看到很多 0。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "例如輸入：```\"This is great, great!\"```\n",
        "\n",
        "tokenize 後：```['this', 'is', 'great', 'great'] ```\n",
        "\n",
        "vector 會是：\n",
        "```{'this': 1, 'is': 1 'great': 2} ```\n"
      ],
      "metadata": {
        "id": "sRJbxs5x8FNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKQ8OgyqmC0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f16ecce-f0b9-4181-cf16-1ae40b4599cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-616724644.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  doc = re.sub(\"\\s+\", \" \", doc) # 清理：把多個空白統一成一個空白\n"
          ]
        }
      ],
      "source": [
        "# Tokenize 文本，然後儲存成字串清單\n",
        "import re\n",
        "strCorpus = []  ## 每個元素是一篇完整文件的字串。\n",
        "for file in myCorpus2.fileids(): # myCorpus2.fileids() 會列出語料庫的所有檔名\n",
        "    doc = myCorpus2.raw(file) #讀取整篇文件的原始內容 (raw)\n",
        "    doc = re.sub(\"\\s+\", \" \", doc) # 清理：把多個空白統一成一個空白\n",
        "    strCorpus.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvuGfgOamC0v"
      },
      "outputs": [],
      "source": [
        "# 示範 NLP 程式碼的測試語料庫\n",
        "toyCorpus = [ \"The elephant sneezed at the sight of potatoes.\", \"Bats can see via echolocation. See the bat sight sneeze!\", \"Wondering, she opened the door to the studio.\", ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbTe3MQKmC0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23747a72-f9e2-4e99-bf3f-57e429e05c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[defaultdict(<class 'int'>, {'the': 2, 'eleph': 1, 'sneez': 1, 'at': 1, 'sight': 1, 'of': 1, 'potato': 1}), defaultdict(<class 'int'>, {'bat': 2, 'can': 1, 'see': 2, 'via': 1, 'echoloc': 1, 'the': 1, 'sight': 1, 'sneez': 1}), defaultdict(<class 'int'>, {'wonder': 1, 'she': 1, 'open': 1, 'the': 2, 'door': 1, 'to': 1, 'studio': 1})]\n"
          ]
        }
      ],
      "source": [
        "toyFreqVectors = map(vectorize, toyCorpus) # 把 vectorize() 函數套用到 toyCorpus 的每一個元素。\n",
        "print(list(toyFreqVectors)) # map() 回傳的是 lazy object：所以可以用 list() 展開，再輸出內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTkl7Bq1mC0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca8bfe4-eeb6-444b-e6db-e16bbee4661d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[defaultdict(<class 'int'>, {'author': 3, 'wodougla': 1, 'type': 1, 'dissent': 3, 'dissentbi': 1, 'dougla': 2, 'mr.': 2, 'justic': 2, 'with': 1, 'whom': 1, 'black': 1, 'concur': 1, 'i': 2, 'have': 1, 'no': 1, 'doubt': 1, 'that': 5, 'the': 18, 'militari': 1, 'had': 1, 'to': 5, 'select': 1, 'this': 3, 'particular': 1, 'properti': 4, 'for': 4, 'destruct': 3, 'but': 2, 'whatev': 2, 'weight': 1, 'of': 4, 'may': 2, 'be': 3, 'believ': 1, 'fifth': 1, 'amend': 1, 'requir': 1, 'compens': 1, 'take': 1, 'was': 4, 'destroy': 1, 'not': 1, 'becaus': 2, 'it': 6, 'in': 1, 'natur': 1, 'a': 2, 'public': 2, 'nuisanc': 1, 'deem': 1, 'necessari': 1, 'help': 1, 'win': 1, 'war': 2, 'as': 3, 'clear': 1, 'appropri': 2, 'end': 1, 'anim': 1, 'food': 1, 'and': 2, 'suppli': 1, 'requisit': 1, 'defens': 1, 'effort': 2, 'court': 1, 'say': 1, 'depriv': 1, 'enemi': 1, 'valuabl': 1, 'logist': 1, 'weapon': 1, 'seem': 1, 'me': 1, 'guid': 1, 'principl': 1, 'should': 2, 'whenev': 1, 'govern': 1, 'determin': 1, 'one': 1, 'person': 1, \"'s\": 1, '--': 2, 'is': 1, 'essenti': 1, 'common': 1, 'good': 1, 'purs': 1, 'rather': 1, 'than': 1, 'individu': 1, 'bear': 1, 'loss': 1}), defaultdict(<class 'int'>, {'author': 1, 'wodougla': 1, 'type': 1, 'dissent': 2, 'mr.': 1, 'justic': 1, 'dougla': 1, 'be': 1, 'of': 2, 'the': 2, 'view': 1, 'that': 1, 'petition': 1, 'was': 1, 'in': 2, 'substanc': 1, 'tri': 1, 'for': 1, 'murder': 1, 'twice': 1, 'violat': 1, 'guarante': 1, 'against': 1, 'doubl': 1, 'jeopardi': 1}), defaultdict(<class 'int'>, {'author': 1, 'tmarshal': 1, 'type': 1, 'dissent': 4, 'dissentbi': 1, 'marshal': 2, 'justic': 1, 'i': 2, 'continu': 1, 'to': 4, 'object': 1, 'decid': 1, 'case': 1, 'without': 1, 'grant': 1, 'either': 2, 'parti': 1, 'an': 1, 'opportun': 1, 'argu': 1, 'the': 1, 'merit': 1, 'by': 1, 'brief': 1, 'or': 1, 'oral': 1, 'argument': 1, 'therefor': 1}), defaultdict(<class 'int'>, {'author': 2, 'ascalia': 1, 'type': 1, 'dissent': 4, 'justic': 3, 'scalia': 1, 'with': 3, 'whom': 1, 'the': 89, 'chief': 1, 'and': 15, \"o'connor\": 1, 'join': 2, 'both': 1, 'right': 3, 'of': 46, 'free': 2, 'polit': 2, 'associ': 6, 'state': 9, \"'s\": 16, 'to': 33, 'establish': 1, 'arrang': 1, 'that': 22, 'assur': 2, 'fair': 1, 'effect': 1, 'parti': 38, 'particip': 2, 'in': 13, 'elect': 4, 'process': 4, 'are': 4, 'essenti': 1, 'democrat': 11, 'govern': 1, 'our': 1, 'case': 4, 'make': 1, 'it': 24, 'clear': 1, 'accommod': 1, 'these': 1, 'two': 2, 'vital': 1, 'interest': 4, 'doe': 3, 'not': 9, 'lend': 1, 'itself': 3, 'bright-lin': 1, 'rule': 2, 'but': 4, 'requir': 4, 'care': 1, 'inquiri': 1, 'into': 1, 'extent': 1, 'which': 5, 'one': 4, 'or': 4, 'other': 3, 'is': 17, 'inordin': 1, 'impair': 2, 'under': 2, 'fact': 4, 'particular': 1, 'see': 4, 'anderson': 1, 'v.': 6, 'celebrezz': 1, '460': 1, 'u.s.': 6, '780': 1, '788-790': 1, '1983': 1, 'storer': 1, 'brown': 1, '415': 2, '724': 1, '730': 1, '1974': 2, 'even': 3, 'so': 4, 'conclus': 2, 'reach': 2, 'on': 4, 'individu': 2, 'shed': 1, 'some': 1, 'measur': 1, 'light': 1, 'upon': 2, 'will': 1, 'be': 13, 'next': 1, 'sinc': 1, 'this': 7, 'an': 6, 'area': 1, 'moreov': 1, 'predict': 1, 'decis': 4, 'import': 4, 'i': 3, 'think': 1, 'worth': 1, 'note': 1, 'for': 3, 'me': 4, 'today': 1, 'alreadi': 1, 'exceed': 1, 'permiss': 1, 'limit': 1, 'first': 2, 'amend': 1, 'restrict': 3, 'order': 1, 'my': 2, 'view': 2, 'court': 2, 'opinion': 3, 'exagger': 1, 'at': 2, 'issu': 1, 'if': 5, 'inde': 1, 'where': 1, 'none': 1, 'exist': 1, 'there': 5, 'no': 6, 'question': 3, 'here': 2, 'republican': 9, 'abil': 4, 'recruit': 1, 'enrol': 1, 'member': 12, 'by': 16, 'offer': 1, 'them': 1, 'select': 8, 'candid': 13, 'conn.': 2, 'gen.': 1, 'stat': 1, '9-56': 1, '1985': 1, 'permit': 2, 'independ': 7, 'voter': 3, 'as': 9, 'late': 1, 'day': 1, 'befor': 2, 'primari': 6, 'cf': 1, 'kusper': 1, 'pontik': 1, '414': 1, '51': 1, '1973': 1, 'nor': 2, 'ani': 4, 'whatev': 1, 'they': 1, 'desir': 3, 'appelle': 1, 'onli': 1, 'complaint': 1, 'can': 5, 'leav': 1, 'person': 2, 'who': 4, 'unwil': 1, 'becom': 1, 'seem': 2, 'fanci': 1, 'refer': 1, 'freedom': 4, 'between': 2, 'putat': 1, 'connecticut': 3, 'while': 1, 'steadfast': 1, 'refus': 1, 'regist': 2, 'a': 14, 'cast': 1, 'vote': 5, 'form': 1, 'more': 4, 'meaning': 1, 'than': 5, 'respond': 1, 'pollster': 1, 'concept': 1, 'extend': 1, 'such': 1, 'casual': 1, 'contact': 1, 'ceas': 1, 'analyt': 1, 'use': 2, 'unit': 1, 'wisconsin': 1, 'ex': 1, 'rel': 1, 'la': 1, 'follett': 1, '450': 1, '107': 1, '130-131': 1, '1981': 1, 'powel': 1, 'j.': 1, '``': 2, 'everi': 1, 'conflict': 1, 'law': 2, 'concern': 1, 'nomin': 3, 'creat': 1, 'burden': 1, \"''\": 2, 'must': 1, 'their': 1, 'own': 1, 'hand': 1, 'unquestion': 1, 'implic': 1, '--': 6, 'hard': 1, 'thought': 2, 'unconstitut': 1, 'entir': 2, 'put': 1, 'forward': 1, 'wish': 2, 'has': 3, 'highest': 1, 'degre': 1, 'support': 2, 'among': 2, 'combin': 1, 'oblig': 1, 'howev': 2, 'let': 1, 'instead': 1, 'party-fund': 1, 'poll': 1, 'mean': 1, 'identifi': 1, 'relat': 1, 'popular': 1, 'potenti': 1, 'reason': 2, 'appar': 1, 'whi': 3, 'insist': 1, 'what': 1, 'might': 1, 'call': 1, 'choic': 4, 'taken': 1, 'membership': 2, 'fashion': 1, 'rather': 2, 'through': 1, 'dilut': 1, 'perhap': 1, 'absolut': 1, 'outnumb': 1, 'outsid': 3, 'character': 2, 'disparag': 1, 'attempt': 1, 'integr': 1, 'against': 2, 'ant': 1, '224.': 1, 'problem': 1, 'less': 1, 'true': 1, 'we': 3, 'have': 3, 'way': 1, 'know': 2, 'major': 3, 'favor': 1, 'allow': 1, 'ultim': 1, 'feder': 1, 'statewid': 1, 'offic': 2, 'determin': 2, 'was': 2, 'made': 1, 'ballot': 1, 'convent': 3, 'all': 1, 'may': 4, 'been': 1, 'domin': 1, 'officehold': 1, 'seeker': 1, 'whose': 1, 'evalu': 1, 'merit': 2, 'vis-a-vi': 1, 'propos': 1, 'faith': 1, 'philosophi': 1, 'diverg': 1, 'signific': 2, 'from': 1, 'rank': 1, 'file': 1, 'had': 1, 'alway': 1, 'purpos': 1, 'state-impos': 2, 'protect': 1, 'general': 1, 'sort': 1, 'minor': 1, 'control': 1, 'nader': 1, 'schaffer': 1, '417': 1, 'f.supp': 1, '837': 1, '843': 1, 'summarili': 1, 'aff': 1, \"'d\": 1, '429': 1, '989': 1, '1976': 1, 'second': 1, 'were': 1, 'want': 2, 'bound': 2, 'honor': 2, 'would': 1, 'express': 1, 'henceforth': 1, 'execut': 2, 'committe': 2, 'smoke-fil': 1, 'room': 1, 'word': 1, 'valid': 1, 'hitherto': 1, 'consid': 1, 'american': 1, 'texa': 1, 'white': 1, '767': 1, '781': 1, 'presuppos': 1, 'element': 1, 'whether': 1, 'beyond': 1, 'understand': 1, 'deleg': 2, 'proscrib': 1, 'nonmemb': 1, 'us': 1, 'said': 1, 'just': 1, 'recommend': 1, 'long': 2, 'name': 2, 'also': 1, 'him': 1, 'plain': 1, 'constitut': 1, 'respect': 1}), defaultdict(<class 'int'>, {'author': 1, 'wjbrennan': 1, 'type': 1, 'dissent': 3, 'dissentbi': 1, 'brennan': 2, 'white': 1, 'marshal': 1, 'justic': 1, 'i': 1, 'would': 1, 'affirm': 1, 'on': 1, 'the': 4, 'ground': 1, 'that': 1, 'challeng': 1, 'classif': 1, 'violat': 1, 'equal': 1, 'protect': 1, 'claus': 1, 'becaus': 1, 'they': 1, 'fail': 1, 'rational-basi': 1, 'test': 1}), defaultdict(<class 'int'>, {'author': 1, 'hablackmun': 1, 'type': 1, 'dissent': 2, 'justic': 4, 'blackmun': 1, 'with': 2, 'whom': 1, 'brennan': 1, 'join': 2, 'i': 4, 'marshal': 2, \"'s\": 3, 'percept': 1, 'and': 3, 'incis': 1, 'opinion': 1, 'reveal': 1, 'great': 3, 'sensit': 1, 'toward': 1, 'those': 2, 'who': 2, 'have': 1, 'suffer': 1, 'the': 16, 'pain': 1, 'of': 10, 'econom': 1, 'discrimin': 3, 'in': 4, 'construct': 1, 'trade': 1, 'for': 1, 'so': 2, 'long': 1, 'never': 2, 'thought': 1, 'that': 4, 'would': 2, 'live': 1, 'to': 4, 'see': 1, 'day': 2, 'when': 1, 'citi': 1, 'richmond': 3, 'virginia': 1, 'cradl': 1, 'old': 1, 'confederaci': 1, 'sought': 1, 'on': 1, 'it': 4, 'own': 1, 'within': 1, 'a': 2, 'narrow': 1, 'confin': 1, 'lessen': 1, 'stark': 1, 'impact': 1, 'persist': 1, 'but': 1, 'credit': 1, 'act': 1, 'yet': 1, 'this': 3, 'court': 2, 'suppos': 1, 'bastion': 1, 'equal': 1, 'strike': 1, 'down': 1, 'effort': 1, 'as': 1, 'though': 3, 'had': 1, 'exist': 1, 'or': 1, 'was': 1, 'not': 1, 'demonstr': 1, 'particular': 1, 'litig': 1, 'convinc': 1, 'disclos': 1, 'fallaci': 1, 'shallow': 1, 'approach': 1, 'histori': 1, 'is': 1, 'irrefut': 1, 'even': 1, 'one': 2, 'might': 1, 'sympath': 1, '--': 3, 'possibl': 1, 'innoc': 1, 'themselv': 1, 'benefit': 1, 'from': 1, 'wrong': 1, 'past': 1, 'decad': 1, 'today': 1, 'regress': 1, 'am': 1, 'confid': 1, 'howev': 1, 'given': 1, 'time': 1, 'again': 1, 'will': 1, 'do': 1, 'best': 1, 'fulfil': 2, 'promis': 1, 'constitut': 1, 'preambl': 1, 'guarante': 1, 'embodi': 1, 'bill': 1, 'right': 1, 'make': 1, 'nation': 1, 'veri': 1, 'special': 1}), defaultdict(<class 'int'>, {'author': 1, 'hablackmun': 1, 'type': 1, 'dissent': 2, 'justic': 4, 'blackmun': 1, 'with': 2, 'whom': 1, 'brennan': 1, 'join': 2, 'i': 4, 'marshal': 2, \"'s\": 3, 'percept': 1, 'and': 3, 'incis': 1, 'opinion': 1, 'reveal': 1, 'great': 3, 'sensit': 1, 'toward': 1, 'those': 2, 'who': 2, 'have': 1, 'suffer': 1, 'the': 16, 'pain': 1, 'of': 10, 'econom': 1, 'discrimin': 3, 'in': 4, 'construct': 1, 'trade': 1, 'for': 1, 'so': 2, 'long': 1, 'never': 2, 'thought': 1, 'that': 4, 'would': 2, 'live': 1, 'to': 4, 'see': 1, 'day': 2, 'when': 1, 'citi': 1, 'richmond': 3, 'virginia': 1, 'cradl': 1, 'old': 1, 'confederaci': 1, 'sought': 1, 'on': 1, 'it': 4, 'own': 1, 'within': 1, 'a': 2, 'narrow': 1, 'confin': 1, 'lessen': 1, 'stark': 1, 'impact': 1, 'persist': 1, 'but': 1, 'credit': 1, 'act': 1, 'yet': 1, 'this': 3, 'court': 2, 'suppos': 1, 'bastion': 1, 'equal': 1, 'strike': 1, 'down': 1, 'effort': 1, 'as': 1, 'though': 3, 'had': 1, 'exist': 1, 'or': 1, 'was': 1, 'not': 1, 'demonstr': 1, 'particular': 1, 'litig': 1, 'convinc': 1, 'disclos': 1, 'fallaci': 1, 'shallow': 1, 'approach': 1, 'histori': 1, 'is': 1, 'irrefut': 1, 'even': 1, 'one': 2, 'might': 1, 'sympath': 1, '--': 3, 'possibl': 1, 'innoc': 1, 'themselv': 1, 'benefit': 1, 'from': 1, 'wrong': 1, 'past': 1, 'decad': 1, 'today': 1, 'regress': 1, 'am': 1, 'confid': 1, 'howev': 1, 'given': 1, 'time': 1, 'again': 1, 'will': 1, 'do': 1, 'best': 1, 'fulfil': 2, 'promis': 1, 'constitut': 1, 'preambl': 1, 'guarante': 1, 'embodi': 1, 'bill': 1, 'right': 1, 'make': 1, 'nation': 1, 'veri': 1, 'special': 1})]\n"
          ]
        }
      ],
      "source": [
        "freqVectors = map(vectorize, strCorpus)\n",
        "print(list(freqVectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frnemoN8mC0v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scikit-Learn\n",
        "\n",
        "CountVectorizer = 自動：\n",
        "\n",
        "- tokenize\n",
        "- lowercase\n",
        "- remove punctuation\n",
        "- build vocabulary\n",
        "- build word-count vectors\n",
        "\n",
        "不需要你自己寫 tokenize 或 vectorize function。"
      ],
      "metadata": {
        "id": "bzoES_AN_y72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2tLtAfBmC0v",
        "outputId": "ce241f18-2e36-4172-c592-fe1bead8fa0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 20)\n",
            "[[1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 2 0 0 0]\n",
            " [0 1 1 1 0 1 0 0 0 0 2 0 1 1 0 0 1 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 2 1 0 1]]\n"
          ]
        }
      ],
      "source": [
        "# Scikit-Learn: 它使用 Scikit-Learn 的 CountVectorizer 來把文字轉換成 Bag-of-Words frequency vectors\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer() # 創建了一個「轉換器物件」\n",
        "toyFreqVectors2 = vectorizer.fit_transform(toyCorpus)\n",
        "#.fit()：讀進 corpus，找到所有出現的 vocabulary\n",
        "#.transform()：把每一篇文件轉成字頻向量\n",
        "\n",
        "print(toyFreqVectors2.shape)\n",
        "print(toyFreqVectors2.toarray())\n",
        "\n",
        "# shape:\n",
        "# 3 篇文件 → 3 rows\n",
        "# 15 個 unique tokens → 15 columns\n",
        "\n",
        "# .toarray → 把稀疏矩陣（sparse matrix）展開成 一般的二維矩陣（ array: list of lists）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIVX7RQ5mC0w",
        "outputId": "a75a2302-758c-4ba7-a60e-3b6b2e97ecc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 587)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 2, 1, 1],\n",
              "       [0, 0, 0, ..., 2, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "freqVectors2 = vectorizer.fit_transform(strCorpus)\n",
        "\n",
        "print(freqVectors2.shape)\n",
        "fvec = freqVectors2.toarray()\n",
        "fvec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Genism: Yet another way to create frequency vectors"
      ],
      "metadata": {
        "id": "rX5l1i6DA19D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx2A3kfBmC0w",
        "outputId": "8f149e09-4858-47ab-c586-3aeec702299c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "! pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJZT0KtfmC0w",
        "outputId": "21a10aa0-d347-426a-f643-3ecb564607ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install scipy\n",
        "! pip install numpy\n",
        "! pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgEiUB4GmC0w"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "\n",
        "tokToyCorpus = [tokenize(doc) for doc in toyCorpus] ## tokenize : u have to use it when using gensim!\n",
        "id2word = gensim.corpora.Dictionary(tokToyCorpus)\n",
        "toyFreqVectors3 = [id2word.doc2bow(doc) for doc in tokToyCorpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLAj-1dvmC0w",
        "outputId": "42257c89-0ec6-49b7-ae82-a804b72c64fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)], [(4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 2), (11, 1)], [(6, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]]\n"
          ]
        }
      ],
      "source": [
        "print(toyFreqVectors3)\n",
        "# 會得到 [(id, freq), (id, freq), ...]\n",
        "\n",
        "#doc1 = ['the','eleph','sneez','at','sight','potato','the']\n",
        "#doc2 = ['bat','can','see','see','the','sight','sneez','bat']\n",
        "#doc3 = ['wonder','she','open','door','to','the','studio']\n",
        "\n",
        "#0: 'the'\n",
        "#1: 'eleph'\n",
        "#2: 'sneez'\n",
        "#3: 'at'\n",
        "#4: 'sight'\n",
        "#5: 'potato'\n",
        "#6: 'bat'\n",
        "# So (6, 2) means: token with ID 6 appears 2 times in that document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOVrFOcPmC0w"
      },
      "outputs": [],
      "source": [
        "tokCorpus = [tokenize(doc) for doc in strCorpus]\n",
        "id2word = gensim.corpora.Dictionary(tokCorpus)\n",
        "freqVectors3 = [id2word.doc2bow(doc) for doc in tokCorpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWpLJJeymC0w"
      },
      "outputs": [],
      "source": [
        "#freqVectors3[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EGc2f-tmC0w",
        "outputId": "417511dc-8b3d-46fe-de78-ea6473edc4a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(freqVectors3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding\n",
        "\n",
        "用一個「二元值」表示是否包含某 token，集合（set）型式的 one-hot label。\n",
        "\n",
        "有些模型（特別是 early neural nets）\n",
        "只需要知道：某個詞是否出現\n",
        "而不需要知道它出現幾次。"
      ],
      "metadata": {
        "id": "VTdrG-BAEPU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NLTK One-Hot Encoding"
      ],
      "metadata": {
        "id": "pqlU6cHbA8j4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cPdzepVmC0w"
      },
      "outputs": [],
      "source": [
        "# NLTK, One-Hot Encoding\n",
        "def vectorizeOH(doc):\n",
        "    return {token: True for token in doc}\n",
        "\n",
        "tokToyCorpus = [tokenize(doc) for doc in toyCorpus]\n",
        "toyOHvectors = map(vectorizeOH, tokToyCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5Fwd-GSmC0w",
        "outputId": "ae863271-eaa7-46df-ef96-4ecf5a524901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'the': True, 'eleph': True, 'sneez': True, 'at': True, 'sight': True, 'of': True, 'potato': True}, {'bat': True, 'can': True, 'see': True, 'via': True, 'echoloc': True, 'the': True, 'sight': True, 'sneez': True}, {'wonder': True, 'she': True, 'open': True, 'the': True, 'door': True, 'to': True, 'studio': True}]\n"
          ]
        }
      ],
      "source": [
        "print(list(toyOHvectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfal8uGWmC0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365ebd57-8928-4a3b-f875-6c3251b072f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'author': True, 'wodougla': True, 'type': True, 'dissent': True, 'dissentbi': True, 'dougla': True, 'mr.': True, 'justic': True, 'with': True, 'whom': True, 'black': True, 'concur': True, 'i': True, 'have': True, 'no': True, 'doubt': True, 'that': True, 'the': True, 'militari': True, 'had': True, 'to': True, 'select': True, 'this': True, 'particular': True, 'properti': True, 'for': True, 'destruct': True, 'but': True, 'whatev': True, 'weight': True, 'of': True, 'may': True, 'be': True, 'believ': True, 'fifth': True, 'amend': True, 'requir': True, 'compens': True, 'take': True, 'was': True, 'destroy': True, 'not': True, 'becaus': True, 'it': True, 'in': True, 'natur': True, 'a': True, 'public': True, 'nuisanc': True, 'deem': True, 'necessari': True, 'help': True, 'win': True, 'war': True, 'as': True, 'clear': True, 'appropri': True, 'end': True, 'anim': True, 'food': True, 'and': True, 'suppli': True, 'requisit': True, 'defens': True, 'effort': True, 'court': True, 'say': True, 'depriv': True, 'enemi': True, 'valuabl': True, 'logist': True, 'weapon': True, 'seem': True, 'me': True, 'guid': True, 'principl': True, 'should': True, 'whenev': True, 'govern': True, 'determin': True, 'one': True, 'person': True, \"'s\": True, '--': True, 'is': True, 'essenti': True, 'common': True, 'good': True, 'purs': True, 'rather': True, 'than': True, 'individu': True, 'bear': True, 'loss': True}, {'author': True, 'wodougla': True, 'type': True, 'dissent': True, 'mr.': True, 'justic': True, 'dougla': True, 'be': True, 'of': True, 'the': True, 'view': True, 'that': True, 'petition': True, 'was': True, 'in': True, 'substanc': True, 'tri': True, 'for': True, 'murder': True, 'twice': True, 'violat': True, 'guarante': True, 'against': True, 'doubl': True, 'jeopardi': True}, {'author': True, 'tmarshal': True, 'type': True, 'dissent': True, 'dissentbi': True, 'marshal': True, 'justic': True, 'i': True, 'continu': True, 'to': True, 'object': True, 'decid': True, 'case': True, 'without': True, 'grant': True, 'either': True, 'parti': True, 'an': True, 'opportun': True, 'argu': True, 'the': True, 'merit': True, 'by': True, 'brief': True, 'or': True, 'oral': True, 'argument': True, 'therefor': True}, {'author': True, 'ascalia': True, 'type': True, 'dissent': True, 'justic': True, 'scalia': True, 'with': True, 'whom': True, 'the': True, 'chief': True, 'and': True, \"o'connor\": True, 'join': True, 'both': True, 'right': True, 'of': True, 'free': True, 'polit': True, 'associ': True, 'state': True, \"'s\": True, 'to': True, 'establish': True, 'arrang': True, 'that': True, 'assur': True, 'fair': True, 'effect': True, 'parti': True, 'particip': True, 'in': True, 'elect': True, 'process': True, 'are': True, 'essenti': True, 'democrat': True, 'govern': True, 'our': True, 'case': True, 'make': True, 'it': True, 'clear': True, 'accommod': True, 'these': True, 'two': True, 'vital': True, 'interest': True, 'doe': True, 'not': True, 'lend': True, 'itself': True, 'bright-lin': True, 'rule': True, 'but': True, 'requir': True, 'care': True, 'inquiri': True, 'into': True, 'extent': True, 'which': True, 'one': True, 'or': True, 'other': True, 'is': True, 'inordin': True, 'impair': True, 'under': True, 'fact': True, 'particular': True, 'see': True, 'anderson': True, 'v.': True, 'celebrezz': True, '460': True, 'u.s.': True, '780': True, '788-790': True, '1983': True, 'storer': True, 'brown': True, '415': True, '724': True, '730': True, '1974': True, 'even': True, 'so': True, 'conclus': True, 'reach': True, 'on': True, 'individu': True, 'shed': True, 'some': True, 'measur': True, 'light': True, 'upon': True, 'will': True, 'be': True, 'next': True, 'sinc': True, 'this': True, 'an': True, 'area': True, 'moreov': True, 'predict': True, 'decis': True, 'import': True, 'i': True, 'think': True, 'worth': True, 'note': True, 'for': True, 'me': True, 'today': True, 'alreadi': True, 'exceed': True, 'permiss': True, 'limit': True, 'first': True, 'amend': True, 'restrict': True, 'order': True, 'my': True, 'view': True, 'court': True, 'opinion': True, 'exagger': True, 'at': True, 'issu': True, 'if': True, 'inde': True, 'where': True, 'none': True, 'exist': True, 'there': True, 'no': True, 'question': True, 'here': True, 'republican': True, 'abil': True, 'recruit': True, 'enrol': True, 'member': True, 'by': True, 'offer': True, 'them': True, 'select': True, 'candid': True, 'conn.': True, 'gen.': True, 'stat': True, '9-56': True, '1985': True, 'permit': True, 'independ': True, 'voter': True, 'as': True, 'late': True, 'day': True, 'befor': True, 'primari': True, 'cf': True, 'kusper': True, 'pontik': True, '414': True, '51': True, '1973': True, 'nor': True, 'ani': True, 'whatev': True, 'they': True, 'desir': True, 'appelle': True, 'onli': True, 'complaint': True, 'can': True, 'leav': True, 'person': True, 'who': True, 'unwil': True, 'becom': True, 'seem': True, 'fanci': True, 'refer': True, 'freedom': True, 'between': True, 'putat': True, 'connecticut': True, 'while': True, 'steadfast': True, 'refus': True, 'regist': True, 'a': True, 'cast': True, 'vote': True, 'form': True, 'more': True, 'meaning': True, 'than': True, 'respond': True, 'pollster': True, 'concept': True, 'extend': True, 'such': True, 'casual': True, 'contact': True, 'ceas': True, 'analyt': True, 'use': True, 'unit': True, 'wisconsin': True, 'ex': True, 'rel': True, 'la': True, 'follett': True, '450': True, '107': True, '130-131': True, '1981': True, 'powel': True, 'j.': True, '``': True, 'everi': True, 'conflict': True, 'law': True, 'concern': True, 'nomin': True, 'creat': True, 'burden': True, \"''\": True, 'must': True, 'their': True, 'own': True, 'hand': True, 'unquestion': True, 'implic': True, '--': True, 'hard': True, 'thought': True, 'unconstitut': True, 'entir': True, 'put': True, 'forward': True, 'wish': True, 'has': True, 'highest': True, 'degre': True, 'support': True, 'among': True, 'combin': True, 'oblig': True, 'howev': True, 'let': True, 'instead': True, 'party-fund': True, 'poll': True, 'mean': True, 'identifi': True, 'relat': True, 'popular': True, 'potenti': True, 'reason': True, 'appar': True, 'whi': True, 'insist': True, 'what': True, 'might': True, 'call': True, 'choic': True, 'taken': True, 'membership': True, 'fashion': True, 'rather': True, 'through': True, 'dilut': True, 'perhap': True, 'absolut': True, 'outnumb': True, 'outsid': True, 'character': True, 'disparag': True, 'attempt': True, 'integr': True, 'against': True, 'ant': True, '224.': True, 'problem': True, 'less': True, 'true': True, 'we': True, 'have': True, 'way': True, 'know': True, 'major': True, 'favor': True, 'allow': True, 'ultim': True, 'feder': True, 'statewid': True, 'offic': True, 'determin': True, 'was': True, 'made': True, 'ballot': True, 'convent': True, 'all': True, 'may': True, 'been': True, 'domin': True, 'officehold': True, 'seeker': True, 'whose': True, 'evalu': True, 'merit': True, 'vis-a-vi': True, 'propos': True, 'faith': True, 'philosophi': True, 'diverg': True, 'signific': True, 'from': True, 'rank': True, 'file': True, 'had': True, 'alway': True, 'purpos': True, 'state-impos': True, 'protect': True, 'general': True, 'sort': True, 'minor': True, 'control': True, 'nader': True, 'schaffer': True, '417': True, 'f.supp': True, '837': True, '843': True, 'summarili': True, 'aff': True, \"'d\": True, '429': True, '989': True, '1976': True, 'second': True, 'were': True, 'want': True, 'bound': True, 'honor': True, 'would': True, 'express': True, 'henceforth': True, 'execut': True, 'committe': True, 'smoke-fil': True, 'room': True, 'word': True, 'valid': True, 'hitherto': True, 'consid': True, 'american': True, 'texa': True, 'white': True, '767': True, '781': True, 'presuppos': True, 'element': True, 'whether': True, 'beyond': True, 'understand': True, 'deleg': True, 'proscrib': True, 'nonmemb': True, 'us': True, 'said': True, 'just': True, 'recommend': True, 'long': True, 'name': True, 'also': True, 'him': True, 'plain': True, 'constitut': True, 'respect': True}, {'author': True, 'wjbrennan': True, 'type': True, 'dissent': True, 'dissentbi': True, 'brennan': True, 'white': True, 'marshal': True, 'justic': True, 'i': True, 'would': True, 'affirm': True, 'on': True, 'the': True, 'ground': True, 'that': True, 'challeng': True, 'classif': True, 'violat': True, 'equal': True, 'protect': True, 'claus': True, 'becaus': True, 'they': True, 'fail': True, 'rational-basi': True, 'test': True}, {'author': True, 'hablackmun': True, 'type': True, 'dissent': True, 'justic': True, 'blackmun': True, 'with': True, 'whom': True, 'brennan': True, 'join': True, 'i': True, 'marshal': True, \"'s\": True, 'percept': True, 'and': True, 'incis': True, 'opinion': True, 'reveal': True, 'great': True, 'sensit': True, 'toward': True, 'those': True, 'who': True, 'have': True, 'suffer': True, 'the': True, 'pain': True, 'of': True, 'econom': True, 'discrimin': True, 'in': True, 'construct': True, 'trade': True, 'for': True, 'so': True, 'long': True, 'never': True, 'thought': True, 'that': True, 'would': True, 'live': True, 'to': True, 'see': True, 'day': True, 'when': True, 'citi': True, 'richmond': True, 'virginia': True, 'cradl': True, 'old': True, 'confederaci': True, 'sought': True, 'on': True, 'it': True, 'own': True, 'within': True, 'a': True, 'narrow': True, 'confin': True, 'lessen': True, 'stark': True, 'impact': True, 'persist': True, 'but': True, 'credit': True, 'act': True, 'yet': True, 'this': True, 'court': True, 'suppos': True, 'bastion': True, 'equal': True, 'strike': True, 'down': True, 'effort': True, 'as': True, 'though': True, 'had': True, 'exist': True, 'or': True, 'was': True, 'not': True, 'demonstr': True, 'particular': True, 'litig': True, 'convinc': True, 'disclos': True, 'fallaci': True, 'shallow': True, 'approach': True, 'histori': True, 'is': True, 'irrefut': True, 'even': True, 'one': True, 'might': True, 'sympath': True, '--': True, 'possibl': True, 'innoc': True, 'themselv': True, 'benefit': True, 'from': True, 'wrong': True, 'past': True, 'decad': True, 'today': True, 'regress': True, 'am': True, 'confid': True, 'howev': True, 'given': True, 'time': True, 'again': True, 'will': True, 'do': True, 'best': True, 'fulfil': True, 'promis': True, 'constitut': True, 'preambl': True, 'guarante': True, 'embodi': True, 'bill': True, 'right': True, 'make': True, 'nation': True, 'veri': True, 'special': True}, {'author': True, 'hablackmun': True, 'type': True, 'dissent': True, 'justic': True, 'blackmun': True, 'with': True, 'whom': True, 'brennan': True, 'join': True, 'i': True, 'marshal': True, \"'s\": True, 'percept': True, 'and': True, 'incis': True, 'opinion': True, 'reveal': True, 'great': True, 'sensit': True, 'toward': True, 'those': True, 'who': True, 'have': True, 'suffer': True, 'the': True, 'pain': True, 'of': True, 'econom': True, 'discrimin': True, 'in': True, 'construct': True, 'trade': True, 'for': True, 'so': True, 'long': True, 'never': True, 'thought': True, 'that': True, 'would': True, 'live': True, 'to': True, 'see': True, 'day': True, 'when': True, 'citi': True, 'richmond': True, 'virginia': True, 'cradl': True, 'old': True, 'confederaci': True, 'sought': True, 'on': True, 'it': True, 'own': True, 'within': True, 'a': True, 'narrow': True, 'confin': True, 'lessen': True, 'stark': True, 'impact': True, 'persist': True, 'but': True, 'credit': True, 'act': True, 'yet': True, 'this': True, 'court': True, 'suppos': True, 'bastion': True, 'equal': True, 'strike': True, 'down': True, 'effort': True, 'as': True, 'though': True, 'had': True, 'exist': True, 'or': True, 'was': True, 'not': True, 'demonstr': True, 'particular': True, 'litig': True, 'convinc': True, 'disclos': True, 'fallaci': True, 'shallow': True, 'approach': True, 'histori': True, 'is': True, 'irrefut': True, 'even': True, 'one': True, 'might': True, 'sympath': True, '--': True, 'possibl': True, 'innoc': True, 'themselv': True, 'benefit': True, 'from': True, 'wrong': True, 'past': True, 'decad': True, 'today': True, 'regress': True, 'am': True, 'confid': True, 'howev': True, 'given': True, 'time': True, 'again': True, 'will': True, 'do': True, 'best': True, 'fulfil': True, 'promis': True, 'constitut': True, 'preambl': True, 'guarante': True, 'embodi': True, 'bill': True, 'right': True, 'make': True, 'nation': True, 'veri': True, 'special': True}]\n"
          ]
        }
      ],
      "source": [
        "tokCorpus = [tokenize(doc) for doc in strCorpus]\n",
        "OHvectors = map(vectorizeOH, tokCorpus)\n",
        "print(list(OHvectors))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scikit-learn, One-Hot Encoding\n",
        "\n",
        "而是把 Bag-of-Words 的「頻率矩陣」轉成「0/1 二值矩陣」"
      ],
      "metadata": {
        "id": "2s3VtODcEI1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0bMVEk0mC0y",
        "outputId": "924ae0a9-bd5f-4467-8b50-fe91b3c6284a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Scikit-learn, One-Hot Encoding\n",
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "# 建立字頻向量（frequency vectors）\n",
        "freq = CountVectorizer()\n",
        "corpus = freq.fit_transform(toyCorpus) # 生一個 Bag-of-Words 矩陣：\n",
        "\n",
        "# 建立 Binarizer 一個函數（把數字全部變 0/1）\n",
        "onehot = Binarizer()\n",
        "# 轉換成一般矩陣\n",
        "onehot.fit_transform(corpus.toarray())\n",
        "\n",
        "## the array is different from above. !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hoonc-05mC0y",
        "outputId": "17a3efa2-7150-4f26-c472-faf5fc7e2354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 1, 1],\n",
              "       [0, 0, 0, ..., 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "freq = CountVectorizer()\n",
        "corpus = freq.fit_transform(strCorpus)\n",
        "onehot = Binarizer()\n",
        "# Leaves the sparse array)\n",
        "OHvectors2 = onehot.fit_transform(corpus)\n",
        "onehot.fit_transform(corpus.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W4DlyuwmC0z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Genism, One-Hot Encoding"
      ],
      "metadata": {
        "id": "0WcCw0DbGTMz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD1wyeiamC0z"
      },
      "outputs": [],
      "source": [
        "# Genism, One-Hot Encoding\n",
        "tokToyCorpus = [tokenize(doc) for doc in toyCorpus] # 它會把每篇文章變成 tokens list：\n",
        "id2word = gensim.corpora.Dictionary(tokToyCorpus) # 建立 gensim dictionary\n",
        "toyOHvectors3 = [\n",
        "    [(token[0], 1) for token in id2word.doc2bow(doc)] # doc2bow = frequency vector（freq encoding）\n",
        "    for doc in tokToyCorpus\n",
        "]\n",
        "\n",
        "# 把 frequency vector 轉成 One-Hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3DcP6T3mC0z"
      },
      "outputs": [],
      "source": [
        "tokCorpus = [tokenize(doc) for doc in strCorpus] # tokenize 每一篇文件\n",
        "id2word = gensim.corpora.Dictionary(tokCorpus) # 建立 gensim 字典（token → id）\n",
        "OHvectors3 = [\n",
        "    [(token[0], 1) for token in id2word.doc2bow(doc)]\n",
        "    for doc in tokCorpus\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ-5KzySmC0z",
        "outputId": "903fb3f2-3d1b-44c1-96b0-f7e286e9946f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(OHvectors3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf-idf"
      ],
      "metadata": {
        "id": "Get4inMVBDwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnS6qWz1mC0z"
      },
      "outputs": [],
      "source": [
        "# NLTK, tf-idf encoding\n",
        "from nltk.text import TextCollection\n",
        "\n",
        "def vectorizeTF(corpus):\n",
        "    corpus = [tokenize(doc) for doc in corpus] # tokenize the corpus\n",
        "    texts = TextCollection(corpus) # TextCollection 是 NLTK 提供的：一個可以計算 tf、idf、tf-idf 的工具，它會讀整個 corpus，計算每個字在整個 corpus 中的 document frequency.\n",
        "\n",
        "    for doc in corpus:\n",
        "        yield {\n",
        "            term: texts.tf_idf(term, doc)\n",
        "            for term in doc\n",
        "        }\n",
        "\n",
        "## one word used a lot across different document, or a word only show up in a few document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-NmIDLymC0z"
      },
      "outputs": [],
      "source": [
        "toyTFvectors = map(vectorizeTF, toyCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaJsj-VgmC0z",
        "outputId": "5ef41120-5e89-41b9-ab2b-90febff5dbc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0:\n",
            "{'the': 0.0, 'eleph': 0.13732653608351372, 'sneez': 0.05068313851352055, 'at': 0.13732653608351372, 'sight': 0.05068313851352055, 'of': 0.13732653608351372, 'potato': 0.13732653608351372}\n",
            "\n",
            "Document 1:\n",
            "{'bat': 0.21972245773362198, 'can': 0.10986122886681099, 'see': 0.21972245773362198, 'via': 0.10986122886681099, 'echoloc': 0.10986122886681099, 'the': 0.0, 'sight': 0.04054651081081644, 'sneez': 0.04054651081081644}\n",
            "\n",
            "Document 2:\n",
            "{'wonder': 0.13732653608351372, 'she': 0.13732653608351372, 'open': 0.13732653608351372, 'the': 0.0, 'door': 0.13732653608351372, 'to': 0.13732653608351372, 'studio': 0.13732653608351372}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "toyTFvectors = list(vectorizeTF(toyCorpus))\n",
        "\n",
        "for i, vec in enumerate(toyTFvectors):\n",
        "    print(f\"Document {i}:\")\n",
        "    print(vec)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KjjpybRmC0z"
      },
      "outputs": [],
      "source": [
        "TFvectors = map(vectorizeTF, strCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-_FHJEFmC0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35eabe4f-3143-4bb7-de8e-67800012c95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0:\n",
            "{'author': 0.0, 'wodougla': 0.007638798588386391, 'type': 0.0, 'dissent': 0.0, 'dissentbi': 0.005166450368214657, 'dougla': 0.015277597176772783, 'mr.': 0.015277597176772783, 'justic': 0.0, 'with': 0.0034122913898501383, 'whom': 0.0034122913898501383, 'black': 0.011865305786922641, 'concur': 0.011865305786922641, 'i': 0.0018798863393568092, 'have': 0.0034122913898501383, 'no': 0.007638798588386391, 'doubt': 0.011865305786922641, 'that': 0.004699715848392023, 'the': 0.0, 'militari': 0.011865305786922641, 'had': 0.0034122913898501383, 'to': 0.010258299896988197, 'select': 0.007638798588386391, 'this': 0.010236874169550414, 'particular': 0.0034122913898501383, 'properti': 0.047461223147690565, 'for': 0.008206639917590559, 'destruct': 0.03559591736076792, 'but': 0.006824582779700277, 'whatev': 0.015277597176772783, 'weight': 0.011865305786922641, 'of': 0.008206639917590559, 'may': 0.015277597176772783, 'be': 0.015499351104643969, 'believ': 0.011865305786922641, 'fifth': 0.011865305786922641, 'amend': 0.007638798588386391, 'requir': 0.007638798588386391, 'compens': 0.011865305786922641, 'take': 0.011865305786922641, 'was': 0.008206639917590559, 'destroy': 0.011865305786922641, 'not': 0.0034122913898501383, 'becaus': 0.015277597176772783, 'it': 0.020473748339100827, 'in': 0.0020516599793976398, 'natur': 0.011865305786922641, 'a': 0.006824582779700277, 'public': 0.023730611573845282, 'nuisanc': 0.011865305786922641, 'deem': 0.011865305786922641, 'necessari': 0.011865305786922641, 'help': 0.011865305786922641, 'win': 0.011865305786922641, 'war': 0.023730611573845282, 'as': 0.010236874169550414, 'clear': 0.007638798588386391, 'appropri': 0.023730611573845282, 'end': 0.011865305786922641, 'anim': 0.011865305786922641, 'food': 0.011865305786922641, 'and': 0.006824582779700277, 'suppli': 0.011865305786922641, 'requisit': 0.011865305786922641, 'defens': 0.011865305786922641, 'effort': 0.010332900736429314, 'court': 0.0034122913898501383, 'say': 0.011865305786922641, 'depriv': 0.011865305786922641, 'enemi': 0.011865305786922641, 'valuabl': 0.011865305786922641, 'logist': 0.011865305786922641, 'weapon': 0.011865305786922641, 'seem': 0.007638798588386391, 'me': 0.007638798588386391, 'guid': 0.011865305786922641, 'principl': 0.011865305786922641, 'should': 0.023730611573845282, 'whenev': 0.011865305786922641, 'govern': 0.007638798588386391, 'determin': 0.007638798588386391, 'one': 0.0034122913898501383, 'person': 0.007638798588386391, \"'s\": 0.0034122913898501383, '--': 0.006824582779700277, 'is': 0.0034122913898501383, 'essenti': 0.007638798588386391, 'common': 0.011865305786922641, 'good': 0.011865305786922641, 'purs': 0.011865305786922641, 'rather': 0.007638798588386391, 'than': 0.007638798588386391, 'individu': 0.007638798588386391, 'bear': 0.011865305786922641, 'loss': 0.011865305786922641}\n",
            "\n",
            "Document 1:\n",
            "{'author': 0.0, 'wodougla': 0.043198723051564414, 'type': 0.0, 'dissent': 0.0, 'mr.': 0.043198723051564414, 'justic': 0.0, 'dougla': 0.043198723051564414, 'be': 0.02921716759955875, 'of': 0.023204981835945715, 'the': 0.0, 'view': 0.043198723051564414, 'that': 0.005315540683698564, 'petition': 0.06710034996742459, 'was': 0.011602490917972857, 'in': 0.023204981835945715, 'substanc': 0.06710034996742459, 'tri': 0.06710034996742459, 'for': 0.011602490917972857, 'murder': 0.06710034996742459, 'twice': 0.06710034996742459, 'violat': 0.043198723051564414, 'guarante': 0.02921716759955875, 'against': 0.043198723051564414, 'doubl': 0.06710034996742459, 'jeopardi': 0.06710034996742459}\n",
            "\n",
            "Document 2:\n",
            "{'author': 0.0, 'tmarshal': 0.052592166190684145, 'type': 0.0, 'dissent': 0.0, 'dissentbi': 0.022899942172627127, 'marshal': 0.030249502050563388, 'justic': 0.0, 'i': 0.008332469179851804, 'continu': 0.052592166190684145, 'to': 0.036375376932023015, 'object': 0.052592166190684145, 'decid': 0.052592166190684145, 'case': 0.03385845860798292, 'without': 0.052592166190684145, 'grant': 0.052592166190684145, 'either': 0.10518433238136829, 'parti': 0.03385845860798292, 'an': 0.03385845860798292, 'opportun': 0.052592166190684145, 'argu': 0.052592166190684145, 'the': 0.0, 'merit': 0.03385845860798292, 'by': 0.03385845860798292, 'brief': 0.052592166190684145, 'or': 0.015124751025281694, 'oral': 0.052592166190684145, 'argument': 0.052592166190684145, 'therefor': 0.052592166190684145}\n",
            "\n",
            "Document 3:\n",
            "{'author': 0.0, 'ascalia': 0.0018585579265093727, 'type': 0.0, 'dissent': 0.0, 'justic': 0.0, 'scalia': 0.0018585579265093727, 'with': 0.001603483633052787, 'whom': 0.000534494544350929, 'the': 0.0, 'chief': 0.0018585579265093727, 'and': 0.008017418165263935, \"o'connor\": 0.0018585579265093727, 'join': 0.0016185250437195868, 'both': 0.0018585579265093727, 'right': 0.00242778756557938, 'of': 0.01478292539118987, 'free': 0.0037171158530187455, 'polit': 0.0037171158530187455, 'associ': 0.011151347559056236, 'state': 0.016727021338584353, \"'s\": 0.008551912709614863, 'to': 0.010605142128462298, 'establish': 0.0018585579265093727, 'arrang': 0.0018585579265093727, 'that': 0.003239078277172573, 'assur': 0.0037171158530187455, 'fair': 0.0018585579265093727, 'effect': 0.0018585579265093727, 'parti': 0.04546799694634574, 'particip': 0.0037171158530187455, 'in': 0.0041777832627275715, 'elect': 0.007434231706037491, 'process': 0.007434231706037491, 'are': 0.007434231706037491, 'essenti': 0.001196526235430151, 'democrat': 0.0204441371916031, 'govern': 0.001196526235430151, 'our': 0.0018585579265093727, 'case': 0.004786104941720604, 'make': 0.0008092625218597934, 'it': 0.012827869064422296, 'clear': 0.001196526235430151, 'accommod': 0.0018585579265093727, 'these': 0.0018585579265093727, 'two': 0.0037171158530187455, 'vital': 0.0018585579265093727, 'interest': 0.007434231706037491, 'doe': 0.005575673779528118, 'not': 0.0048104508991583615, 'lend': 0.0018585579265093727, 'itself': 0.005575673779528118, 'bright-lin': 0.0018585579265093727, 'rule': 0.0037171158530187455, 'but': 0.002137978177403716, 'requir': 0.004786104941720604, 'care': 0.0018585579265093727, 'inquiri': 0.0018585579265093727, 'into': 0.0018585579265093727, 'extent': 0.0018585579265093727, 'which': 0.009292789632546865, 'one': 0.002137978177403716, 'or': 0.002137978177403716, 'other': 0.005575673779528118, 'is': 0.009086407253965792, 'inordin': 0.0018585579265093727, 'impair': 0.0037171158530187455, 'under': 0.0037171158530187455, 'fact': 0.007434231706037491, 'particular': 0.000534494544350929, 'see': 0.0032370500874391735, 'anderson': 0.0018585579265093727, 'v.': 0.011151347559056236, 'celebrezz': 0.0018585579265093727, '460': 0.0018585579265093727, 'u.s.': 0.011151347559056236, '780': 0.0018585579265093727, '788-790': 0.0018585579265093727, '1983': 0.0018585579265093727, 'storer': 0.0018585579265093727, 'brown': 0.0018585579265093727, '415': 0.0037171158530187455, '724': 0.0018585579265093727, '730': 0.0018585579265093727, '1974': 0.0037171158530187455, 'even': 0.00242778756557938, 'so': 0.0032370500874391735, 'conclus': 0.0037171158530187455, 'reach': 0.0037171158530187455, 'on': 0.002137978177403716, 'individu': 0.002393052470860302, 'shed': 0.0018585579265093727, 'some': 0.0018585579265093727, 'measur': 0.0018585579265093727, 'light': 0.0018585579265093727, 'upon': 0.0037171158530187455, 'will': 0.0008092625218597934, 'be': 0.010520412784177313, 'next': 0.0018585579265093727, 'sinc': 0.0018585579265093727, 'this': 0.0037414618104565033, 'an': 0.0071791574125809055, 'area': 0.0018585579265093727, 'moreov': 0.0018585579265093727, 'predict': 0.0018585579265093727, 'decis': 0.007434231706037491, 'import': 0.007434231706037491, 'i': 0.0004416924923417145, 'think': 0.0018585579265093727, 'worth': 0.0018585579265093727, 'note': 0.0018585579265093727, 'for': 0.0009641038298602089, 'me': 0.004786104941720604, 'today': 0.0008092625218597934, 'alreadi': 0.0018585579265093727, 'exceed': 0.0018585579265093727, 'permiss': 0.0018585579265093727, 'limit': 0.0018585579265093727, 'first': 0.0037171158530187455, 'amend': 0.001196526235430151, 'restrict': 0.005575673779528118, 'order': 0.0018585579265093727, 'my': 0.0037171158530187455, 'view': 0.002393052470860302, 'court': 0.001068989088701858, 'opinion': 0.00242778756557938, 'exagger': 0.0018585579265093727, 'at': 0.0037171158530187455, 'issu': 0.0018585579265093727, 'if': 0.009292789632546865, 'inde': 0.0018585579265093727, 'where': 0.0018585579265093727, 'none': 0.0018585579265093727, 'exist': 0.0008092625218597934, 'there': 0.009292789632546865, 'no': 0.0071791574125809055, 'question': 0.005575673779528118, 'here': 0.0037171158530187455, 'republican': 0.016727021338584353, 'abil': 0.007434231706037491, 'recruit': 0.0018585579265093727, 'enrol': 0.0018585579265093727, 'member': 0.022302695118112472, 'by': 0.019144419766882415, 'offer': 0.0018585579265093727, 'them': 0.0018585579265093727, 'select': 0.009572209883441207, 'candid': 0.024161253044621845, 'conn.': 0.0037171158530187455, 'gen.': 0.0018585579265093727, 'stat': 0.0018585579265093727, '9-56': 0.0018585579265093727, '1985': 0.0018585579265093727, 'permit': 0.0037171158530187455, 'independ': 0.013009905485565609, 'voter': 0.005575673779528118, 'as': 0.0048104508991583615, 'late': 0.0018585579265093727, 'day': 0.0008092625218597934, 'befor': 0.0037171158530187455, 'primari': 0.011151347559056236, 'cf': 0.0018585579265093727, 'kusper': 0.0018585579265093727, 'pontik': 0.0018585579265093727, '414': 0.0018585579265093727, '51': 0.0018585579265093727, '1973': 0.0018585579265093727, 'nor': 0.0037171158530187455, 'ani': 0.007434231706037491, 'whatev': 0.001196526235430151, 'they': 0.001196526235430151, 'desir': 0.005575673779528118, 'appelle': 0.0018585579265093727, 'onli': 0.0018585579265093727, 'complaint': 0.0018585579265093727, 'can': 0.009292789632546865, 'leav': 0.0018585579265093727, 'person': 0.002393052470860302, 'who': 0.0032370500874391735, 'unwil': 0.0018585579265093727, 'becom': 0.0018585579265093727, 'seem': 0.002393052470860302, 'fanci': 0.0018585579265093727, 'refer': 0.0018585579265093727, 'freedom': 0.007434231706037491, 'between': 0.0037171158530187455, 'putat': 0.0018585579265093727, 'connecticut': 0.005575673779528118, 'while': 0.0018585579265093727, 'steadfast': 0.0018585579265093727, 'refus': 0.0018585579265093727, 'regist': 0.0037171158530187455, 'a': 0.007482923620913007, 'cast': 0.0018585579265093727, 'vote': 0.009292789632546865, 'form': 0.0018585579265093727, 'more': 0.007434231706037491, 'meaning': 0.0018585579265093727, 'than': 0.005982631177150755, 'respond': 0.0018585579265093727, 'pollster': 0.0018585579265093727, 'concept': 0.0018585579265093727, 'extend': 0.0018585579265093727, 'such': 0.0018585579265093727, 'casual': 0.0018585579265093727, 'contact': 0.0018585579265093727, 'ceas': 0.0018585579265093727, 'analyt': 0.0018585579265093727, 'use': 0.0037171158530187455, 'unit': 0.0018585579265093727, 'wisconsin': 0.0018585579265093727, 'ex': 0.0018585579265093727, 'rel': 0.0018585579265093727, 'la': 0.0018585579265093727, 'follett': 0.0018585579265093727, '450': 0.0018585579265093727, '107': 0.0018585579265093727, '130-131': 0.0018585579265093727, '1981': 0.0018585579265093727, 'powel': 0.0018585579265093727, 'j.': 0.0018585579265093727, '``': 0.0037171158530187455, 'everi': 0.0018585579265093727, 'conflict': 0.0018585579265093727, 'law': 0.0037171158530187455, 'concern': 0.0018585579265093727, 'nomin': 0.005575673779528118, 'creat': 0.0018585579265093727, 'burden': 0.0018585579265093727, \"''\": 0.0037171158530187455, 'must': 0.0018585579265093727, 'their': 0.0018585579265093727, 'own': 0.0008092625218597934, 'hand': 0.0018585579265093727, 'unquestion': 0.0018585579265093727, 'implic': 0.0018585579265093727, '--': 0.003206967266105574, 'hard': 0.0018585579265093727, 'thought': 0.0016185250437195868, 'unconstitut': 0.0018585579265093727, 'entir': 0.0037171158530187455, 'put': 0.0018585579265093727, 'forward': 0.0018585579265093727, 'wish': 0.0037171158530187455, 'has': 0.005575673779528118, 'highest': 0.0018585579265093727, 'degre': 0.0018585579265093727, 'support': 0.0037171158530187455, 'among': 0.0037171158530187455, 'combin': 0.0018585579265093727, 'oblig': 0.0018585579265093727, 'howev': 0.0016185250437195868, 'let': 0.0018585579265093727, 'instead': 0.0018585579265093727, 'party-fund': 0.0018585579265093727, 'poll': 0.0018585579265093727, 'mean': 0.0018585579265093727, 'identifi': 0.0018585579265093727, 'relat': 0.0018585579265093727, 'popular': 0.0018585579265093727, 'potenti': 0.0018585579265093727, 'reason': 0.0037171158530187455, 'appar': 0.0018585579265093727, 'whi': 0.005575673779528118, 'insist': 0.0018585579265093727, 'what': 0.0018585579265093727, 'might': 0.0008092625218597934, 'call': 0.0018585579265093727, 'choic': 0.007434231706037491, 'taken': 0.0018585579265093727, 'membership': 0.0037171158530187455, 'fashion': 0.0018585579265093727, 'rather': 0.002393052470860302, 'through': 0.0018585579265093727, 'dilut': 0.0018585579265093727, 'perhap': 0.0018585579265093727, 'absolut': 0.0018585579265093727, 'outnumb': 0.0018585579265093727, 'outsid': 0.005575673779528118, 'character': 0.0037171158530187455, 'disparag': 0.0018585579265093727, 'attempt': 0.0018585579265093727, 'integr': 0.0018585579265093727, 'against': 0.002393052470860302, 'ant': 0.0018585579265093727, '224.': 0.0018585579265093727, 'problem': 0.0018585579265093727, 'less': 0.0018585579265093727, 'true': 0.0018585579265093727, 'we': 0.005575673779528118, 'have': 0.001603483633052787, 'way': 0.0018585579265093727, 'know': 0.0037171158530187455, 'major': 0.005575673779528118, 'favor': 0.0018585579265093727, 'allow': 0.0018585579265093727, 'ultim': 0.0018585579265093727, 'feder': 0.0018585579265093727, 'statewid': 0.0018585579265093727, 'offic': 0.0037171158530187455, 'determin': 0.002393052470860302, 'was': 0.0006427358865734726, 'made': 0.0018585579265093727, 'ballot': 0.0018585579265093727, 'convent': 0.005575673779528118, 'all': 0.0018585579265093727, 'may': 0.004786104941720604, 'been': 0.0018585579265093727, 'domin': 0.0018585579265093727, 'officehold': 0.0018585579265093727, 'seeker': 0.0018585579265093727, 'whose': 0.0018585579265093727, 'evalu': 0.0018585579265093727, 'merit': 0.002393052470860302, 'vis-a-vi': 0.0018585579265093727, 'propos': 0.0018585579265093727, 'faith': 0.0018585579265093727, 'philosophi': 0.0018585579265093727, 'diverg': 0.0018585579265093727, 'signific': 0.0037171158530187455, 'from': 0.0008092625218597934, 'rank': 0.0018585579265093727, 'file': 0.0018585579265093727, 'had': 0.000534494544350929, 'alway': 0.0018585579265093727, 'purpos': 0.0018585579265093727, 'state-impos': 0.0037171158530187455, 'protect': 0.001196526235430151, 'general': 0.0018585579265093727, 'sort': 0.0018585579265093727, 'minor': 0.0018585579265093727, 'control': 0.0018585579265093727, 'nader': 0.0018585579265093727, 'schaffer': 0.0018585579265093727, '417': 0.0018585579265093727, 'f.supp': 0.0018585579265093727, '837': 0.0018585579265093727, '843': 0.0018585579265093727, 'summarili': 0.0018585579265093727, 'aff': 0.0018585579265093727, \"'d\": 0.0018585579265093727, '429': 0.0018585579265093727, '989': 0.0018585579265093727, '1976': 0.0018585579265093727, 'second': 0.0018585579265093727, 'were': 0.0018585579265093727, 'want': 0.0037171158530187455, 'bound': 0.0037171158530187455, 'honor': 0.0037171158530187455, 'would': 0.000534494544350929, 'express': 0.0018585579265093727, 'henceforth': 0.0018585579265093727, 'execut': 0.0037171158530187455, 'committe': 0.0037171158530187455, 'smoke-fil': 0.0018585579265093727, 'room': 0.0018585579265093727, 'word': 0.0018585579265093727, 'valid': 0.0018585579265093727, 'hitherto': 0.0018585579265093727, 'consid': 0.0018585579265093727, 'american': 0.0018585579265093727, 'texa': 0.0018585579265093727, 'white': 0.001196526235430151, '767': 0.0018585579265093727, '781': 0.0018585579265093727, 'presuppos': 0.0018585579265093727, 'element': 0.0018585579265093727, 'whether': 0.0018585579265093727, 'beyond': 0.0018585579265093727, 'understand': 0.0018585579265093727, 'deleg': 0.0037171158530187455, 'proscrib': 0.0018585579265093727, 'nonmemb': 0.0018585579265093727, 'us': 0.0018585579265093727, 'said': 0.0018585579265093727, 'just': 0.0018585579265093727, 'recommend': 0.0018585579265093727, 'long': 0.0016185250437195868, 'name': 0.0037171158530187455, 'also': 0.0018585579265093727, 'him': 0.0018585579265093727, 'plain': 0.0018585579265093727, 'constitut': 0.0008092625218597934, 'respect': 0.0018585579265093727}\n",
            "\n",
            "Document 4:\n",
            "{'author': 0.0, 'wjbrennan': 0.058966974213797374, 'type': 0.0, 'dissent': 0.0, 'dissentbi': 0.025675692739006172, 'brennan': 0.051351385478012344, 'white': 0.03796251419682933, 'marshal': 0.016958054179861293, 'justic': 0.0, 'i': 0.004671232722038132, 'would': 0.016958054179861293, 'affirm': 0.058966974213797374, 'on': 0.016958054179861293, 'the': 0.0, 'ground': 0.058966974213797374, 'that': 0.004671232722038132, 'challeng': 0.058966974213797374, 'classif': 0.058966974213797374, 'violat': 0.03796251419682933, 'equal': 0.025675692739006172, 'protect': 0.03796251419682933, 'claus': 0.058966974213797374, 'becaus': 0.03796251419682933, 'they': 0.03796251419682933, 'fail': 0.058966974213797374, 'rational-basi': 0.058966974213797374, 'test': 0.058966974213797374}\n",
            "\n",
            "Document 5:\n",
            "{'author': 0.0, 'hablackmun': 0.00623265158455407, 'type': 0.0, 'dissent': 0.0, 'justic': 0.0, 'blackmun': 0.00623265158455407, 'with': 0.005568316297864902, 'whom': 0.002784158148932451, 'brennan': 0.004215412240732357, 'join': 0.008430824481464714, 'i': 0.0030676752204429523, 'marshal': 0.005568316297864902, \"'s\": 0.008352474446797353, 'percept': 0.00623265158455407, 'and': 0.008352474446797353, 'incis': 0.00623265158455407, 'opinion': 0.004215412240732357, 'reveal': 0.00623265158455407, 'great': 0.01869795475366221, 'sensit': 0.00623265158455407, 'toward': 0.00623265158455407, 'those': 0.01246530316910814, 'who': 0.008430824481464714, 'have': 0.002784158148932451, 'suffer': 0.00623265158455407, 'the': 0.0, 'pain': 0.00623265158455407, 'of': 0.016739912269712085, 'econom': 0.00623265158455407, 'discrimin': 0.01869795475366221, 'in': 0.006695964907884834, 'construct': 0.00623265158455407, 'trade': 0.00623265158455407, 'for': 0.0016739912269712084, 'so': 0.008430824481464714, 'long': 0.004215412240732357, 'never': 0.01246530316910814, 'thought': 0.004215412240732357, 'that': 0.0030676752204429523, 'would': 0.005568316297864902, 'live': 0.00623265158455407, 'to': 0.006695964907884834, 'see': 0.004215412240732357, 'day': 0.008430824481464714, 'when': 0.00623265158455407, 'citi': 0.00623265158455407, 'richmond': 0.01869795475366221, 'virginia': 0.00623265158455407, 'cradl': 0.00623265158455407, 'old': 0.00623265158455407, 'confederaci': 0.00623265158455407, 'sought': 0.00623265158455407, 'on': 0.002784158148932451, 'it': 0.011136632595729805, 'own': 0.004215412240732357, 'within': 0.00623265158455407, 'a': 0.005568316297864902, 'narrow': 0.00623265158455407, 'confin': 0.00623265158455407, 'lessen': 0.00623265158455407, 'stark': 0.00623265158455407, 'impact': 0.00623265158455407, 'persist': 0.00623265158455407, 'but': 0.002784158148932451, 'credit': 0.00623265158455407, 'act': 0.00623265158455407, 'yet': 0.00623265158455407, 'this': 0.008352474446797353, 'court': 0.005568316297864902, 'suppos': 0.00623265158455407, 'bastion': 0.00623265158455407, 'equal': 0.004215412240732357, 'strike': 0.00623265158455407, 'down': 0.00623265158455407, 'effort': 0.004215412240732357, 'as': 0.002784158148932451, 'though': 0.01869795475366221, 'had': 0.002784158148932451, 'exist': 0.004215412240732357, 'or': 0.002784158148932451, 'was': 0.0016739912269712084, 'not': 0.002784158148932451, 'demonstr': 0.00623265158455407, 'particular': 0.002784158148932451, 'litig': 0.00623265158455407, 'convinc': 0.00623265158455407, 'disclos': 0.00623265158455407, 'fallaci': 0.00623265158455407, 'shallow': 0.00623265158455407, 'approach': 0.00623265158455407, 'histori': 0.00623265158455407, 'is': 0.002784158148932451, 'irrefut': 0.00623265158455407, 'even': 0.004215412240732357, 'one': 0.005568316297864902, 'might': 0.004215412240732357, 'sympath': 0.00623265158455407, '--': 0.008352474446797353, 'possibl': 0.00623265158455407, 'innoc': 0.00623265158455407, 'themselv': 0.00623265158455407, 'benefit': 0.00623265158455407, 'from': 0.004215412240732357, 'wrong': 0.00623265158455407, 'past': 0.00623265158455407, 'decad': 0.00623265158455407, 'today': 0.004215412240732357, 'regress': 0.00623265158455407, 'am': 0.00623265158455407, 'confid': 0.00623265158455407, 'howev': 0.004215412240732357, 'given': 0.00623265158455407, 'time': 0.00623265158455407, 'again': 0.00623265158455407, 'will': 0.004215412240732357, 'do': 0.00623265158455407, 'best': 0.00623265158455407, 'fulfil': 0.01246530316910814, 'promis': 0.00623265158455407, 'constitut': 0.004215412240732357, 'preambl': 0.00623265158455407, 'guarante': 0.004215412240732357, 'embodi': 0.00623265158455407, 'bill': 0.00623265158455407, 'right': 0.004215412240732357, 'make': 0.004215412240732357, 'nation': 0.00623265158455407, 'veri': 0.00623265158455407, 'special': 0.00623265158455407}\n",
            "\n",
            "Document 6:\n",
            "{'author': 0.0, 'hablackmun': 0.00623265158455407, 'type': 0.0, 'dissent': 0.0, 'justic': 0.0, 'blackmun': 0.00623265158455407, 'with': 0.005568316297864902, 'whom': 0.002784158148932451, 'brennan': 0.004215412240732357, 'join': 0.008430824481464714, 'i': 0.0030676752204429523, 'marshal': 0.005568316297864902, \"'s\": 0.008352474446797353, 'percept': 0.00623265158455407, 'and': 0.008352474446797353, 'incis': 0.00623265158455407, 'opinion': 0.004215412240732357, 'reveal': 0.00623265158455407, 'great': 0.01869795475366221, 'sensit': 0.00623265158455407, 'toward': 0.00623265158455407, 'those': 0.01246530316910814, 'who': 0.008430824481464714, 'have': 0.002784158148932451, 'suffer': 0.00623265158455407, 'the': 0.0, 'pain': 0.00623265158455407, 'of': 0.016739912269712085, 'econom': 0.00623265158455407, 'discrimin': 0.01869795475366221, 'in': 0.006695964907884834, 'construct': 0.00623265158455407, 'trade': 0.00623265158455407, 'for': 0.0016739912269712084, 'so': 0.008430824481464714, 'long': 0.004215412240732357, 'never': 0.01246530316910814, 'thought': 0.004215412240732357, 'that': 0.0030676752204429523, 'would': 0.005568316297864902, 'live': 0.00623265158455407, 'to': 0.006695964907884834, 'see': 0.004215412240732357, 'day': 0.008430824481464714, 'when': 0.00623265158455407, 'citi': 0.00623265158455407, 'richmond': 0.01869795475366221, 'virginia': 0.00623265158455407, 'cradl': 0.00623265158455407, 'old': 0.00623265158455407, 'confederaci': 0.00623265158455407, 'sought': 0.00623265158455407, 'on': 0.002784158148932451, 'it': 0.011136632595729805, 'own': 0.004215412240732357, 'within': 0.00623265158455407, 'a': 0.005568316297864902, 'narrow': 0.00623265158455407, 'confin': 0.00623265158455407, 'lessen': 0.00623265158455407, 'stark': 0.00623265158455407, 'impact': 0.00623265158455407, 'persist': 0.00623265158455407, 'but': 0.002784158148932451, 'credit': 0.00623265158455407, 'act': 0.00623265158455407, 'yet': 0.00623265158455407, 'this': 0.008352474446797353, 'court': 0.005568316297864902, 'suppos': 0.00623265158455407, 'bastion': 0.00623265158455407, 'equal': 0.004215412240732357, 'strike': 0.00623265158455407, 'down': 0.00623265158455407, 'effort': 0.004215412240732357, 'as': 0.002784158148932451, 'though': 0.01869795475366221, 'had': 0.002784158148932451, 'exist': 0.004215412240732357, 'or': 0.002784158148932451, 'was': 0.0016739912269712084, 'not': 0.002784158148932451, 'demonstr': 0.00623265158455407, 'particular': 0.002784158148932451, 'litig': 0.00623265158455407, 'convinc': 0.00623265158455407, 'disclos': 0.00623265158455407, 'fallaci': 0.00623265158455407, 'shallow': 0.00623265158455407, 'approach': 0.00623265158455407, 'histori': 0.00623265158455407, 'is': 0.002784158148932451, 'irrefut': 0.00623265158455407, 'even': 0.004215412240732357, 'one': 0.005568316297864902, 'might': 0.004215412240732357, 'sympath': 0.00623265158455407, '--': 0.008352474446797353, 'possibl': 0.00623265158455407, 'innoc': 0.00623265158455407, 'themselv': 0.00623265158455407, 'benefit': 0.00623265158455407, 'from': 0.004215412240732357, 'wrong': 0.00623265158455407, 'past': 0.00623265158455407, 'decad': 0.00623265158455407, 'today': 0.004215412240732357, 'regress': 0.00623265158455407, 'am': 0.00623265158455407, 'confid': 0.00623265158455407, 'howev': 0.004215412240732357, 'given': 0.00623265158455407, 'time': 0.00623265158455407, 'again': 0.00623265158455407, 'will': 0.004215412240732357, 'do': 0.00623265158455407, 'best': 0.00623265158455407, 'fulfil': 0.01246530316910814, 'promis': 0.00623265158455407, 'constitut': 0.004215412240732357, 'preambl': 0.00623265158455407, 'guarante': 0.004215412240732357, 'embodi': 0.00623265158455407, 'bill': 0.00623265158455407, 'right': 0.004215412240732357, 'make': 0.004215412240732357, 'nation': 0.00623265158455407, 'veri': 0.00623265158455407, 'special': 0.00623265158455407}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "TFvectors = list(vectorizeTF(strCorpus))\n",
        "\n",
        "for i, vec in enumerate(TFvectors):\n",
        "    print(f\"Document {i}:\")\n",
        "    print(vec)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scikit-Learn, tf-idf encoding"
      ],
      "metadata": {
        "id": "05JQU58XbCuh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XZ07-rhmC0z"
      },
      "outputs": [],
      "source": [
        "# Scikit-Learn, tf-idf encoding\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "toyTFvectors2 = tfidf.fit_transform(toyCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFLuKbuYmC00",
        "outputId": "2cc7710a-1038-4b96-b585-0d793dcd40e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 23 stored elements and shape (3, 20)>\n",
            "  Coords\tValues\n",
            "  (0, 16)\t0.44730460893892116\n",
            "  (0, 6)\t0.37867626873820165\n",
            "  (0, 14)\t0.37867626873820165\n",
            "  (0, 0)\t0.37867626873820165\n",
            "  (0, 12)\t0.28799306292785165\n",
            "  (0, 7)\t0.37867626873820165\n",
            "  (0, 9)\t0.37867626873820165\n",
            "  (1, 16)\t0.1786694534059618\n",
            "  (1, 12)\t0.23006945204561577\n",
            "  (1, 2)\t0.30251368128649075\n",
            "  (1, 3)\t0.30251368128649075\n",
            "  (1, 10)\t0.6050273625729815\n",
            "  (1, 18)\t0.30251368128649075\n",
            "  (1, 5)\t0.30251368128649075\n",
            "  (1, 1)\t0.30251368128649075\n",
            "  (1, 13)\t0.30251368128649075\n",
            "  (2, 16)\t0.4343672818844283\n",
            "  (2, 19)\t0.3677238693250534\n",
            "  (2, 11)\t0.3677238693250534\n",
            "  (2, 8)\t0.3677238693250534\n",
            "  (2, 4)\t0.3677238693250534\n",
            "  (2, 17)\t0.3677238693250534\n",
            "  (2, 15)\t0.3677238693250534\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "print(toyTFvectors2)\n",
        "toyTFvectors2.shape\n",
        "\n",
        "# 結果是該字在 Document 0 的 TF-IDF 分數。\n",
        "# 位置\t意義\n",
        "# 0\t第 0 份文件（Document 0）\n",
        "# 16\t字典中 index = 16 的那個 token\n",
        "# 0.4473\t該文件的該 token 的 TF-IDF 分數\n",
        "\n",
        "# 該字在所有文件中是否常見？越罕見，分數越高。\n",
        "# TF × IDF = TF-IDF_final score\n",
        "# 像是\"the\" 在 三份文件都出現，所以它的 IDF 很接近 0。（越多人用的字 → 越不重要 → IDF 越低）\n",
        "# 算式 IDF(the) = log(N / df(the)) = log(3/3) = log(1) = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1NzlHuCmC00"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "TFvectors2 = tfidf.fit_transform(strCorpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orqDdViUmC00",
        "outputId": "36bfd571-0f94-4cbb-e9ea-4e7ec08e8607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 587)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "TFvectors2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbJvzaWjmC00"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### genism, tf-idf encoding"
      ],
      "metadata": {
        "id": "WyeTvVzkeHyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVViqQ8mmC00"
      },
      "outputs": [],
      "source": [
        "# genism, tf-idf encoding\n",
        "tokToyCorpus = [tokenize(doc) for doc in toyCorpus]\n",
        "lexicon = gensim.corpora.Dictionary(tokToyCorpus)\n",
        "tfidf = gensim.models.TfidfModel(dictionary=lexicon, normalize=True)\n",
        "toyTFvectors3 = [tfidf[lexicon.doc2bow(doc)] for doc in tokToyCorpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8YZIgPamC00",
        "outputId": "8418037d-2aab-410a-ff28-71ee36b4b783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, np.float64(0.4837965208957426)), (1, np.float64(0.4837965208957426)), (2, np.float64(0.4837965208957426)), (3, np.float64(0.4837965208957426)), (4, np.float64(0.17855490118826325)), (5, np.float64(0.17855490118826325))], [(4, np.float64(0.10992597952954358)), (5, np.float64(0.10992597952954358)), (7, np.float64(0.5956913654963344)), (8, np.float64(0.2978456827481672)), (9, np.float64(0.2978456827481672)), (10, np.float64(0.5956913654963344)), (11, np.float64(0.2978456827481672))], [(12, np.float64(0.408248290463863)), (13, np.float64(0.408248290463863)), (14, np.float64(0.408248290463863)), (15, np.float64(0.408248290463863)), (16, np.float64(0.408248290463863)), (17, np.float64(0.408248290463863))]]\n"
          ]
        }
      ],
      "source": [
        "print(toyTFvectors3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI8u8Jx_mC00"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distributed Representation\n",
        "\n",
        "\n",
        "TF, TF-IDF, BOW\tSparse（稀疏）、超大維度、90% 是 0\n",
        "- TF-IDF 是：[(3, 0.44), (26, 0.21), (88, 0.87), ...] （稀疏）\n",
        "\n",
        "Doc2Vec\tDense（密集）、低維度、沒有 0\n",
        "- Doc2Vec 得到的向量看起來像：[-0.13, 0.87, 0.05, -0.42, ...] （例如 100 維）\n",
        "- Doc2Vec 可理解語意（semantic representation）\n",
        "\n",
        "\n",
        "\n",
        "TF-IDF / BOW 只能比較哪些字出現一樣。如果字不重複就完全無法比較\n",
        "\n",
        "Doc2Vec 即使字完全不一樣，只要語意接近，向量相似度（cosine similarity）會靠近。這是分散式語意的強大之處。"
      ],
      "metadata": {
        "id": "FkoDIxe0BJ1Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58RIWZwTmC00",
        "outputId": "468e5a38-4a50-4921-f38f-c3bbca102b61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-5.2559674e-03 -5.9936498e-03 -9.9146254e-03  8.5665295e-03\n",
            "  3.5847796e-03  2.6267971e-04 -9.8911952e-03 -5.1613934e-03\n",
            " -9.7270506e-03  2.0224657e-03  2.8346470e-03  4.6406458e-03\n",
            " -4.3243794e-03 -3.1749432e-03 -3.0726346e-03 -8.7502059e-03\n",
            "  2.1682635e-03  9.2512239e-03 -9.5137712e-03 -3.4688634e-03\n",
            " -3.7633737e-03  2.6175780e-03 -5.7026939e-03  2.6463985e-03\n",
            "  5.7865707e-03 -8.1161438e-03 -8.3585950e-03 -9.9731311e-03\n",
            "  4.9417545e-03 -9.1574620e-03  5.8580614e-03  6.8114670e-03\n",
            " -6.5167653e-03 -4.5419913e-03 -1.2705415e-03  1.6345874e-03\n",
            " -1.4837370e-03 -8.5483706e-03 -3.6299569e-03  1.7294660e-03\n",
            " -2.0310427e-03 -7.2464654e-03  4.2032171e-03 -8.5925050e-03\n",
            "  2.7253102e-03 -4.6202657e-03  6.4654934e-04 -2.0457348e-03\n",
            "  5.4251067e-03 -8.0400398e-03 -2.1325520e-03 -7.6262681e-05\n",
            " -6.6337567e-03 -6.5803230e-03 -1.9557416e-03  8.8215312e-03\n",
            " -1.2637944e-03  3.5586639e-03 -5.7755318e-03  8.8291727e-03\n",
            "  2.9386890e-03  9.3009342e-03  4.3924297e-03 -4.2032376e-03\n",
            "  2.2444502e-03 -4.4188551e-03  5.7925293e-03  1.8414595e-03\n",
            " -2.3049368e-03 -5.8892933e-03 -8.0570737e-03 -8.5308874e-04\n",
            " -8.9493245e-03 -9.2283171e-03 -7.9420656e-03  2.1805645e-03\n",
            " -6.4925817e-03 -7.8082508e-03  2.1300097e-03  2.0451855e-03\n",
            "  8.3590578e-03  4.6819523e-03 -9.4456514e-03 -3.5458032e-04\n",
            "  7.8527071e-03  2.6930550e-03  2.7000178e-03 -4.8926664e-03\n",
            "  6.4851679e-03  1.6467690e-03 -7.6299459e-03  6.8895887e-03\n",
            " -9.7765019e-03 -8.1599606e-03 -4.8777321e-03  9.9633913e-03\n",
            "  3.1389296e-03 -2.0122137e-03  8.9285588e-03  2.3700253e-03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-687081128.py:13: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  print(toyModel.docvecs[0])\n"
          ]
        }
      ],
      "source": [
        "## Slide 20, Distributed Representation\n",
        "# Genism (the only option)\n",
        "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
        "\n",
        "corpus = [list(tokenize(doc)) for doc in toyCorpus] #先 tokenize corpus\n",
        "corpus = [\n",
        "    TaggedDocument(words, ['d{}'.format(idx)]) #  TaggedDocument 標記文件（Doc2Vec 必要步驟）\n",
        "    for idx, words in enumerate(corpus)\n",
        "]\n",
        "toyModel = Doc2Vec(corpus, min_count=0)  # size=5, 建立 Doc2Vec 模型\n",
        "\n",
        "print(toyModel.docvecs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhiIGnCemC00",
        "outputId": "25a3f554-5917-4874-f91c-701fd8b9d78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-4.2198738e-01  5.6964403e-01 -1.2523958e-01  6.6518670e-01\n",
            "  1.6320406e-01 -9.4609839e-01  1.2806635e-01  1.7377440e+00\n",
            " -4.7184888e-01 -7.8881389e-01 -5.0169196e-02 -1.4315276e+00\n",
            "  5.9740704e-01  1.1773859e+00  5.9406996e-01 -4.0982604e-01\n",
            "  9.1145575e-01  3.1282258e-01 -1.4885694e-01 -5.6883878e-01\n",
            " -5.4572470e-02  4.3965080e-01  2.0627999e-01  7.4375468e-01\n",
            "  2.4681708e-01  5.1529241e-01 -4.4300494e-01 -5.5855680e-01\n",
            "  3.0511139e-02 -9.0532142e-01  6.3319165e-01  3.3364210e-02\n",
            "  2.5430176e-01 -1.4377232e-01 -4.0192521e-01  6.2891191e-01\n",
            " -1.6899855e-01 -9.8733127e-01 -2.4156374e-01 -7.3019344e-01\n",
            " -1.0147717e-01  1.3203858e-01 -4.3308035e-01  2.8660846e-01\n",
            "  3.5042610e-02 -8.8911134e-01 -9.8572457e-01  1.8258080e-01\n",
            " -1.4504999e-01  7.7341920e-01 -5.7639575e-01  3.4444530e-02\n",
            " -3.4880501e-01  2.0311555e-01 -2.3843253e-01 -1.9748969e-01\n",
            " -7.8260446e-01  7.5431979e-01 -1.1491742e+00 -2.9330088e-02\n",
            "  7.9523295e-01  1.1019710e+00  2.9741484e-01  1.8451114e-01\n",
            " -5.4168254e-02  1.1440616e+00  5.8641464e-01  3.7020472e-01\n",
            " -1.0418884e+00  1.3135980e+00 -6.4476103e-01 -1.7541756e-01\n",
            " -3.7404534e-01 -2.9904526e-01  1.1658013e+00  1.0939380e-01\n",
            "  8.6304295e-01 -7.5127500e-01 -1.7386730e-01  1.0465569e+00\n",
            " -8.8592869e-01  8.3620459e-02 -1.3692178e+00  1.1117727e+00\n",
            " -6.2473375e-01  6.6295010e-01  1.0671260e-01  1.6684383e-01\n",
            " -1.1330262e-03 -7.6355290e-01 -1.2903753e-01  5.9498954e-01\n",
            " -8.7463945e-01 -2.8107101e-01  2.4628165e-01  9.0626216e-01\n",
            "  7.4821129e-02  5.5197090e-01  3.4065664e-01  3.2997090e-02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1479814973.py:9: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  print(model.docvecs[3])\n"
          ]
        }
      ],
      "source": [
        "corpus = [list(tokenize(doc)) for doc in strCorpus]\n",
        "corpus = [\n",
        "    TaggedDocument(words, ['d{}'.format(idx)])\n",
        "    for idx, words in enumerate(corpus)\n",
        "]\n",
        "\n",
        "model = Doc2Vec(corpus, min_count=3)  # size=10, min_count=3 出現至少 3 次的詞才會被模型使用\n",
        "\n",
        "print(model.docvecs[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_UW0jXlmC00"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 文件分類器 (Document Classifier)\n",
        "\n",
        "使用 One-Hot Encoding → Naive Bayes → 訓練 → 預測。\n",
        "\n",
        "非常基本、非常簡化的小範例。\n",
        "\n",
        "- Step 1：向量化文字（X）: One-Hot Encoding 版本\n",
        "（每篇文章變成一個 0/1 的向量）\\\\\n",
        "\n",
        "- Step 2：做標籤（y）: 根據每篇 document 的 category （正負文本最常用）\n",
        "\n",
        "- Step 3：使用機器學習模型: Multinomial Naive Bayes\n",
        "（適合文字分類）\n",
        "\n",
        "- Step 4：進行預測: 拿文件向量去預測類別\n",
        "（示範如何分類）"
      ],
      "metadata": {
        "id": "sibOzdAen8MR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKnFUoFJpLvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "製作 X matrix：文件向量（one-hot）:作用：把每個 document 轉成數學向量"
      ],
      "metadata": {
        "id": "BW96gV2KoFBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp0S5LYRmC00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ef55d5-8f7a-429c-9650-35e183d3c485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 1, 1],\n",
              "       [0, 0, 0, ..., 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Create the X matrix (with one-hot encoding)\n",
        "freq = CountVectorizer()\n",
        "corpus = freq.fit_transform(strCorpus)\n",
        "onehot = Binarizer()\n",
        "# Converts the sparse array to a dense one (so we can view it)\n",
        "documents = onehot.fit_transform(corpus.toarray())\n",
        "documents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "製作 y vector：標注每份文件（分類類別）\n",
        "\n",
        "X：文件向量 \\\n",
        "y：文件的類別（正評？負評？哪一種案件？）"
      ],
      "metadata": {
        "id": "gXtdMuJjoJ-S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlaibfNLmC00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8400d61c-33d4-4c87-8406-623e42937b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg']\n",
            "['neg']\n",
            "['neg']\n",
            "['pos']\n",
            "['pos']\n",
            "['pos']\n",
            "['pos']\n"
          ]
        }
      ],
      "source": [
        "# Create the y vector with the labels for each document\n",
        "labels = []\n",
        "for doc in myCorpus2.fileids():\n",
        "    lab = myCorpus2.categories(doc)\n",
        "    labels.append(lab)\n",
        "    print(lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "訓練模型（Naive Bayes）\n",
        "\n",
        "使用 Multinomial Naive Bayes （常用於文字分類）訓練分類模型。\n",
        "\n",
        "alpha=0.0 = 不做 smoothing（教科書示範）\n",
        "\n",
        "class_prior=[0.4, 0.6]  假設兩類的機率（演示用）"
      ],
      "metadata": {
        "id": "YjfZreq9oeH5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL3E0s7KmC01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "becef6a9-19b7-4b17-840f-daa5eac4e7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/naive_bayes.py:898: RuntimeWarning: divide by zero encountered in log\n",
            "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Use the fit method (with a naive bayes model)\n",
        "# Note: 6 documents is way too few to train a model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB(alpha=0.0, class_prior=[0.4, 0.6])\n",
        "\n",
        "model.fit(documents, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "用模型進行預測"
      ],
      "metadata": {
        "id": "nTA2KsgloqhF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncHIpSn-mC01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd92563-ca0c-4d82-c40e-e19858d41fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg'], dtype='<U3')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Now that the model is fit, we can use the predict method\n",
        "# Here I am using the same documents for fit and predict\n",
        "# In real applications, you would use them on different documents\n",
        "model.predict(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ay3Sq6lylFkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 你其實就可以跑 topic model 了"
      ],
      "metadata": {
        "id": "HAHzgDBmoXJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import nltk\n",
        "#import string\n",
        "#from nltk.corpus import stopwords\n",
        "\n",
        "#nltk.download('stopwords')\n",
        "\n",
        "#def tokenize(text):\n",
        "#    stemmer = nltk.stem.SnowballStemmer('english')\n",
        "\n",
        "#    # 內建 stopwords\n",
        "#    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#    # 自己加的 stopwords（法律文件常見無意義字）\n",
        "#    custom_stop = {\n",
        "#        \"court\", \"judge\", \"case\", \"opinion\", \"states\",\n",
        "#        \"justice\", \"law\", \"u\", \"s\", \"v\", \"section\"\n",
        "#    }\n",
        "\n",
        "#    # 合併\n",
        "#    stop_words = stop_words.union(custom_stop)\n",
        "\n",
        "#    # 轉小寫\n",
        "#    text = text.lower()\n",
        "#    tokens = []\n",
        "\n",
        "#    for token in nltk.word_tokenize(text):\n",
        "\n",
        "#        # 去除標點符號\n",
        "#        if token in string.punctuation:\n",
        "#            continue\n",
        "\n",
        "#        # 去除停用詞\n",
        "#        if token in stop_words:\n",
        "#            continue\n",
        "\n",
        "#        # 只保留字母（刪掉純數字、No. 123、1852、lexis 之類雜訊）\n",
        "#        if not token.isalpha():\n",
        "#            continue\n",
        "\n",
        "#        # 詞幹化\n",
        "#        tokens.append(stemmer.stem(token))\n",
        "\n",
        "#    return tokens\n"
      ],
      "metadata": {
        "id": "dFnm1WiSr0F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 整理資料\n",
        "\n",
        "LDA 所需要的全部資料：\n",
        "\n",
        "tokCorpus = tokenized documents（list of tokens every document）\n",
        "\n",
        "id2word = dictionary（token → integer id）\n",
        "\n",
        "freqVectors3 = doc-term matrix（稀疏 BOW）"
      ],
      "metadata": {
        "id": "aIdxbdcEodBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokCorpus = [tokenize(doc) for doc in strCorpus]\n",
        "id2word = gensim.corpora.Dictionary(tokCorpus)\n",
        "freqVectors3 = [id2word.doc2bow(doc) for doc in tokCorpus]"
      ],
      "metadata": {
        "id": "CvIfXd4foK9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立 Topic Model（最常用是 LDA）"
      ],
      "metadata": {
        "id": "R1Rmd8Xxo0wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "num_topics = 5  # ← 你要自己決定（5, 10, 20 都可以）\n",
        "lda_model = LdaModel(corpus=freqVectors3,\n",
        "                     id2word=id2word,\n",
        "                     num_topics=num_topics,\n",
        "                     random_state=42,\n",
        "                     passes=10)\n"
      ],
      "metadata": {
        "id": "iCVGJD56n3Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 查看每個 Topic 的 Top Words"
      ],
      "metadata": {
        "id": "fvgcU8ASo2yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model.print_topics(num_words=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tbxdsS2n340",
        "outputId": "2bc731af-1678-4dfe-a7f1-506189e7db67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.063*\"the\" + 0.040*\"of\" + 0.016*\"to\" + 0.016*\"it\" + 0.016*\"i\" + 0.016*\"that\" + 0.016*\"justic\" + 0.016*\"in\" + 0.012*\"and\" + 0.012*\"\\'s\"'),\n",
              " (1,\n",
              "  '0.002*\"of\" + 0.002*\"the\" + 0.002*\"in\" + 0.002*\"that\" + 0.002*\"to\" + 0.002*\"it\" + 0.002*\"parti\" + 0.002*\"dissent\" + 0.002*\"\\'s\" + 0.002*\"justic\"'),\n",
              " (2,\n",
              "  '0.037*\"the\" + 0.030*\"dissent\" + 0.013*\"of\" + 0.013*\"that\" + 0.013*\"in\" + 0.013*\"author\" + 0.013*\"justic\" + 0.013*\"type\" + 0.013*\"violat\" + 0.013*\"brennan\"'),\n",
              " (3,\n",
              "  '0.005*\"the\" + 0.004*\"parti\" + 0.004*\"of\" + 0.003*\"that\" + 0.003*\"to\" + 0.003*\"it\" + 0.002*\"is\" + 0.002*\"\\'s\" + 0.002*\"a\" + 0.002*\"and\"'),\n",
              " (4,\n",
              "  '0.080*\"the\" + 0.037*\"of\" + 0.031*\"to\" + 0.029*\"parti\" + 0.022*\"it\" + 0.020*\"that\" + 0.013*\"is\" + 0.013*\"and\" + 0.013*\"\\'s\" + 0.013*\"by\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 查看每份文件的 Topic Distribution"
      ],
      "metadata": {
        "id": "7CYibULfo7PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(freqVectors3):\n",
        "    print(f\"Document {i}:\")\n",
        "    print(lda_model.get_document_topics(doc))\n",
        "\n",
        "# Document 0: [(4, np.float32(0.9899633))]\n",
        "# 文件 0 幾乎完全是 Topic 4，機率= 0.9899（99%）"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcLHwaufn6A2",
        "outputId": "489d4b92-3c19-4c4c-bc71-8763522288a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0:\n",
            "[(4, np.float32(0.99511147))]\n",
            "Document 1:\n",
            "[(2, np.float32(0.97303814))]\n",
            "Document 2:\n",
            "[(4, np.float32(0.97864693))]\n",
            "Document 3:\n",
            "[(4, np.float32(0.99923295))]\n",
            "Document 4:\n",
            "[(2, np.float32(0.9762821))]\n",
            "Document 5:\n",
            "[(0, np.float32(0.9960197))]\n",
            "Document 6:\n",
            "[(0, np.float32(0.99601966))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(lda_model, freqVectors3, id2word)\n",
        "\n",
        "#encoding 確認，確認是否有字體"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CP7SBBL6n9v5",
        "outputId": "849f9e38-32ec-407d-de0c-040ee5dc039b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (1.16.3)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (1.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.14.1)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim->pyLDAvis) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->pyLDAvis) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim->pyLDAvis) (2.0.1)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "4     -0.031141  0.110885       1        1  72.803919\n",
              "0      0.152976 -0.005420       2        1  23.446183\n",
              "2     -0.025593 -0.037991       3        1   3.588724\n",
              "3     -0.044157 -0.025797       4        1   0.080595\n",
              "1     -0.052084 -0.041678       5        1   0.080579, topic_info=        Term        Freq       Total Category  logprob  loglift\n",
              "79       the  127.000000  127.000000  Default  30.0000  30.0000\n",
              "121    parti   36.000000   36.000000  Default  29.0000  29.0000\n",
              "26   dissent   15.000000   15.000000  Default  28.0000  28.0000\n",
              "60        of   62.000000   62.000000  Default  27.0000  27.0000\n",
              "78      that   32.000000   32.000000  Default  26.0000  26.0000\n",
              "..       ...         ...         ...      ...      ...      ...\n",
              "192   candid    0.002591   12.369447   Topic5  -6.2774  -1.3472\n",
              "82      type    0.002590    5.476167   Topic5  -6.2777  -0.5327\n",
              "310   member    0.002589   11.435530   Topic5  -6.2782  -1.2695\n",
              "58       not    0.002589   11.189832   Topic5  -6.2782  -1.2478\n",
              "43         i    0.002588   13.531002   Topic5  -6.2785  -1.4381\n",
              "\n",
              "[313 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "0         1  0.770265        's\n",
              "0         2  0.240708        's\n",
              "1         1  0.639878        --\n",
              "1         2  0.399924        --\n",
              "136       1  0.748335       414\n",
              "...     ...       ...       ...\n",
              "92        1  0.552458      with\n",
              "92        2  0.414344      with\n",
              "93        1  0.588878  wodougla\n",
              "453       1  0.206321     would\n",
              "453       2  0.618962     would\n",
              "\n",
              "[179 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 1, 3, 4, 2])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el3421340327313179685358132674\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el3421340327313179685358132674_data = {\"mdsDat\": {\"x\": [-0.03114119872141675, 0.15297555770120394, -0.025593292648882084, -0.04415718994962772, -0.05208387638127727], \"y\": [0.11088547389070483, -0.0054196189393271275, -0.03799136576376254, -0.025796565828987258, -0.041677923358627925], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [72.80391921668146, 23.446183107341934, 3.588723705285509, 0.08059450362546673, 0.08057946706561805]}, \"tinfo\": {\"Term\": [\"the\", \"parti\", \"dissent\", \"of\", \"that\", \"be\", \"in\", \"by\", \"justic\", \"candid\", \"member\", \"democrat\", \"i\", \"author\", \"republican\", \"state\", \"it\", \"select\", \"is\", \"to\", \"'s\", \"and\", \"a\", \"no\", \"an\", \"independ\", \"for\", \"--\", \"this\", \"primari\", \"parti\", \"by\", \"candid\", \"member\", \"democrat\", \"republican\", \"state\", \"select\", \"no\", \"an\", \"independ\", \"be\", \"than\", \"may\", \"associ\", \"v.\", \"u.s.\", \"primari\", \"vote\", \"which\", \"case\", \"me\", \"requir\", \"if\", \"can\", \"there\", \"properti\", \"interest\", \"process\", \"more\", \"decis\", \"is\", \"to\", \"the\", \"it\", \"of\", \"as\", \"that\", \"a\", \"and\", \"'s\", \"not\", \"in\", \"dissent\", \"this\", \"for\", \"--\", \"i\", \"was\", \"justic\", \"great\", \"discrimin\", \"though\", \"richmond\", \"those\", \"fulfil\", \"never\", \"again\", \"act\", \"confin\", \"am\", \"shallow\", \"demonstr\", \"litig\", \"benefit\", \"approach\", \"promis\", \"strike\", \"reveal\", \"innoc\", \"pain\", \"time\", \"sensit\", \"hablackmun\", \"trade\", \"best\", \"embodi\", \"when\", \"toward\", \"lessen\", \"sought\", \"day\", \"would\", \"justic\", \"i\", \"the\", \"of\", \"join\", \"marshal\", \"in\", \"--\", \"court\", \"this\", \"who\", \"so\", \"with\", \"that\", \"it\", \"one\", \"'s\", \"and\", \"to\", \"dissent\", \"a\", \"violat\", \"petition\", \"murder\", \"jeopardi\", \"tri\", \"doubl\", \"substanc\", \"twice\", \"wjbrennan\", \"claus\", \"rational-basi\", \"fail\", \"ground\", \"challeng\", \"test\", \"affirm\", \"classif\", \"brennan\", \"wodougla\", \"they\", \"protect\", \"white\", \"guarante\", \"equal\", \"view\", \"against\", \"dougla\", \"mr.\", \"becaus\", \"dissentbi\", \"dissent\", \"type\", \"author\", \"the\", \"justic\", \"in\", \"that\", \"of\", \"be\", \"for\", \"was\", \"on\", \"fail\", \"test\", \"wjbrennan\", \"claus\", \"challeng\", \"classif\", \"ground\", \"rational-basi\", \"affirm\", \"twice\", \"substanc\", \"doubl\", \"tri\", \"jeopardi\", \"murder\", \"petition\", \"violat\", \"767\", \"been\", \"poll\", \"conflict\", \"next\", \"degre\", \"true\", \"issu\", \"him\", \"them\", \"414\", \"consid\", \"casual\", \"the\", \"parti\", \"of\", \"that\", \"it\", \"to\", \"member\", \"is\", \"a\", \"'s\", \"candid\", \"by\", \"and\", \"on\", \"in\", \"democrat\", \"state\", \"republican\", \"not\", \"primari\", \"other\", \"be\", \"select\", \"as\", \"no\", \"ani\", \"elect\", \"u.s.\", \"there\", \"--\", \"i\", \"so\", \"or\", \"dissent\", \"justic\", \"twice\", \"substanc\", \"doubl\", \"tri\", \"jeopardi\", \"murder\", \"petition\", \"wjbrennan\", \"claus\", \"fail\", \"test\", \"rational-basi\", \"challeng\", \"ground\", \"affirm\", \"classif\", \"violat\", \"been\", \"poll\", \"degre\", \"conflict\", \"next\", \"414\", \"767\", \"them\", \"true\", \"issu\", \"henceforth\", \"form\", \"him\", \"dilut\", \"american\", \"respect\", \"said\", \"pollster\", \"417\", \"made\", \"leav\", \"forward\", \"summarili\", \"their\", \"wodougla\", \"relat\", \"of\", \"guarante\", \"against\", \"the\", \"in\", \"that\", \"view\", \"dissent\", \"justic\", \"mr.\", \"dougla\", \"to\", \"it\", \"parti\", \"'s\", \"be\", \"by\", \"author\", \"is\", \"and\", \"for\", \"was\", \"a\", \"as\", \"candid\", \"type\", \"member\", \"not\", \"i\"], \"Freq\": [127.0, 36.0, 15.0, 62.0, 32.0, 15.0, 20.0, 16.0, 12.0, 12.0, 11.0, 10.0, 13.0, 8.0, 8.0, 8.0, 34.0, 8.0, 18.0, 45.0, 20.0, 20.0, 18.0, 6.0, 6.0, 6.0, 8.0, 12.0, 14.0, 5.0, 35.94678156796349, 15.786805197268036, 12.11366926889467, 11.180522650569072, 10.278607447089035, 8.442338970173497, 8.443012816533573, 8.44679123152418, 6.608146590096884, 6.615545550818892, 6.616174125847283, 14.890683563440266, 5.699182408112864, 5.700873118230781, 5.69547654333329, 5.691914037770717, 5.688383454300998, 5.683817434219414, 4.773289650087207, 4.777733495613411, 4.775953403635501, 4.777921835961253, 4.7792094571066706, 4.7721297173132085, 4.77505871443304, 4.768225935557935, 3.869957976286959, 3.857287807432125, 3.8568249370857335, 3.853081636397266, 3.8553010924531925, 16.721932146153996, 38.823101430567924, 99.47791485775568, 27.761785161144932, 46.176122198145805, 11.21045048322279, 24.99393540925705, 14.87857290181292, 15.814643583844, 15.798942557373042, 9.372252751095457, 13.052098703386859, 10.310480786201818, 9.40693697558451, 6.624070490816134, 7.549954542816467, 6.6486801028002755, 5.717776736999824, 5.723704379442078, 4.865873747448951, 4.863978794865892, 4.864533187187982, 4.863777673443582, 3.2963677752066247, 3.2940354396047877, 3.293260112783469, 1.7273431112007724, 1.7262827377539685, 1.726614139502811, 1.7261059153882579, 1.7269711487189923, 1.7262666629934493, 1.7258262893215526, 1.7265242329933959, 1.7264885320717775, 1.726897503885916, 1.7261575041545751, 1.7265825507292327, 1.7264631115202589, 1.7264747003010983, 1.727143858936663, 1.726575447928073, 1.7271098402574248, 1.7261180649165573, 1.7263825508018433, 1.726650588087709, 1.7264907750616176, 1.7264367563896403, 1.7259601210486655, 1.7262984386828477, 3.295811513726334, 3.3092657144492237, 6.4459901831288375, 6.453390554273887, 25.36941135030844, 15.869157603141755, 3.296308335975868, 3.31955916865608, 6.4452215852770385, 4.867890942978285, 3.293553196789213, 4.866217298726093, 3.3002178672667815, 3.298022727876817, 3.2970724478479876, 6.450659340312191, 6.454479152009509, 3.2970186160918304, 4.880349630043907, 4.880626639289132, 6.482364749362197, 3.3317898184213144, 3.3078189860025, 0.7828124184281086, 0.4280679619849219, 0.42796831425583765, 0.4279359280286417, 0.42793100715313137, 0.4279110089439353, 0.4278626012615895, 0.4278043232184816, 0.42604914419706597, 0.42581400073299946, 0.42571572627149945, 0.4254455358742925, 0.42544433426515627, 0.42532840759325, 0.42526663916169877, 0.4249072722007377, 0.42463994277766465, 0.7770219212200294, 0.42871130923841544, 0.4263964378471819, 0.4254999802120609, 0.42557316393040645, 0.42797752659254884, 0.41987670694210916, 0.42979661977611616, 0.42966913476870894, 0.4302721995063969, 0.42981038106170033, 0.4283168953443139, 0.425943116495663, 1.8533049411386242, 0.7836542314572718, 0.7858968918613652, 2.289932623025066, 0.7848617914197147, 0.7969554724006706, 0.8066505126677519, 0.8217359143005428, 0.4408684180159202, 0.4368162773013493, 0.433961540091046, 0.4281374550466347, 0.0024887714915278426, 0.002486214305017003, 0.0024818193816424374, 0.002482560676601453, 0.0024835292591806214, 0.002483153712568665, 0.0024788964467845386, 0.0024774310439869014, 0.0024798502516527147, 0.0024463160916107563, 0.0024463213923114385, 0.002446320749802265, 0.0024463229985843726, 0.0024463242836027196, 0.0024463120759284215, 0.00244631721600181, 0.0024786812062113904, 0.002532055728278844, 0.0025303235235468783, 0.0025302653764666693, 0.002526814459695383, 0.0025267794429454232, 0.0025262493728772212, 0.0025264981845546895, 0.0025256299940338922, 0.002525730546719557, 0.002524047333312077, 0.0025231911898382846, 0.002519642772299908, 0.0025196805197138556, 0.007430038406643326, 0.005033963319860484, 0.005004111058637713, 0.0039000653791125195, 0.0037360899704145596, 0.0038189389583107203, 0.0032627714524966667, 0.003375777250963874, 0.003336244304022807, 0.003344440151040965, 0.0031604926659369267, 0.0032312512374592876, 0.0032769651226501736, 0.0029210709387861825, 0.0032455592742456916, 0.0030374193912289286, 0.0029672133775958446, 0.002966198855610765, 0.002971306482286122, 0.0028374872416500356, 0.00270132284253039, 0.003015854534581551, 0.0028872502196528086, 0.002932185383725318, 0.0028196894162873442, 0.0027292260521751127, 0.0027284643575498364, 0.002777584505124445, 0.002746976974368133, 0.0028693467015310633, 0.002853690680498494, 0.0027780609256766527, 0.0027691040265423916, 0.002810355364268193, 0.002798741047192014, 0.002590824301956998, 0.002588718710427953, 0.0025869903620155065, 0.002586269601220574, 0.002586091819981717, 0.002584954469725543, 0.0025813871213436743, 0.002555817778829342, 0.002555828860044772, 0.002555823078541069, 0.002555830787212673, 0.0025558272540715213, 0.0025558261298902455, 0.002555827093474196, 0.0025558319113939483, 0.0025558306266153475, 0.0025897791345654165, 0.0025587366352125616, 0.0025587989469746907, 0.002559119659832863, 0.002558292904803382, 0.002558869449200398, 0.0025589095985316663, 0.0025578313480911197, 0.0025585749137062123, 0.0025586691843360308, 0.002558482570244295, 0.0025591204628194887, 0.002559158684982856, 0.0025583023800455616, 0.002558889363268707, 0.002559670187463217, 0.0025596168691512924, 0.0025590592752386355, 0.002559070677648716, 0.0025594042382928945, 0.0025591565972176303, 0.00255930787989785, 0.002559381594070059, 0.0025593461020612177, 0.0025592927837492932, 0.002592481505754437, 0.002559154027660429, 0.002805082493049955, 0.002601416659129579, 0.002595139070289761, 0.002772646008915458, 0.0026975683654166115, 0.0026799410424191636, 0.002586343475990108, 0.0026318537065669048, 0.0026245426739402358, 0.0025808210157727885, 0.002578129886396523, 0.0026369253700927416, 0.002632744058137115, 0.002631917463704959, 0.0026284890320092793, 0.002617331693447088, 0.0026009809585866533, 0.0025997766392459234, 0.002599751586063212, 0.0025958668973669967, 0.0025957279806808078, 0.0025949914813480184, 0.0025931730378362054, 0.00259153366034185, 0.002591141642271344, 0.0025903052514023588, 0.00258913610287582, 0.002588971169422969, 0.002588192111799035], \"Total\": [127.0, 36.0, 15.0, 62.0, 32.0, 15.0, 20.0, 16.0, 12.0, 12.0, 11.0, 10.0, 13.0, 8.0, 8.0, 8.0, 34.0, 8.0, 18.0, 45.0, 20.0, 20.0, 18.0, 6.0, 6.0, 6.0, 8.0, 12.0, 14.0, 5.0, 36.243398982137975, 16.051768797841692, 12.36944705411761, 11.435530292091645, 10.531151847458984, 8.68889983694569, 8.689955474520874, 8.69616842335006, 6.853360830337156, 6.86213348763256, 6.862963412179043, 15.504207723868616, 5.941859521202786, 5.944945435425222, 5.939978037527186, 5.937176407352045, 5.933624922933852, 5.929189445499459, 5.014983573588951, 5.019670104957047, 5.018433307344595, 5.020620780380093, 5.02219505023442, 5.015051001405009, 5.018869501615213, 5.011865635785175, 4.10963710633773, 4.097166030692132, 4.097399062520283, 4.0936648097667385, 4.096030204344947, 18.549801847443074, 45.409274435252456, 127.14746151550474, 34.32145963364212, 62.87482490913979, 13.0357337972126, 32.25782526865852, 18.277036844926062, 20.784643002774608, 20.772072808076125, 11.189831554860492, 20.30021888870423, 15.501017754832592, 14.359248199803405, 8.795988027349031, 12.502379801981451, 13.5310021707741, 7.884106134790786, 12.959979637711763, 5.139627781919098, 5.139391128719914, 5.139988825352575, 5.1397100350555025, 3.5661593443897597, 3.564980293307371, 3.564965328220551, 1.9924140964984902, 1.9912347077142796, 1.9919049181566293, 1.9913215687562658, 1.9923272071658806, 1.9917250601002356, 1.9913661706024874, 1.99217927768608, 1.9921884438020119, 1.9927127464357033, 1.9920246759090385, 1.9925281385806435, 1.9924099175387169, 1.992430159607286, 1.9932054800950874, 1.9925791307066965, 1.9932315395952989, 1.9921657484135844, 1.9924804583709717, 1.9927955770831847, 1.9926513043110445, 1.9926270721690118, 1.9921151768744383, 1.9925449530215253, 4.484313617785801, 4.846824936062337, 12.959979637711763, 13.5310021707741, 127.14746151550474, 62.87482490913979, 5.39703897157576, 5.780319081656068, 20.30021888870423, 12.502379801981451, 6.321425949208858, 14.359248199803405, 7.241580042301378, 7.240411946150541, 7.240368411466396, 32.25782526865852, 34.32145963364212, 8.172797328946121, 20.772072808076125, 20.784643002774608, 45.409274435252456, 15.501017754832592, 18.277036844926062, 1.1335483627938792, 0.7756589705098047, 0.7755628791353687, 0.7755319142411083, 0.7755271916845391, 0.7755076589766388, 0.7754612050178972, 0.7754038747475983, 0.7773885987128931, 0.7776239150850298, 0.778068090360188, 0.7776736530870877, 0.7783017818250172, 0.7781473844544948, 0.7780509185635689, 0.7788876854667076, 0.7789998416749087, 2.7147160939609685, 1.698145030621902, 1.696807891785578, 1.6957441116719882, 1.6986274186005565, 2.3487077900625826, 2.3582752360832995, 2.613449570122025, 2.6136244669461752, 2.620989473442764, 2.6217203435761864, 2.623343782415888, 2.6260155025703606, 15.501017754832592, 5.4761674746142415, 8.244815431272626, 127.14746151550474, 12.959979637711763, 20.30021888870423, 32.25782526865852, 62.87482490913979, 15.504207723868616, 8.795988027349031, 7.884106134790786, 6.015119464448684, 0.7776736530870877, 0.7780509185635689, 0.7773885987128931, 0.7776239150850298, 0.7781473844544948, 0.7789998416749087, 0.7783017818250172, 0.778068090360188, 0.7788876854667076, 0.7754038747475983, 0.7754612050178972, 0.7755076589766388, 0.7755271916845391, 0.7755319142411083, 0.7755628791353687, 0.7756589705098047, 1.1335483627938792, 1.3357631549410147, 1.3356071518580344, 1.3357741720758392, 1.335788836217696, 1.3362158286806922, 1.3360264623597222, 1.3362660254789973, 1.3362169004651416, 1.3363591522115799, 1.3361832442694204, 1.3363003624672598, 1.3364985382652594, 1.336543449947025, 127.14746151550474, 36.243398982137975, 62.87482490913979, 32.25782526865852, 34.32145963364212, 45.409274435252456, 11.435530292091645, 18.549801847443074, 18.277036844926062, 20.772072808076125, 12.36944705411761, 16.051768797841692, 20.784643002774608, 6.015119464448684, 20.30021888870423, 10.531151847458984, 8.689955474520874, 8.68889983694569, 11.189831554860492, 5.929189445499459, 3.169033379889381, 15.504207723868616, 8.69616842335006, 13.0357337972126, 6.853360830337156, 4.090038347730931, 4.089750311275743, 5.933624922933852, 5.011865635785175, 12.502379801981451, 13.5310021707741, 7.240411946150541, 6.586565965181545, 15.501017754832592, 12.959979637711763, 0.7754038747475983, 0.7754612050178972, 0.7755076589766388, 0.7755271916845391, 0.7755319142411083, 0.7755628791353687, 0.7756589705098047, 0.7773885987128931, 0.7776239150850298, 0.7776736530870877, 0.7780509185635689, 0.778068090360188, 0.7781473844544948, 0.7783017818250172, 0.7788876854667076, 0.7789998416749087, 1.1335483627938792, 1.3356071518580344, 1.3357741720758392, 1.3360264623597222, 1.335788836217696, 1.3362158286806922, 1.3363003624672598, 1.3357631549410147, 1.3361832442694204, 1.3362660254789973, 1.3362169004651416, 1.3367197213322586, 1.3367792963689042, 1.3363591522115799, 1.3368186153137656, 1.337830930300808, 1.3380574123472773, 1.3372376626950473, 1.3372711640833286, 1.3380420931890982, 1.337559133199398, 1.3381811104554067, 1.338577316596339, 1.3384827396769392, 1.338614708353109, 1.698145030621902, 1.338479862347035, 62.87482490913979, 2.3487077900625826, 2.6136244669461752, 127.14746151550474, 20.30021888870423, 32.25782526865852, 2.613449570122025, 15.501017754832592, 12.959979637711763, 2.6217203435761864, 2.620989473442764, 45.409274435252456, 34.32145963364212, 36.243398982137975, 20.772072808076125, 15.504207723868616, 16.051768797841692, 8.244815431272626, 18.549801847443074, 20.784643002774608, 8.795988027349031, 7.884106134790786, 18.277036844926062, 13.0357337972126, 12.36944705411761, 5.4761674746142415, 11.435530292091645, 11.189831554860492, 13.5310021707741], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.546, -4.3688, -4.6337, -4.7138, -4.798, -4.9948, -4.9947, -4.9942, -5.2397, -5.2386, -5.2385, -4.4273, -5.3877, -5.3874, -5.3883, -5.389, -5.3896, -5.3904, -5.565, -5.5641, -5.5644, -5.564, -5.5637, -5.5652, -5.5646, -5.566, -5.7748, -5.7781, -5.7782, -5.7791, -5.7786, -4.3113, -3.469, -2.5281, -3.8044, -3.2956, -4.7112, -3.9094, -4.4281, -4.3671, -4.3681, -4.8903, -4.5591, -4.7949, -4.8866, -5.2373, -5.1065, -5.2336, -5.3844, -5.3834, -4.4127, -4.4131, -4.413, -4.4131, -4.8021, -4.8028, -4.8031, -5.4484, -5.449, -5.4488, -5.4491, -5.4486, -5.449, -5.4492, -5.4488, -5.4489, -5.4486, -5.4491, -5.4488, -5.4489, -5.4489, -5.4485, -5.4488, -5.4485, -5.4491, -5.4489, -5.4488, -5.4489, -5.4489, -5.4492, -5.449, -4.8023, -4.7982, -4.1315, -4.1303, -2.7614, -3.2306, -4.8022, -4.7951, -4.1316, -4.4123, -4.803, -4.4126, -4.801, -4.8016, -4.8019, -4.1308, -4.1302, -4.8019, -4.4097, -4.4097, -4.1259, -4.7914, -4.7987, -4.3629, -4.9665, -4.9668, -4.9668, -4.9668, -4.9669, -4.967, -4.9671, -4.9712, -4.9718, -4.972, -4.9727, -4.9727, -4.9729, -4.9731, -4.9739, -4.9746, -4.3703, -4.965, -4.9704, -4.9725, -4.9724, -4.9667, -4.9858, -4.9625, -4.9628, -4.9614, -4.9625, -4.9659, -4.9715, -3.5011, -4.3618, -4.359, -3.2895, -4.3603, -4.345, -4.3329, -4.3144, -4.9371, -4.9463, -4.9528, -4.9664, -6.3179, -6.3189, -6.3207, -6.3204, -6.32, -6.3201, -6.3219, -6.3225, -6.3215, -6.3351, -6.3351, -6.3351, -6.3351, -6.3351, -6.3351, -6.3351, -6.322, -6.3006, -6.3013, -6.3014, -6.3027, -6.3027, -6.3029, -6.3028, -6.3032, -6.3031, -6.3038, -6.3042, -6.3056, -6.3055, -5.2241, -5.6135, -5.6194, -5.8687, -5.9116, -5.8897, -6.0471, -6.0131, -6.0248, -6.0224, -6.0789, -6.0568, -6.0428, -6.1577, -6.0524, -6.1187, -6.1421, -6.1424, -6.1407, -6.1868, -6.2359, -6.1258, -6.1694, -6.1539, -6.1931, -6.2257, -6.2259, -6.2081, -6.2192, -6.1756, -6.1811, -6.2079, -6.2112, -6.1964, -6.2005, -6.2775, -6.2783, -6.279, -6.2793, -6.2793, -6.2798, -6.2812, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2911, -6.2779, -6.29, -6.29, -6.2898, -6.2902, -6.2899, -6.2899, -6.2903, -6.29, -6.29, -6.2901, -6.2898, -6.2898, -6.2901, -6.2899, -6.2896, -6.2896, -6.2899, -6.2898, -6.2897, -6.2898, -6.2898, -6.2897, -6.2897, -6.2898, -6.2769, -6.2898, -6.1981, -6.2734, -6.2759, -6.2097, -6.2371, -6.2437, -6.2792, -6.2618, -6.2646, -6.2814, -6.2824, -6.2599, -6.2615, -6.2618, -6.2631, -6.2673, -6.2736, -6.2741, -6.2741, -6.2756, -6.2756, -6.2759, -6.2766, -6.2772, -6.2774, -6.2777, -6.2782, -6.2782, -6.2785], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3092, 0.3008, 0.2965, 0.2948, 0.2931, 0.2886, 0.2886, 0.2883, 0.281, 0.2808, 0.2808, 0.277, 0.2757, 0.2755, 0.2754, 0.2752, 0.2752, 0.2751, 0.268, 0.268, 0.2679, 0.2679, 0.2678, 0.2677, 0.2676, 0.2676, 0.2573, 0.2571, 0.2569, 0.2568, 0.2568, 0.2137, 0.1607, 0.072, 0.1053, 0.0087, 0.1666, 0.0623, 0.1117, 0.0441, 0.0437, 0.1401, -0.1243, -0.0903, -0.1055, 0.0338, -0.187, -0.3932, -0.0039, -0.4998, 1.3957, 1.3954, 1.3954, 1.3953, 1.3718, 1.3714, 1.3712, 1.3077, 1.3077, 1.3075, 1.3075, 1.3075, 1.3074, 1.3073, 1.3073, 1.3073, 1.3073, 1.3072, 1.3072, 1.3072, 1.3072, 1.3072, 1.3072, 1.3072, 1.3071, 1.3071, 1.3071, 1.3071, 1.3071, 1.307, 1.307, 1.1425, 1.0689, 0.7521, 0.7101, -0.1613, 0.0737, 0.9574, 0.8958, 0.3032, 0.5072, 0.7985, 0.3684, 0.6646, 0.6641, 0.6638, -0.1591, -0.2205, 0.5427, 0.0021, 0.0015, -0.4962, -0.0869, -0.2589, 2.9572, 2.7329, 2.7328, 2.7328, 2.7328, 2.7328, 2.7327, 2.7327, 2.726, 2.7251, 2.7243, 2.7242, 2.7234, 2.7233, 2.7233, 2.7214, 2.7206, 2.0764, 1.9509, 1.9462, 1.9448, 1.9432, 1.6248, 1.6016, 1.5223, 1.5219, 1.5205, 1.5191, 1.515, 1.5085, 1.2034, 1.3832, 0.9769, -0.6895, 0.5233, 0.0898, -0.3613, -1.0101, -0.2327, 0.3248, 0.4277, 0.6848, 1.379, 1.3775, 1.3765, 1.3765, 1.3763, 1.375, 1.3742, 1.3739, 1.3738, 1.3647, 1.3646, 1.3646, 1.3645, 1.3645, 1.3645, 1.3644, 0.9981, 0.8553, 0.8547, 0.8546, 0.8532, 0.8528, 0.8528, 0.8527, 0.8524, 0.8523, 0.8518, 0.8514, 0.8498, 0.8498, -2.6241, -1.7583, -2.3151, -1.897, -2.002, -2.26, -1.0384, -1.4881, -1.4851, -1.6106, -1.1488, -1.3872, -1.6316, -0.5066, -1.6176, -1.0276, -0.8588, -0.859, -1.1103, -0.5212, 0.0561, -1.4215, -0.8868, -1.2762, -0.6724, -0.1888, -0.189, -0.5433, -0.3856, -1.2561, -1.3406, -0.7422, -0.6508, -1.4919, -1.317, 1.4223, 1.4214, 1.4207, 1.4204, 1.4203, 1.4198, 1.4183, 1.4061, 1.4058, 1.4057, 1.4053, 1.4052, 1.4051, 1.4049, 1.4042, 1.404, 1.0421, 0.8661, 0.866, 0.8659, 0.8657, 0.8657, 0.8656, 0.8656, 0.8656, 0.8655, 0.8655, 0.8654, 0.8653, 0.8653, 0.8652, 0.8648, 0.8646, 0.865, 0.8649, 0.8645, 0.8648, 0.8644, 0.8641, 0.8641, 0.864, 0.639, 0.8641, -2.8938, 0.3181, 0.2088, -3.6096, -1.8024, -2.272, 0.2055, -1.5573, -1.381, 0.2002, 0.1994, -2.6302, -2.3518, -2.4066, -1.8513, -1.563, -1.604, -0.9382, -1.7491, -1.8644, -1.0045, -0.8953, -1.7368, -1.3995, -1.3472, -0.5327, -1.2695, -1.2478, -1.4381]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 3, 1, 1, 1, 2, 2, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 3, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 3, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 3, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2], \"Freq\": [0.7702649681537436, 0.24070780254804489, 0.6398781773316559, 0.3999238608322849, 0.7483347517422384, 0.7473606436525427, 0.7486357115787929, 0.8207019620997367, 0.16414039241994732, 1.0044019382806872, 1.0038073930087332, 0.7652208744192124, 1.004358126472338, 0.7474786068633893, 1.0200909108830238, 0.7697991251456235, 0.24056222660800736, 0.9779859404543524, 1.0039210930182287, 0.8438343534103239, 0.15342442789278615, 1.010104744848148, 0.727730056544622, 0.24257668551487402, 0.12128834275743701, 0.9674792976946257, 0.7623857816142425, 0.7487231545659565, 1.0039257121091048, 1.0037739600393252, 0.7367252894139122, 0.3683626447069561, 0.9967748851547966, 0.996240288453577, 0.9701322902712434, 0.996326880080758, 0.7481986463213267, 1.0040639900878714, 0.7486213186445797, 0.7482237887801764, 0.47457646804760206, 0.47457646804760206, 0.22299956810196636, 0.6689987043058991, 0.9765552987760976, 0.7484881685904453, 0.9495637461929538, 1.0041546597296656, 0.7480446401214195, 0.9728778905460281, 0.6451189307800388, 0.19353567923401166, 0.12902378615600776, 0.7616101268413638, 0.7630705961489147, 0.978054818889971, 1.0036152342968165, 0.8480774293850727, 0.7958173633519243, 0.22737638952912123, 0.7480666425013476, 0.7470618152582662, 0.8415193782787459, 0.9728330945656609, 0.8515320673189017, 1.0033957221076661, 0.7480999823982079, 0.7483018306456545, 0.5173304912417684, 0.44342613535008724, 0.9969988338302457, 0.6403871835704031, 0.2955633154940322, 0.049260552582338704, 1.0199675533134522, 1.0038094984342676, 0.9762845757374109, 0.9164518381280337, 0.10781786330918043, 0.7483814937918362, 0.815816119095186, 0.1748177398061113, 0.3705735701619485, 0.5558603552429228, 0.46296369035494644, 0.46296369035494644, 0.07716061505915775, 0.7472830039124393, 1.0039580156896013, 1.0043356312490235, 0.7476304973582981, 0.3460016604181992, 0.5190024906272989, 1.0092607350517828, 0.9958927827290449, 0.9619142898521427, 0.9771195703313883, 0.76285787113048, 0.8415229108265821, 0.7483820940718434, 1.0213966801534409, 0.8043016515374352, 0.17873370034165226, 0.7316123753262844, 0.25447386967870766, 0.01590461685491923, 0.6649909488317403, 0.33249547441587013, 0.6117856345576048, 0.36707138073456286, 0.759120917703006, 0.3036483670812024, 0.946660902670807, 1.0037993002445849, 0.993284322415292, 0.7486295370166991, 0.7477914927489513, 1.0119427039988222, 0.9762290513972115, 1.003656951348021, 0.9733219494809768, 0.5897116157543423, 0.7471162085670023, 0.9207149524251103, 0.9955806076800254, 0.7473520872663882, 1.00374994022653, 0.972817525871575, 0.7478102269305039, 0.9199453840520407, 1.0037242532449246, 1.003851171035823, 0.5524547539213777, 0.4143410654410332, 1.003741469906197, 0.9206031059026899, 1.0040036271575412, 0.7471146024948842, 1.009784896224784, 0.7750057479631097, 0.18600137951114634, 0.031000229918524393, 0.7786234881923115, 0.19662209297785646, 0.015729767438228518, 0.7470409474510369, 0.7484003442557506, 0.9976324912422925, 0.5893419077322207, 0.6267737610471292, 0.3482076450261829, 0.8412411533768296, 0.972764760759383, 1.00340884067035, 0.8588553876941764, 0.13213159810679637, 1.0037001042161706, 1.0039325300079345, 0.7483539811180491, 0.547828387993435, 0.36521892532895667, 0.18260946266447833, 1.0111862610003548, 1.0105813922877818, 0.7652720843994009, 0.8821855624538861, 0.9970122387503199, 0.7610247626580458, 0.25367492088601523, 1.0036878984662578, 0.9960813948833764, 0.5887106195565047, 0.5523656407350567, 0.41427423055129253, 0.5524580757058297, 0.41434355677937224, 0.588877853167686, 0.20632063530077097, 0.6189619059023129], \"Term\": [\"'s\", \"'s\", \"--\", \"--\", \"414\", \"417\", \"767\", \"a\", \"a\", \"act\", \"again\", \"against\", \"am\", \"american\", \"an\", \"and\", \"and\", \"ani\", \"approach\", \"as\", \"as\", \"associ\", \"author\", \"author\", \"author\", \"be\", \"becaus\", \"been\", \"benefit\", \"best\", \"brennan\", \"brennan\", \"by\", \"can\", \"candid\", \"case\", \"casual\", \"confin\", \"conflict\", \"consid\", \"court\", \"court\", \"day\", \"day\", \"decis\", \"degre\", \"democrat\", \"demonstr\", \"dilut\", \"discrimin\", \"dissent\", \"dissent\", \"dissent\", \"dissentbi\", \"dougla\", \"elect\", \"embodi\", \"equal\", \"for\", \"for\", \"form\", \"forward\", \"fulfil\", \"great\", \"guarante\", \"hablackmun\", \"henceforth\", \"him\", \"i\", \"i\", \"if\", \"in\", \"in\", \"in\", \"independ\", \"innoc\", \"interest\", \"is\", \"is\", \"issu\", \"it\", \"it\", \"join\", \"join\", \"justic\", \"justic\", \"justic\", \"leav\", \"lessen\", \"litig\", \"made\", \"marshal\", \"marshal\", \"may\", \"me\", \"member\", \"more\", \"mr.\", \"never\", \"next\", \"no\", \"not\", \"not\", \"of\", \"of\", \"of\", \"on\", \"on\", \"one\", \"one\", \"or\", \"or\", \"other\", \"pain\", \"parti\", \"poll\", \"pollster\", \"primari\", \"process\", \"promis\", \"properti\", \"protect\", \"relat\", \"republican\", \"requir\", \"respect\", \"reveal\", \"richmond\", \"said\", \"select\", \"sensit\", \"shallow\", \"so\", \"so\", \"sought\", \"state\", \"strike\", \"summarili\", \"than\", \"that\", \"that\", \"that\", \"the\", \"the\", \"the\", \"their\", \"them\", \"there\", \"they\", \"this\", \"this\", \"those\", \"though\", \"time\", \"to\", \"to\", \"toward\", \"trade\", \"true\", \"type\", \"type\", \"type\", \"u.s.\", \"v.\", \"view\", \"violat\", \"vote\", \"was\", \"was\", \"when\", \"which\", \"white\", \"who\", \"who\", \"with\", \"with\", \"wodougla\", \"would\", \"would\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 1, 3, 4, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el3421340327313179685358132674\", ldavis_el3421340327313179685358132674_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el3421340327313179685358132674\", ldavis_el3421340327313179685358132674_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el3421340327313179685358132674\", ldavis_el3421340327313179685358132674_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhLOTsDloAhJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}